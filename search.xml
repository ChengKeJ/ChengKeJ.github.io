<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>最好使用的 v2rayNG 完整介绍与入门</title>
      <link href="2024/01/03/vpn-v2ray/"/>
      <url>2024/01/03/vpn-v2ray/</url>
      
        <content type="html"><![CDATA[<h3 id="一-v2rayNG介绍"><a href="#一-v2rayNG介绍" class="headerlink" title="一.v2rayNG介绍"></a>一.v2rayNG介绍</h3><p>v2rayNG 提供了一个简洁而直观的用户界面，使用户可以轻松配置和管理 V2Ray 的各种功能。它支持多种传输协议和代理方式，包括 Shadowsocks、VMess、Socks 等。用户可以根据自己的需求选择合适的协议和代理方式来进行网络代理。</p><p>作为市场上排名第一的vpn，v2rayNG可以做到vpn能做的一切，链接到最快的服务器，保护用户的互联网链接，互联网服务提供商和黑客的窥探，保护用户的整个网络。</p><h3 id="二-v2rayNG优点"><a href="#二-v2rayNG优点" class="headerlink" title="二.v2rayNG优点"></a>二.v2rayNG优点</h3><ul><li>1.拥有全球3000多个节点</li><li>2.闪电网速，无限流量</li><li>3.观看tiktok、youtube 4K原画无卡顿</li><li>4.节点任意切换，实现翻墙自由</li><li>5.适配windows.安卓.ios.mac</li><li>6.提供退款保障，人工售后稳定</li></ul><h3 id="三-v2rayNG-价格"><a href="#三-v2rayNG-价格" class="headerlink" title="三.v2rayNG 价格"></a>三.v2rayNG 价格</h3><table><thead><tr><th>方案名称</th><th>价格</th><th>流量</th><th>设备限制</th></tr></thead><tbody><tr><td>Vip包月</td><td>29.8</td><td>无限流量</td><td>5个节点同时在线</td></tr><tr><td>Vip包季</td><td>79.8</td><td>无限流量</td><td>10个节点同时在线</td></tr><tr><td>Vip包年</td><td>268</td><td>无限流量</td><td>15个节点同时在线</td></tr><tr><td>个人定制化</td><td>999</td><td>无限流量</td><td>100个节点同时在线</td></tr></tbody></table><span id="more"></span><h3 id="四-购买地址-amp-人工客服"><a href="#四-购买地址-amp-人工客服" class="headerlink" title="四. 购买地址&amp;人工客服"></a>四. 购买地址&amp;人工客服</h3><ul><li>快速购买<ul><li><a target="_blank" rel="noopener" href="https://86faka.cc/">https://86faka.cc</a></li></ul></li><li>人工售后服务<ul><li>微信号：vipcc868686 QQ号：3682083251 电报号：@vipcc868686</li></ul></li></ul><p><img src="/uploads/a.png" alt="Image.png"></p><h3 id="五-V2rayN（Windows）使用教程"><a href="#五-V2rayN（Windows）使用教程" class="headerlink" title="五. V2rayN（Windows）使用教程"></a>五. V2rayN（Windows）使用教程</h3><ul><li>1.复制以下官网链接到Google.com（谷歌浏览器）下载 <a target="_blank" rel="noopener" href="https://github.com/2dust/v2rayN/releases/tag/6.31">https://github.com/2dust/v2rayN/releases/tag/6.31</a></li></ul><p><img src="/uploads/b.png" alt="Image.png"></p><ul><li>2.根据自己电脑配置选择v2rayN版本下载。</li><li>3.下载后在图标点击鼠标右键以管理员身份运行打开。</li></ul><p><img src="/uploads/c.png" alt="Image.png"></p><ul><li>4.如果运行报错，点击安装解压出来的windowsdesktop-runtime-6.0.24-win-x64.exe后再运行v2rayN。</li></ul><p><img src="/uploads/d.png" alt="Image.png"></p><ul><li>5.打开V2rayN软件后，复制卡密内容。找到服务器，点击从剪贴板导入批量URL，系统代理设置为“自动配置系统代理”，路由设置为“全局模式”。</li></ul><p><img src="/uploads/e.png" alt="Image.png"></p><h3 id="六-Clash-for-windows（windows、mac系统）使用教程"><a href="#六-Clash-for-windows（windows、mac系统）使用教程" class="headerlink" title="六. Clash for windows（windows、mac系统）使用教程"></a>六. Clash for windows（windows、mac系统）使用教程</h3><ul><li>1.下载clash软件：<a target="_blank" rel="noopener" href="https://github.com/Z-Siqi/Clash-for-Windows_Chinese/releases/tag/CFW-V0.20.39_CN">https://github.com/Z-Siqi/Clash-for-Windows_Chinese/releases/tag/CFW-V0.20.39_CN</a></li><li>2.因卡密内容为vmess协议，需要转换成clash，转换地址：<a target="_blank" rel="noopener" href="https://v1.v2rayse.com/v2ray-clash/%EF%BC%8C%E5%B0%86%E5%8D%A1%E5%AF%86%E5%A4%8D%E5%88%B6%E5%88%B0%E8%BD%AC%E6%8D%A2%E5%8C%BA%E5%9F%9F%E5%86%85%EF%BC%8C%E7%BD%91%E7%AB%99%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90clash">https://v1.v2rayse.com/v2ray-clash/，将卡密复制到转换区域内，网站自动生成clash</a></li></ul><p><img src="/uploads/f.png" alt="Image.png"></p><p>3.点击预览clash，在新窗口点击左下方订阅。</p><p><img src="/uploads/g.png" alt="Image.png"></p><p><img src="/uploads/h.png" alt="Image.png"></p><ul><li>4.打开clash软件，在配置中粘贴订阅地址到url中，点击download下载。</li><li>5.打开代理，选择上网节点，在回到主页打开系统代理就能正常上网了。</li></ul><p><img src="/uploads/j.png" alt="Image.png"></p><p><img src="/uploads/k.png" alt="Image.png"></p><h3 id="七-V2rayNG-Angdroid-安卓手机-使用教程"><a href="#七-V2rayNG-Angdroid-安卓手机-使用教程" class="headerlink" title="七. V2rayNG Angdroid(安卓手机)使用教程"></a>七. V2rayNG Angdroid(安卓手机)使用教程</h3><ul><li>1.把以下链接复制到浏览器（建议使用百度、UC、谷歌）下载。</li></ul><p><a target="_blank" rel="noopener" href="https://ssrvps.org/wp-content/uploads/2020/09/v2rayNG_1.3.3.apk">https://ssrvps.org/wp-content/uploads/2020/09/v2rayNG_1.3.3.apk</a></p><ul><li>2.下载后在界面上打开v2rayNG。</li></ul><ul><li>3.点击软件主界面右上角的 ➕ 号按钮，复制微信发的节点，点击从剪贴板导入配置文件即可。</li><li>4.点击软件主界面右小角的 V 字图标启动代理，点击确定启动。</li></ul><p><img src="/uploads/l.png" alt="Image.png"></p><h3 id="八-V2rayNG-ios（苹果手机）使用教程"><a href="#八-V2rayNG-ios（苹果手机）使用教程" class="headerlink" title="八.V2rayNG ios（苹果手机）使用教程"></a>八.V2rayNG ios（苹果手机）使用教程</h3><p>1.苹果手机需要一个国外Apple ID（建议在淘宝商城购买）。</p><p>2.国外ID登录后去app stose去下载v2Box或者Shadowrocket</p><p>（注意：Shadowrocket需要美国Apple ID曾经下载过的才能免费下载，建议新手小白下载v2box即可。）</p><p><img src="/uploads/m.png" alt="Image.png"></p><p>3.复制卡密内容，点击右上角“+”号，点击第一个，v2box自动添加节点。</p><p>4.添加后打开home主界面，滑动图标变为绿色，<a target="_blank" rel="noopener" href="http://访问google.com/">访问google.com</a>，如果不能正常访问，可切换节点再次访问。</p><p><img src="/uploads/q.png" alt="Image.png"></p>]]></content>
      
      
      <categories>
          
          <category> vpn </category>
          
      </categories>
      
      
        <tags>
            
            <tag> vpn </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>在3分钟内学习二分查找</title>
      <link href="2023/12/17/algo-binary-search/"/>
      <url>2023/12/17/algo-binary-search/</url>
      
        <content type="html"><![CDATA[<p>二分查找是一种在有序数组中查找元素的算法，通过不断将搜索区域分成两半来实现。你可能在日常生活中已经不知不觉地使用了大脑里的二分查找。</p><p>最常见的例子是在字典中查找一个单词。假设你想找到“马拉松”的定义。你不会从字典的开头开始查找。你会打开字典大约在中间位置。如果你在‘T’处，你已经过头了。所以，你会调整并分割差距，缩小范围直到找到“马拉松”。</p><p><img src="/uploads/1*eyscCE4qgTvv-yHMQzfpoQ.png" alt="1*eyscCE4qgTvv-yHMQzfpoQ.png"></p><p>这个逐步排除的过程就是二分查找的要点，但是针对数组的情况。</p><h1 id="线性查找-vs-二分查找"><a href="#线性查找-vs-二分查找" class="headerlink" title="线性查找 vs 二分查找"></a>线性查找 vs 二分查找</h1><p>考虑一个从1到100的数字数组，你需要在这个范围内找到一个特定的数字，就像玩一个猜数游戏。</p><h2 id="线性查找"><a href="#线性查找" class="headerlink" title="线性查找"></a>线性查找</h2><p>简单的方法是使用一个简单的for循环——遍历数组中的每个元素直到找到目标项。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">findItem</span>(<span class="params">arr, item</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">let</span> i = <span class="number">0</span>; i &lt; arr.length; i++) &#123;  </span><br><span class="line">    <span class="keyword">if</span> (arr[i] === item) &#123;  </span><br><span class="line">      <span class="keyword">return</span> i;  </span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> -<span class="number">1</span>; <span class="comment">// 未找到项</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个方法可以找到，但它的时间复杂度是O(n)；想象一下，如果你要找的数在1到1万亿之间。</p><p>你可以比线性查找做得更好。</p><span id="more"></span><h2 id="二分查找"><a href="#二分查找" class="headerlink" title="二分查找"></a>二分查找</h2><p>使用二分查找，不是检查每个元素，而是从中间开始。如果你要找的数字更大，你向右走；如果更小，你向左走。</p><p><img src="/uploads/1*hAOPpSt3hqukVmFdPrKefQ.png" alt="1*hAOPpSt3hqukVmFdPrKefQ.png"></p><p>然后呢？你重复这个过程。中间，左边或右边，缩小可能性直到找到数字。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">binarySearch</span>(<span class="params">arr, target</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">let</span> left = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">let</span> right = arr.length - <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">while</span>(left &lt;= right) &#123;</span><br><span class="line">    <span class="keyword">let</span> mid = <span class="built_in">Math</span>.floor((left + right) / <span class="number">2</span>);</span><br><span class="line">    <span class="keyword">if</span>(arr[mid] === target) <span class="keyword">return</span> mid;</span><br><span class="line">    <span class="keyword">if</span>(arr[mid] &lt; target) left = mid + <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">else</span> right = mid - <span class="number">1</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>它不仅能迅速切入数据；时间复杂度为O(logN)，比线性搜索快得多。</p><p>在空间方面，它是O(1)。不需要额外的存储空间。</p><h1 id="小结：何时使用二分查找？"><a href="#小结：何时使用二分查找？" class="headerlink" title="小结：何时使用二分查找？"></a>小结：何时使用二分查找？</h1><p>二分查找最常用于数组，但也可以应用于数据库中的有序序列、排序链表中的搜索算法，甚至决策过程中可以预测和系统地划分范围的情况。</p><p><img src="/uploads/1*Rg-FcePvP1TUC1FN55UfcQ.png" alt="1*Rg-FcePvP1TUC1FN55UfcQ.png"></p><p>重要的是，二分查找只能在排序的项目集合上执行。整个二分查找的方法基于这样一个原则，即集合是按顺序排列的，这样算法才能通过比较中间项来预测搜索项的位置。如果集合没有排序，这种预测就不起作用，算法也不能正确运行。</p><h2 id="系统设计概念系列文章"><a href="#系统设计概念系列文章" class="headerlink" title="系统设计概念系列文章"></a>系统设计概念系列文章</h2><p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzU0NDMzMjY5Ng==&mid=2247488478&idx=1&sn=351b322c2089d8fd7124cf801e0a0524&chksm=fb7c9d29cc0b143facd8d62fb15812d6d28e22749e1183c48d6946dbd13d2e206cd9826bfb20&scene=21#wechat_redirect">计算机的层次化架构</a></p><p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzU0NDMzMjY5Ng==&mid=2247488411&idx=1&sn=2520f364a171f0d747a855600c99cc4b&chksm=fb7c9d6ccc0b147a44627a8eef07b5772acbda406ce566afe306ed2b3c98f665e05c12b6ad36&scene=21#wechat_redirect">每个开发者都应该知道的7个原则</a></p><p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzU0NDMzMjY5Ng==&mid=2247488409&idx=1&sn=a02b97d71d301be4200ab25e4ffad0bc&chksm=fb7c9d6ecc0b1478f85986554735e307e2c92d45236f241dec44a529e9c799c521d5448f9f9a&scene=21#wechat_redirect">6个系统设计的基本概念</a></p><p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzU0NDMzMjY5Ng==&mid=2247488407&idx=1&sn=6072efba48ed2f9f1968594a1055a3f6&chksm=fb7c9d60cc0b14766e394d5c04f33d5b1c63987d6cf5b66732887e9ffedbbfc576e5a6617891&scene=21#wechat_redirect">数据库：系统设计的核心</a></p><h2 id="图解系列"><a href="#图解系列" class="headerlink" title="图解系列"></a>图解系列</h2><p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzU0NDMzMjY5Ng==&mid=2247488260&idx=1&sn=89701a38ab8af1c670b432b5e7bedf2d&chksm=fb7c9df3cc0b14e52a043999e59b5c1251c3183a61b8c9d35777f237d1478c07b7d01352346e&scene=21#wechat_redirect">系统设计中的缓存技术：完整指南</a></p><p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzU0NDMzMjY5Ng==&mid=2247488165&idx=1&sn=2c4aaad53e6ca87f61e23dfba2fd8f9e&chksm=fb7c9c52cc0b1544266bb7e008f55bfbaa9b2acdb512eb07beece554e9f766e80f12699208b7&scene=21#wechat_redirect">关系数据库的全景图</a></p><p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzU0NDMzMjY5Ng==&mid=2247487961&idx=1&sn=f1437b130e1828f4c1c0c45806e4922f&chksm=fb7c9f2ecc0b1638cf34322599d4bd42c002bf2e37c642d9dbc596366f91f237f410b4e90fc5&scene=21#wechat_redirect">Redis 全景解析</a></p><p>当然架构设计、全景图解系列还有很多,快来关注一起学习吧~</p>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>缓存：系统设计中至关重要的一环</title>
      <link href="2023/12/17/redis-system-redis/"/>
      <url>2023/12/17/redis-system-redis/</url>
      
        <content type="html"><![CDATA[<p><img src="https://miro.medium.com/v2/resize:fit:2000/1*miHYi3-erQzdPaF0arbxwQ.png" alt="1*miHYi3-erQzdPaF0arbxwQ.png"></p><h2 id="什么是缓存？"><a href="#什么是缓存？" class="headerlink" title="什么是缓存？"></a>什么是缓存？</h2><p>缓存就像是一个超快速的存储区域，保存了计算机或手机经常使用的内容的副本，这样可以在不访问较慢的主存储器的情况下快速获取。</p><p>一个<strong>现实中的例子</strong>可以是，每当我们购买杂货时，通常会倾向于大量购买，这样可以让杂货多存放一段时间，避免频繁去市场购买，这其实就是将杂货缓存在我们附近，而不是每次都从市场购买。</p><p>在系统设计中，如果缓存得当，它可以显著提升系统的性能。</p><p>缓存策略取决于<strong>数据访问模式</strong>，即数据是如何读取或写入的。例如：</p><ul><li>系统是读取密集型还是写入密集型？</li><li>系统是否需要高一致性？</li></ul><p>等等……</p><p>因此，选择正确的写入缓存策略非常关键，下面是一些不同的<strong>缓存策略</strong>：</p><span id="more"></span><h1 id="1-缓存旁路（懒加载）"><a href="#1-缓存旁路（懒加载）" class="headerlink" title="1. 缓存旁路（懒加载）"></a>1. 缓存旁路（懒加载）</h1><p>在这种设置中，应用程序<strong>缓存被分离</strong>出来，应用程序显式地与缓存和数据库一起工作。这是一种技术，应用程序代码负责管理缓存。当需要时，应用程序会将数据显式加载到缓存中，而缓存不会主动参与数据获取。</p><p><img src="/uploads/1*kf4ytjqSKx-UAYaA-MW4Hw.png" alt="1*kf4ytjqSKx-UAYaA-MW4Hw.png"></p><p>缓存旁路</p><p>该图示了其工作原理。</p><h2 id="使用场景："><a href="#使用场景：" class="headerlink" title="使用场景："></a><strong>使用场景：</strong></h2><p>适用于读取密集型系统，Redis 或 Memcached 非常受欢迎，我曾经在缓存旁路设置中使用过 Redis 以及 Mongo-db，效果非常显著。</p><p>这种读取技术可以与诸如<strong>写入旁路缓存</strong>之类的数据写入技术相结合，我接下来会解释。</p><h2 id="优点："><a href="#优点：" class="headerlink" title="优点："></a><strong>优点：</strong></h2><ul><li><strong>灵活性</strong>：允许选择性缓存特定数据。</li><li><strong>控制</strong>：应用程序控制数据何时加载到缓存中。</li></ul><h2 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a><strong>缺点：</strong></h2><ul><li><strong>提供过期数据</strong>：可能会提供过期数据，但如果我们实现了缓存的TTL（生存时间），则可以避免这种情况。</li></ul><h1 id="2-写入旁路"><a href="#2-写入旁路" class="headerlink" title="2. 写入旁路"></a>2. 写入旁路</h1><p>跳过缓存，直接将数据写入数据库，并在读取用户请求的数据时更新缓存。</p><h2 id="使用场景：-1"><a href="#使用场景：-1" class="headerlink" title="使用场景："></a><strong>使用场景：</strong></h2><p>写入旁路可以与读取通过结合，对于数据写入一次，读取频率较低或几乎不读取的情况下提供良好的性能，例如实时日志或聊天室消息。同样，这种模式也可以与缓存旁路结合使用。</p><h1 id="3-读取穿透缓存"><a href="#3-读取穿透缓存" class="headerlink" title="3. 读取穿透缓存"></a>3. 读取穿透缓存</h1><p>读取穿透缓存是一种策略，当发生<strong>缓存未命中</strong>时，缓存会自动从底层数据源检索数据并填充自身。这种技术与应用程序的数据访问层无缝集成，确保缓存与数据源保持同步。</p><p><img src="/uploads/1*h-CUV05gwKCUl7GdFfS_Nw.png" alt="1*h-CUV05gwKCUl7GdFfS_Nw.png"></p><p>读取穿透缓存</p><h2 id="使用场景、优点和缺点："><a href="#使用场景、优点和缺点：" class="headerlink" title="使用场景、优点和缺点："></a><strong>使用场景、优点和缺点：</strong></h2><p>读取穿透缓存适用于<strong>读取密集</strong>的工作负载，当同一数据被多次请求时。例如，一个新博客。缺点是，当首次请求数据时，总是会导致缓存未命中，并造成额外的数据加载开销。</p><h1 id="4-写入穿透缓存"><a href="#4-写入穿透缓存" class="headerlink" title="4. 写入穿透缓存"></a>4. 写入穿透缓存</h1><p>写入穿透缓存是一种策略，其中写操作同时应用于<strong>缓存</strong>和底层<strong>数据源</strong>。这确保了缓存和数据源保持同步，但与写入后缓存相比可能会引入额外的延迟。它同步应用更新。</p><p><img src="/uploads/1*7TjoMj10e--091ttHEKvTg.png" alt="1*7TjoMj10e--091ttHEKvTg.png"></p><h2 id="使用场景、优点和缺点：-1"><a href="#使用场景、优点和缺点：-1" class="headerlink" title="使用场景、优点和缺点："></a><strong>使用场景、优点和缺点：</strong></h2><p>当与读取穿透缓存结合时，写入穿透缓存可以保证每次读取和写入的数据一致性。但它会增加写操作的额外开销，因为每次写入都需要两次写入操作（缓存和数据库）。它以异步方式应用更新。</p><h1 id="5-写入后缓存"><a href="#5-写入后缓存" class="headerlink" title="5. 写入后缓存"></a>5. 写入后缓存</h1><p>写入后缓存，也称为<strong>写回缓存</strong>，涉及在写操作发生时延迟对数据源的更新。系统不会立即更新底层存储，而是首先更新缓存，然后异步将更改传播到数据源。</p><p><img src="/uploads/1*Sfn9HMtmSggo3FCQIyxJPQ.png" alt="1*Sfn9HMtmSggo3FCQIyxJPQ.png"></p><h2 id="使用场景、优点和缺点：-2"><a href="#使用场景、优点和缺点：-2" class="headerlink" title="使用场景、优点和缺点："></a><strong>使用场景、优点和缺点：</strong></h2><p>写回缓存提高了写入性能，非常适用于写入密集型任务。当与读取穿透结合时，适用于混合工作负载，确保最近的</p><p>数据可用。</p><h1 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h1><p>本文探讨了缓存技术，强调了根据数据访问模式选择正确策略的重要性。了解这些缓存策略对于在不同场景中优化系统性能至关重要。</p><h2 id="系统设计概念系列文章"><a href="#系统设计概念系列文章" class="headerlink" title="系统设计概念系列文章"></a>系统设计概念系列文章</h2><p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzU0NDMzMjY5Ng==&mid=2247488478&idx=1&sn=351b322c2089d8fd7124cf801e0a0524&chksm=fb7c9d29cc0b143facd8d62fb15812d6d28e22749e1183c48d6946dbd13d2e206cd9826bfb20&scene=21#wechat_redirect">计算机的层次化架构</a></p><p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzU0NDMzMjY5Ng==&mid=2247488411&idx=1&sn=2520f364a171f0d747a855600c99cc4b&chksm=fb7c9d6ccc0b147a44627a8eef07b5772acbda406ce566afe306ed2b3c98f665e05c12b6ad36&scene=21#wechat_redirect">每个开发者都应该知道的7个原则</a></p><p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzU0NDMzMjY5Ng==&mid=2247488409&idx=1&sn=a02b97d71d301be4200ab25e4ffad0bc&chksm=fb7c9d6ecc0b1478f85986554735e307e2c92d45236f241dec44a529e9c799c521d5448f9f9a&scene=21#wechat_redirect">6个系统设计的基本概念</a></p><p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzU0NDMzMjY5Ng==&mid=2247488407&idx=1&sn=6072efba48ed2f9f1968594a1055a3f6&chksm=fb7c9d60cc0b14766e394d5c04f33d5b1c63987d6cf5b66732887e9ffedbbfc576e5a6617891&scene=21#wechat_redirect">数据库：系统设计的核心</a></p><h2 id="图解系列"><a href="#图解系列" class="headerlink" title="图解系列"></a>图解系列</h2><p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzU0NDMzMjY5Ng==&mid=2247488260&idx=1&sn=89701a38ab8af1c670b432b5e7bedf2d&chksm=fb7c9df3cc0b14e52a043999e59b5c1251c3183a61b8c9d35777f237d1478c07b7d01352346e&scene=21#wechat_redirect">系统设计中的缓存技术：完整指南</a></p><p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzU0NDMzMjY5Ng==&mid=2247488165&idx=1&sn=2c4aaad53e6ca87f61e23dfba2fd8f9e&chksm=fb7c9c52cc0b1544266bb7e008f55bfbaa9b2acdb512eb07beece554e9f766e80f12699208b7&scene=21#wechat_redirect">关系数据库的全景图</a></p><p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzU0NDMzMjY5Ng==&mid=2247487961&idx=1&sn=f1437b130e1828f4c1c0c45806e4922f&chksm=fb7c9f2ecc0b1638cf34322599d4bd42c002bf2e37c642d9dbc596366f91f237f410b4e90fc5&scene=21#wechat_redirect">Redis 全景解析</a></p><p>当然架构设计、全景图解系列还有很多,快来关注一起学习吧~</p>]]></content>
      
      
      <categories>
          
          <category> 系统设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 缓存技术 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计算机的层次化架构</title>
      <link href="2023/12/03/systemDesign-cpu/"/>
      <url>2023/12/03/systemDesign-cpu/</url>
      
        <content type="html"><![CDATA[<p>计算机在多层次系统中运行。每个层次都经过优化，以执行特定的任务，确保整个机器的高效运行。</p><p><img src="/uploads/1*1CjGIK6LMua2woczwH1r6A.png" alt="1*1CjGIK6LMua2woczwH1r6A.png"></p><h2 id="从比特到大字节：理解计算机内存单元"><a href="#从比特到大字节：理解计算机内存单元" class="headerlink" title="从比特到大字节：理解计算机内存单元"></a>从比特到大字节：理解计算机内存单元</h2><p>在最基本的层面上，计算机使用二进制运行，只包含 0 和 1，被称为<strong>比特</strong>。以下是一个细分：</p><p><strong>1 比特：</strong> 这是计算机中的基本数据单元，表示为 0 或 1。</p><p><strong>1 字节：</strong> 包含 8 个比特，字节用于表示单个字符（例如，“A”）或数字（例如，1）。</p><span id="more"></span><p><img src="/uploads/1*jwxOxDwjT18FwRsqsVztCg.png" alt="1*jwxOxDwjT18FwRsqsVztCg.png"></p><p>进一步扩展：</p><ul><li>千字节（KB）：大约 1,024 字节。</li><li>兆字节（MB）：大约 1,024 KB。</li><li>吉字节（GB）：大约 1,024 MB。</li><li>太字节（TB）：大约 1,024 GB。</li></ul><h2 id="硬盘存储：数据的中央存储库"><a href="#硬盘存储：数据的中央存储库" class="headerlink" title="硬盘存储：数据的中央存储库"></a>硬盘存储：数据的中央存储库</h2><p>计算机的主要数据存储在硬盘存储设备中。</p><p>示例：这包括固态驱动器（SSD）和硬盘驱动器（HDD）。</p><p><img src="/uploads/1*jlQhFPO24uzLfAoGV_rETw.png" alt="1*jlQhFPO24uzLfAoGV_rETw.png"></p><p>显著特点：</p><ul><li><strong>非易失性：</strong> 即使关闭电源或重新启动计算机，数据仍然保持完好。</li><li><strong>存储空间：</strong> 硬盘存储设备的容量通常在 100 GB 到几 TB 之间。</li><li><strong>速度差异：</strong> 尽管价格较高，但相较于 HDD，SSD 的数据检索速度显著更快。例如，SSD 的读取速度可能在 500 MB/s 到 3,500 MB/s 之间（取决于类型和质量），而 HDD 可能提供 80 MB/s 到 160 MB/s。</li></ul><h2 id="RAM：数据处理的前沿"><a href="#RAM：数据处理的前沿" class="headerlink" title="RAM：数据处理的前沿"></a>RAM：数据处理的前沿</h2><p>随机访问存储器（RAM）充当正在使用或正在处理的数据的主要持有者。当启动程序时，由于其快速的读写能力，程序的数据 — 从变量到运行时堆栈 — 存储在这里。</p><p>示例：常见的 RAM 类型包括 DDR4 和 LPDDR5。</p><p><img src="/uploads/1*HgYTk5q2B9dkeYlpg_T6WA.png" alt="1*HgYTk5q2B9dkeYlpg_T6WA.png"></p><p>关键点：</p><ul><li><strong>易失性内存：</strong> 断电时 RAM 的内容会丢失。</li><li><strong>速度：</strong> RAM 比硬盘存储快得多，通常超过 5,000 MB/s。</li><li><strong>存储范围：</strong> 对于典型的消费者设备，RAM 的范围可以从几 GB（8 GB、16 GB、32 GB）到高端服务器可以拥有数百 GB（128 GB 或更多）。</li></ul><h2 id="缓存存储：速度大师"><a href="#缓存存储：速度大师" class="headerlink" title="缓存存储：速度大师"></a>缓存存储：速度大师</h2><p>即使迅速的 RAM 不足以满足需求时，还有缓存存储。</p><p><img src="/uploads/1*W25HWBrg7ku2qh9qoptveQ.png" alt="1*W25HWBrg7ku2qh9qoptveQ.png"></p><p>特征：</p><ul><li><strong>尺寸：</strong> 缓存比 RAM 小但比 RAM 更快，通常以兆字节为单位。</li><li><strong>速度：</strong> 它的访问时间超过 RAM，使其成为存储频繁使用的数据以实现最佳 CPU 性能的理想选择。</li></ul><h2 id="CPU：每台计算机的心跳"><a href="#CPU：每台计算机的心跳" class="headerlink" title="CPU：每台计算机的心跳"></a>CPU：每台计算机的心跳</h2><p>中央处理单元（CPU）通常被称为计算机的“大脑”。它在提取、解码和执行指令方面发挥着关键作用。</p><p><img src="/uploads/1*Gs4u9u7X6rV4LUi92YC7TQ.png" alt="1*Gs4u9u7X6rV4LUi92YC7TQ.png"></p><p>特征：</p><ul><li><strong>执行：</strong> CPU 解释和处理来自我们代码的操作。</li><li><strong>代码翻译：</strong> 高级编程语言需要被翻译成机器代码 — 一系列 0 和 1 — 以便 CPU 理解和运行它们。这种转换是由编译器执行的。</li></ul><p><img src="/uploads/1*IpOltycnP34DNe_3Uz8T8A.png" alt="1*IpOltycnP34DNe_3Uz8T8A.png"></p><h2 id="主板：组"><a href="#主板：组" class="headerlink" title="主板：组"></a>主板：组</h2><p>件的统一者</p><p>最后但并非最不重要，主板（或主板）充当中央枢纽，连接上述所有组件。从托管 CPU 和 RAM 插槽到为数据流提供路径，主板确保所有计算机组件的无缝集成和功能。</p><p><img src="/uploads/1*MJaF3KQr2bDU_wfsE9vNCg.png" alt="1*MJaF3KQr2bDU_wfsE9vNCg.png"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>通过对这些基本概念的理解，您更好地准备深入探讨系统设计的领域。</p><h2 id="系统设计概念系列文章"><a href="#系统设计概念系列文章" class="headerlink" title="系统设计概念系列文章"></a>系统设计概念系列文章</h2><p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzU0NDMzMjY5Ng==&mid=2247488478&idx=1&sn=351b322c2089d8fd7124cf801e0a0524&chksm=fb7c9d29cc0b143facd8d62fb15812d6d28e22749e1183c48d6946dbd13d2e206cd9826bfb20&scene=21#wechat_redirect">计算机的层次化架构</a></p><p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzU0NDMzMjY5Ng==&mid=2247488411&idx=1&sn=2520f364a171f0d747a855600c99cc4b&chksm=fb7c9d6ccc0b147a44627a8eef07b5772acbda406ce566afe306ed2b3c98f665e05c12b6ad36&scene=21#wechat_redirect">每个开发者都应该知道的7个原则</a></p><p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzU0NDMzMjY5Ng==&mid=2247488409&idx=1&sn=a02b97d71d301be4200ab25e4ffad0bc&chksm=fb7c9d6ecc0b1478f85986554735e307e2c92d45236f241dec44a529e9c799c521d5448f9f9a&scene=21#wechat_redirect">6个系统设计的基本概念</a></p><p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzU0NDMzMjY5Ng==&mid=2247488407&idx=1&sn=6072efba48ed2f9f1968594a1055a3f6&chksm=fb7c9d60cc0b14766e394d5c04f33d5b1c63987d6cf5b66732887e9ffedbbfc576e5a6617891&scene=21#wechat_redirect">数据库：系统设计的核心</a></p><h2 id="图解系列"><a href="#图解系列" class="headerlink" title="图解系列"></a>图解系列</h2><p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzU0NDMzMjY5Ng==&mid=2247488260&idx=1&sn=89701a38ab8af1c670b432b5e7bedf2d&chksm=fb7c9df3cc0b14e52a043999e59b5c1251c3183a61b8c9d35777f237d1478c07b7d01352346e&scene=21#wechat_redirect">系统设计中的缓存技术：完整指南</a></p><p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzU0NDMzMjY5Ng==&mid=2247488165&idx=1&sn=2c4aaad53e6ca87f61e23dfba2fd8f9e&chksm=fb7c9c52cc0b1544266bb7e008f55bfbaa9b2acdb512eb07beece554e9f766e80f12699208b7&scene=21#wechat_redirect">关系数据库的全景图</a></p><p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzU0NDMzMjY5Ng==&mid=2247487961&idx=1&sn=f1437b130e1828f4c1c0c45806e4922f&chksm=fb7c9f2ecc0b1638cf34322599d4bd42c002bf2e37c642d9dbc596366f91f237f410b4e90fc5&scene=21#wechat_redirect">Redis 全景解析</a></p><p>当然架构设计、全景图解系列还有很多,快来关注一起学习吧~</p>]]></content>
      
      
      <categories>
          
          <category> 系统设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 系统设计,计算机层次结构,硬件优化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分片并不意味着分布式</title>
      <link href="2023/12/03/systemDesign-shard/"/>
      <url>2023/12/03/systemDesign-shard/</url>
      
        <content type="html"><![CDATA[<p>Sharding（分片）是一种将数据和负载分布到多个独立的数据库实例的技术。这种方法通过将原始数据集分割为分片来利用水平可扩展性，然后将这些分片分布到多个数据库实例中。</p><p><img src="/uploads/1*yg3PV8O2RO4YegyiYeiItA.png" alt="1*yg3PV8O2RO4YegyiYeiItA.png"></p><p>但是，尽管”分布”一词出现在分片的定义中，但分片数据库并不是分布式数据库。</p><span id="more"></span><h2 id="分片解决方案"><a href="#分片解决方案" class="headerlink" title="分片解决方案"></a>分片解决方案</h2><p>每个分片解决方案在其架构中都有一个关键组件。该组件可以有各种名称，包括协调器、路由器或导演：</p><p><img src="/uploads/1*kp39_8mQ0E9bIO0Lw3PGFw.png" alt="1*kp39_8mQ0E9bIO0Lw3PGFw.png"></p><p>协调器是唯一一个知道数据分布的组件。它将客户端请求映射到特定的分片，然后转发到相应的数据库实例。这就是为什么客户端必须始终通过协调器路由其请求的原因。</p><p>例如，如果客户端想要将新记录插入到<code>Car</code>表中，请求首先会传递到协调器。协调器将记录的主键映射到其中一个分片，然后将请求转发到负责该分片的数据库实例。</p><p><img src="/uploads/1*YNUB6y8WJnp0CCVAXSjQ0g.png" alt="1*YNUB6y8WJnp0CCVAXSjQ0g.png"></p><p>在上面的示意图中，首先，协调器将键<code>121</code>映射到分片<code>10</code>，然后将记录插入到存储在拥有分片<code>10</code>的数据库实例上的表<code>car_10</code>中。</p><p>然而，还有一个问题：为什么在分片解决方案中需要协调器呢？答案很直接。分片存储在设计用于单服务器部署的数据库实例上。</p><p><em>这些数据库实例不相互通信，也不支持任何能促进这种通信的协议。它们彼此不知道，存在于各自的隔离环境中，对于它们是一个更大系统的一部分这一事实毫不知情。</em></p><p>因此，在分片解决方案中，协调器是不可或缺的。如果您有兴趣更深入地了解分片数据库架构，请考虑探索用于PostgreSQL的CitusData或Azure CosmosDB，用于MySQL的Vitess，用于Oracle的Distributed Autonomous Database以及MongoDB Sharded Cluster。</p><h2 id="分布式数据库"><a href="#分布式数据库" class="headerlink" title="分布式数据库"></a>分布式数据库</h2><p>与分片数据库解决方案类似，分布式数据库也使用类似的分片技术在数据库节点群集中分发数据和负载。但是，与分片解决方案不同，分布式数据库不依赖于协调器组件。</p><p><strong>分布式数据库建立在共享无关架构上</strong>，没有像协调器这样的单一组件负担着做出许多决策：</p><p><img src="/uploads/1*deOgcXccWs9lKUSgLPNOww.png" alt="1*deOgcXccWs9lKUSgLPNOww.png"></p><p><em>集群中的所有节点都知道对方，因此也知道数据的分布。通过直接通信，每个节点可以将客户端请求路由到适当的分片所有者。此外，它们可以执行和协调多节点事务。当扩展到更多节点时，集群会自动重新平衡和分割分片。节点保持数据的冗余副本（基于配置的复制因子），即使某些节点失败，也可以继续操作而无需停机。</em></p><p>所有这些对于客户端来说是透明的，客户端只需与任何节点建立连接，然后允许该节点管理分布式方面。</p><p>例如，客户端可能连接到<code>node1</code>并插入具有id<code>121</code>的新的<code>Car</code>记录。如果<code>node1</code>是记录分片的所有者，则它将在本地存储记录，并使用共识算法将更改复制到其他节点的子集。如果不是，<code>node1</code>将记录转发到分片的所有者，可能是<code>node4</code>。</p><p><img src="/uploads/1*weEdq2BxIpf6GiLjipns5Q.png" alt="1*weEdq2BxIpf6GiLjipns5Q.png"></p><p>如果您有兴趣探索真正分布式数据库的架构，请考虑研究Google Spanner，YugabyteDB，CockroachDB，Apache Cassandra或Apache Ignite。</p><p>在数据库领域，分片和分布经常被混为一谈，但它们有着不同的目的。</p><p>虽然分片涉及将数据分割到多个独立的实例中，但这并不意味着系统本质上是分布式的。分片解决方案中协调器的存在，该协调器指导客户端请求到适当的分片，突显了这一区别。</p><p>另一方面，建立在共享无关架构上的分布式数据库缺乏这种集中式协调器。这些系统中的节点都知道对方，管理数据分布，并无缝处理客户端请求。</p><p>这两种架构都有其优点，了解它们的细微差别对于进行数据库设计和选择至关重要。</p><h2 id="系统设计概念系列文章"><a href="#系统设计概念系列文章" class="headerlink" title="系统设计概念系列文章"></a>系统设计概念系列文章</h2><p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzU0NDMzMjY5Ng==&mid=2247488478&idx=1&sn=351b322c2089d8fd7124cf801e0a0524&chksm=fb7c9d29cc0b143facd8d62fb15812d6d28e22749e1183c48d6946dbd13d2e206cd9826bfb20&scene=21#wechat_redirect">计算机的层次化架构</a></p><p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzU0NDMzMjY5Ng==&mid=2247488411&idx=1&sn=2520f364a171f0d747a855600c99cc4b&chksm=fb7c9d6ccc0b147a44627a8eef07b5772acbda406ce566afe306ed2b3c98f665e05c12b6ad36&scene=21#wechat_redirect">每个开发者都应该知道的7个原则</a></p><p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzU0NDMzMjY5Ng==&mid=2247488409&idx=1&sn=a02b97d71d301be4200ab25e4ffad0bc&chksm=fb7c9d6ecc0b1478f85986554735e307e2c92d45236f241dec44a529e9c799c521d5448f9f9a&scene=21#wechat_redirect">6个系统设计的基本概念</a></p><p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzU0NDMzMjY5Ng==&mid=2247488407&idx=1&sn=6072efba48ed2f9f1968594a1055a3f6&chksm=fb7c9d60cc0b14766e394d5c04f33d5b1c63987d6cf5b66732887e9ffedbbfc576e5a6617891&scene=21#wechat_redirect">数据库：系统设计的核心</a></p><h2 id="图解系列"><a href="#图解系列" class="headerlink" title="图解系列"></a>图解系列</h2><p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzU0NDMzMjY5Ng==&mid=2247488260&idx=1&sn=89701a38ab8af1c670b432b5e7bedf2d&chksm=fb7c9df3cc0b14e52a043999e59b5c1251c3183a61b8c9d35777f237d1478c07b7d01352346e&scene=21#wechat_redirect">系统设计中的缓存技术：完整指南</a></p><p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzU0NDMzMjY5Ng==&mid=2247488165&idx=1&sn=2c4aaad53e6ca87f61e23dfba2fd8f9e&chksm=fb7c9c52cc0b1544266bb7e008f55bfbaa9b2acdb512eb07beece554e9f766e80f12699208b7&scene=21#wechat_redirect">关系数据库的全景图</a></p><p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzU0NDMzMjY5Ng==&mid=2247487961&idx=1&sn=f1437b130e1828f4c1c0c45806e4922f&chksm=fb7c9f2ecc0b1638cf34322599d4bd42c002bf2e37c642d9dbc596366f91f237f410b4e90fc5&scene=21#wechat_redirect">Redis 全景解析</a></p><p>当然架构设计、全景图解系列还有很多,快来关注一起学习吧~</p>]]></content>
      
      
      <categories>
          
          <category> 数据库分片 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 系统设计,数据库分片,分片技术 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>生产就绪应用程序架构的高层次概述</title>
      <link href="2023/11/26/systemDesign-web/"/>
      <url>2023/11/26/systemDesign-web/</url>
      
        <content type="html"><![CDATA[<p>在你使用的每个完美应用程序背后，都有一整套的架构、测试、监控和安全措施。今天，让我们来看看一个生产就绪应用程序的非常高层次的架构。</p><h2 id="CI-CD-管道"><a href="#CI-CD-管道" class="headerlink" title="CI/CD 管道"></a>CI/CD 管道</h2><p>我们的第一个关键领域是持续集成和持续部署——CI/CD 管道。</p><p>这确保我们的代码从存储库经过一系列测试和管道检查，无需任何手动干预就进入生产服务器。</p><p><img src="/uploads/1*DIPdJHlAKsQero5qiyM7NQ.png" alt="1*DIPdJHlAKsQero5qiyM7NQ.png"></p><p>它配置了像 Jenkins 或 GitHub Actions 这样的平台，用于自动化我们的部署流程。</p><span id="more"></span><h2 id="与服务器的交互"><a href="#与服务器的交互" class="headerlink" title="与服务器的交互"></a>与服务器的交互</h2><p>一旦我们的应用程序投入生产，它就必须处理大量用户请求。这由我们的负载均衡器和反向代理（如 Nginx）管理。</p><p><img src="/uploads/1*Gm7GMJvVh-dVdT6C07eMsw.png" alt="1*Gm7GMJvVh-dVdT6C07eMsw.png"></p><p>它们确保用户请求均匀分布在多个服务器上，即使在流量激增期间也能保持平稳的用户体验。</p><h2 id="骨干：数据存储和外部-API"><a href="#骨干：数据存储和外部-API" class="headerlink" title="骨干：数据存储和外部 API"></a>骨干：数据存储和外部 API</h2><p>我们的服务器还需要存储数据。为此，我们还有一个不运行在相同生产服务器上的外部存储服务器。相反，它通过网络连接。</p><p><img src="/uploads/1*OHiyw0UFHWRnsQ5XubDTXg.png" alt="1*OHiyw0UFHWRnsQ5XubDTXg.png"></p><p>我们的服务器可能还与其他服务器通信。而且我们可以有多个这样的服务，不仅仅是一个。</p><p><img src="/uploads/1*K0zq-pfcKDYdJCvvEOx4Ow.png" alt="1*K0zq-pfcKDYdJCvvEOx4Ow.png"></p><h2 id="监控、日志和警报：默默的保护者"><a href="#监控、日志和警报：默默的保护者" class="headerlink" title="监控、日志和警报：默默的保护者"></a>监控、日志和警报：默默的保护者</h2><p>为了确保一切运行顺利，我们有日志记录和监控系统，对每个微观交互保持敏锐的关注，存储日志并分析数据。</p><p><img src="/uploads/1*Gz8f6IeZRgPT1AE-fFhzcw.png" alt="1*Gz8f6IeZRgPT1AE-fFhzcw.png"></p><p>将日志存储在外部服务上是一种标准做法，通常不在我们的主要生产服务器上。</p><p>对于后端，像 PM2 这样的工具可以用于日志记录和监控。对于前端，像 Sentry 这样的平台可以用于实时捕获和报告错误。</p><p><img src="/uploads/1*PZ0wV0VYw8EI1zFVmMPn8w.png" alt="1*PZ0wV0VYw8EI1zFVmMPn8w.png"></p><h2 id="警报服务"><a href="#警报服务" class="headerlink" title="警报服务"></a>警报服务</h2><p>当事情不按计划进行时，也就是我们的日志系统检测到失败的请求或异常时？</p><p>首先，它通知我们的警报服务。之后，推送通知被发送，以保持用户的知情。从一般的“出现问题了”到具体的“支付失败”，有效的沟通确保用户不会被置于黑暗中，培养了信任和可靠性。</p><p><img src="/uploads/1*dbccl16Pm4c4SpKS_D3dCg.png" alt="1*dbccl16Pm4c4SpKS_D3dCg.png"></p><p>现代做法是将这些警报直接集成到我们常用的平台中，如 Slack。</p><p><img src="/uploads/1*iJ0jseZ7PLHyqGC2EgVb0Q.png" alt="1*iJ0jseZ7PLHyqGC2EgVb0Q.png"></p><p>想象一下一个专门的 Slack 频道，警报在问题出现的瞬间弹出。这使开发人员几乎可以立即采取行动，在问题升级之前解决根本原因。</p><h2 id="在生产环境中调试"><a href="#在生产环境中调试" class="headerlink" title="在生产环境中调试"></a>在生产环境中调试</h2><p>之后，开发人员必须调试问题。</p><p><strong>日志查看：</strong>首先，需要识别问题。我们之前提到的那些日志？它们是我们首选的工具。开发人员通过它们筛选，寻找可能指向问题源的模式或异常。</p><p><img src="/uploads/1*vECE_pDLSK_BNBTb1nUiZA.png" alt="1*vECE_pDLSK_BNBTb1nUiZA.png"></p><p><strong>在安全环境中复制：</strong>黄金法则是——<em>永远不要直接在生产环境中调试。</em>相反，开发人员在‘staging’或‘test’环境中重新创建问题。这确保用户不会受到调试过程的影响。</p><p><img src="/uploads/1*0PgaONmKlvOJpC9RY3rYPQ.png" alt="1*0PgaONmKlvOJpC9RY3rYPQ.png"></p><p>开发人员使用工具来查看运行中的应用程序并开始调试。</p><p><strong>热修复：</strong>一旦错误修复，就会推出‘hotfix’。这是一个快速的、临时的修复，旨在让事情再次运行起来。这就像在更永久的解决方案可以实施之前的一个补丁。</p><p><img src="/uploads/1*3OMXgA7h80Q4hkMNoPkwzw.png" alt="1*3OMXgA7h80Q4hkMNoPkwzw.png"></p><h2 id="系统设计概念系列文章"><a href="#系统设计概念系列文章" class="headerlink" title="系统设计概念系列文章"></a>系统设计概念系列文章</h2><p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzU0NDMzMjY5Ng==&mid=2247488478&idx=1&sn=351b322c2089d8fd7124cf801e0a0524&chksm=fb7c9d29cc0b143facd8d62fb15812d6d28e22749e1183c48d6946dbd13d2e206cd9826bfb20&scene=21#wechat_redirect">计算机的层次化架构</a></p><p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzU0NDMzMjY5Ng==&mid=2247488411&idx=1&sn=2520f364a171f0d747a855600c99cc4b&chksm=fb7c9d6ccc0b147a44627a8eef07b5772acbda406ce566afe306ed2b3c98f665e05c12b6ad36&scene=21#wechat_redirect">每个开发者都应该知道的7个原则</a></p><p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzU0NDMzMjY5Ng==&mid=2247488409&idx=1&sn=a02b97d71d301be4200ab25e4ffad0bc&chksm=fb7c9d6ecc0b1478f85986554735e307e2c92d45236f241dec44a529e9c799c521d5448f9f9a&scene=21#wechat_redirect">6个系统设计的基本概念</a></p><p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzU0NDMzMjY5Ng==&mid=2247488407&idx=1&sn=6072efba48ed2f9f1968594a1055a3f6&chksm=fb7c9d60cc0b14766e394d5c04f33d5b1c63987d6cf5b66732887e9ffedbbfc576e5a6617891&scene=21#wechat_redirect">数据库：系统设计的核心</a></p><h2 id="图解系列"><a href="#图解系列" class="headerlink" title="图解系列"></a>图解系列</h2><p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzU0NDMzMjY5Ng==&mid=2247488260&idx=1&sn=89701a38ab8af1c670b432b5e7bedf2d&chksm=fb7c9df3cc0b14e52a043999e59b5c1251c3183a61b8c9d35777f237d1478c07b7d01352346e&scene=21#wechat_redirect">系统设计中的缓存技术：完整指南</a></p><p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzU0NDMzMjY5Ng==&mid=2247488165&idx=1&sn=2c4aaad53e6ca87f61e23dfba2fd8f9e&chksm=fb7c9c52cc0b1544266bb7e008f55bfbaa9b2acdb512eb07beece554e9f766e80f12699208b7&scene=21#wechat_redirect">关系数据库的全景图</a></p><p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzU0NDMzMjY5Ng==&mid=2247487961&idx=1&sn=f1437b130e1828f4c1c0c45806e4922f&chksm=fb7c9f2ecc0b1638cf34322599d4bd42c002bf2e37c642d9dbc596366f91f237f410b4e90fc5&scene=21#wechat_redirect">Redis 全景解析</a></p><p>当然架构设计、全景图解系列还有很多,快来关注一起学习吧~</p>]]></content>
      
      
      <categories>
          
          <category> 持续集成,系统设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 持续集成,系统设计 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kafka 在分布式系统中八个使用场景</title>
      <link href="2023/11/19/kafka-kafka/"/>
      <url>2023/11/19/kafka-kafka/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Kafka 最初是为大规模日志处理而构建的。它会保留消息直到过期，并允许消费者以自己的速度拉取消息。与其前身不同，Kafka 不仅仅是一个消息队列，它是一个适用于各种情况的开源事件流平台。让我们回顾一下流行的 Kafka 使用案例。</p></blockquote><h2 id="1-日志处理和分析"><a href="#1-日志处理和分析" class="headerlink" title="1. 日志处理和分析"></a>1. 日志处理和分析</h2><ul><li>下图显示了一个典型的 ELK（Elastic-Logstash-Kibana）堆栈。Kafka高效地收集来自每个实例的日志流。</li><li>ElasticSearch 从 Kafka 消耗日志并对其进行索引。Kibana 在 ElasticSearch 之上提供了搜索和可视化界面。</li></ul><p><img src="/uploads/1*kTAkXkIs0mD7zrkuZA7Ocg.png" alt="1*kTAkXkIs0mD7zrkuZA7Ocg.png"></p><span id="more"></span><h2 id="2-推荐中的数据流"><a href="#2-推荐中的数据流" class="headerlink" title="2. 推荐中的数据流"></a>2. 推荐中的数据流</h2><ul><li>像亚马逊这样的电子商务网站使用过去的行为和类似的用户来计算产品推荐。</li><li>下图显示了推荐系统的工作原理。Kafka 会流式传输原始的点击流数据，Flink 对其进行处理，模型训练从数据湖中消耗聚合数据。</li><li>这允许不断改进每个用户的推荐相关性。另一个伟大的 Kafka 使用案例是实时点击流分析。</li></ul><p><img src="/uploads/1*3luo79062OAw-yPYMnSTjQ.png" alt="1*3luo79062OAw-yPYMnSTjQ.png"></p><h2 id="3-系统监控和警报"><a href="#3-系统监控和警报" class="headerlink" title="3. 系统监控和警报"></a>3. 系统监控和警报</h2><ul><li>与日志分析系统类似，我们需要收集用于监控和故障排除的系统度量信息。</li><li>不同之处在于度量数据是结构化数据，而日志是非结构化文本。度量数据被发送到 Kafka 并在 Flink 中进行聚合。聚合后的数据被实时监控仪表板和警报系统（例如 PagerDuty）消耗。</li></ul><p><img src="/uploads/1*1JdHcMKoYmk17tspT76zTg.png" alt="1*1JdHcMKoYmk17tspT76zTg.png"></p><h2 id="4-CDC（变更数据捕获）"><a href="#4-CDC（变更数据捕获）" class="headerlink" title="4. CDC（变更数据捕获）"></a>4. CDC（变更数据捕获）</h2><ul><li>变更数据捕获（CDC）将数据库更改流式传输到其他系统以进行复制或缓存/索引更新。</li><li>Kafka 也是构建数据管道的强大工具，这意味着您可以使用它从各种来源摄取数据，应用处理规则，并将数据存储在数据仓库、数据湖或数据网格中。</li><li>例如，在下图中，交易日志被发送到 Kafka，并由 ElasticSearch、Redis 和辅助数据库摄取。</li></ul><p><img src="/uploads/1*GeYyb7RDExgEjom9DyC5UA.png" alt="1*GeYyb7RDExgEjom9DyC5UA.png"></p><h2 id="5-系统迁移"><a href="#5-系统迁移" class="headerlink" title="5. 系统迁移"></a>5. 系统迁移</h2><ul><li>升级旧服务具有挑战性 —— 旧的编程语言、复杂的逻辑和缺乏测试。我们可以通过利用消息中间件来减轻风险。</li><li>在下图中，为了升级下图中的订单服务，我们更新了传统的订单服务以消耗 Kafka 的输入并将结果写入 ORDER 主题。新订单服务消耗相同的输入并将结果写入 ORDERNEW 主题。</li><li>对账服务比较 ORDER 和 ORDERNEW。如果它们相同，新服务会通过测试。</li></ul><p><img src="/uploads/1*A-ZEA4YCeZT5Mpk5VkeZwg.png" alt="1*A-ZEA4YCeZT5Mpk5VkeZwg.png"></p><h2 id="6-事件溯源"><a href="#6-事件溯源" class="headerlink" title="6. 事件溯源"></a>6. 事件溯源</h2><ul><li>如果将事件作为系统中的第一类公民（即，真实来源）来处理，那么存储应用程序状态就是一系列事件，系统中的其他所有内容都可以从这些持久且不可变的事件中重新计算。</li><li>事件溯源就是关于以事件序列捕获状态更改。公司通常将 Kafka 作为他们的主要事件存储。在出现任何故障、回滚或需要重建状态的情况下，您只需随时重新应用来自 Kafka 的事件。</li></ul><h2 id="7-消息传递"><a href="#7-消息传递" class="headerlink" title="7. 消息传递"></a>7. 消息传递</h2><ul><li>Kafka 最好且最常见的用例之一是作为消息队列。Kafka 为您提供了一个可靠且可扩展的消息队列，可以处理大量数据。</li><li>我们可以将消息组织成“主题”，这意味着您将每条消息发布到一个特定的主题，而在另一侧，消费者将订阅一个或多个主题，并从中消费消息。</li><li>微服务之间解耦通信的最大优势在于，您可以随时将新服务添加到这些事件中，而不会增加系统的复杂性或不得不更改任何源代码。</li></ul><h2 id="8-提交日志"><a href="#8-提交日志" class="headerlink" title="8. 提交日志"></a>8. 提交日志</h2><ul><li>Kafka 可以作为分布式系统的一种外部提交日志。这个日志有助于在节点之间复制数据，并充当了失败节点恢复其数据的重新同步机制。</li><li>Kafka 中的日志压缩功能有助于支持此用途。</li></ul><blockquote><p><em>别忘了点击“掌声”和“关注”按钮，帮助我撰写更多类似的文章。</em></p></blockquote><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a target="_blank" rel="noopener" href="https://www.confluent.io/learn/apache-kafka-benefits-and-use-cases/">Apache Kafka 的优势和使用案例</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> kafka,系统设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka,系统设计,网络技术 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>软件工程师的关键原则-18个系统设计概念</title>
      <link href="2023/11/11/systemDesign-concept/"/>
      <url>2023/11/11/systemDesign-concept/</url>
      
        <content type="html"><![CDATA[<h1 id=""><a href="#" class="headerlink" title=""></a></h1><p><img src="https://res.craft.do/user/full/c4fcd313-f319-c77e-e1f2-f4caca9f2c87/doc/4A23BC2F-F18E-4384-96A0-CC28554D239A/75A77844-2DB2-4BB0-B17C-298A9D960897_2/mQBuMRK0FskOtnkEZYLfl2U4RmQTCze1yiF3qmEtHx0z/WeChat49289609a91e7d7c0e32077538409d13.png" alt="WeChat49289609a91e7d7c0e32077538409d13.png"></p><p>要在系统设计中脱颖而出，深刻理解诸如<strong>负载均衡</strong>、<strong>缓存</strong>、<strong>分区</strong>、<strong>复制</strong>、<strong>数据库</strong>和<strong>代理</strong>等基本系统设计概念至关重要。</p><p>在掌握这个主模板的基础上，我们将讨论18个重要的系统设计概念。以下是每个概念的简要描述：</p><h3 id="1-域名系统-DNS"><a href="#1-域名系统-DNS" class="headerlink" title="1. 域名系统 (DNS)"></a>1. 域名系统 (DNS)</h3><p>域名系统（DNS）是互联网基础设施的一个基本组成部分，将用户友好的域名转换为其相应的IP地址。它充当了互联网的电话簿，允许用户通过输入易于记忆的域名而不是计算机用于识别彼此的数值IP地址（如“192.0.2.1”）来访问网站和服务。</p><p>当您在Web浏览器中输入域名时，DNS负责查找相关的IP地址并将您的请求发送到适当的服务器。这个过程从您的计算机向递归解析器发送查询开始，然后递归解析器搜索一系列DNS服务器，从根服务器开始，然后是顶级域（TLD）服务器，最终是权威域名服务器。一旦找到IP地址，递归解析器将其返回给您的计算机，允许您的浏览器与目标服务器建立连接并访问所需的内容。</p><span id="more"></span><p><img src="https://res.craft.do/user/full/c4fcd313-f319-c77e-e1f2-f4caca9f2c87/doc/4A23BC2F-F18E-4384-96A0-CC28554D239A/E422D047-3CF9-44FC-8485-DC0691A0D20F_2/BHwIE9I3p9Zq4obdSxwyhvPpxnyDaKy52K8lkxH15JIz/WeChat49853bf56d5a9f0c3582bd606f58336a.png" alt="WeChat49853bf56d5a9f0c3582bd606f58336a.png"></p><p><strong>DNS</strong></p><h3 id="2-负载均衡器"><a href="#2-负载均衡器" class="headerlink" title="2. 负载均衡器"></a>2. 负载均衡器</h3><p>负载均衡器是一种用于分发入站网络流量到多个服务器的网络设备或软件，以确保最佳资源利用、降低延迟并保持高可用性。在出现突发流量或服务器请求不均匀分布的情况下，负载均衡器在扩展应用程序和有效管理服务器工作负载方面发挥着至关重要的作用。</p><p>负载均衡器使用各种算法来确定入站流量的分发。一些常见的算法包括：</p><p>•<strong>轮询算法:</strong> 请求按顺序和均匀地分配到所有可用服务器。•<strong>最少连接算法:</strong> 负载均衡器将请求分配给具有最少活动连接的服务器，为较不繁忙的服务器提供优先。•<strong>IP哈希算法:</strong> 客户端的IP地址被哈希，生成的值用于确定请求应该被定向到哪个服务器。这种方法确保特定客户端的请求一直路由到相同的服务器，有助于维护会话一致性。</p><p><img src="https://res.craft.do/user/full/c4fcd313-f319-c77e-e1f2-f4caca9f2c87/doc/4A23BC2F-F18E-4384-96A0-CC28554D239A/CC0B4F86-331E-4864-98DE-240A50A68478_2/Q6ehJ8vV27Zplx3vzY8oxZAfcznDjsxBVrIghyNhHyUz/WeChatff70f6ceea4bec786b6b65a93e59d09d.png" alt="WeChatff70f6ceea4bec786b6b65a93e59d09d.png"></p><p><strong>负载均衡器</strong></p><h3 id="3-API-网关"><a href="#3-API-网关" class="headerlink" title="3. API 网关"></a>3. API 网关</h3><p>API网关是一种充当外部客户端与应用程序的内部微服务或基于API的后端服务之间中间件的服务器或服务。它是当今体</p><p>系结构的重要组件，特别是在基于微服务的系统中，它简化了通信过程，为客户端提供访问各种服务的单一入口点。</p><p>API网关的主要功能包括：</p><p>1.请求路由：API网关根据预定义的规则和配置，将来自客户端的传入API请求路由到适当的后端服务或微服务。2.身份验证和授权：API网关管理用户身份验证和授权，确保只有经授权的客户端才能访问服务。它在将请求路由到后端服务之前验证API密钥、令牌或其他凭证。3.速率限制和节流：为了保护后端服务免受过大的负荷或滥用，API网关根据预定义的策略对客户端的请求进行速率限制或节流。4.缓存：为了降低延迟和后端负载，API网关缓存经常使用的响应，直接提供给客户端，无需查询后端服务。5.请求和响应转换：API网关可以修改请求和响应，例如转换数据格式、添加或删除标头，或更改查询参数，以确保客户端和服务之间的兼容性。</p><p><img src="https://res.craft.do/user/full/c4fcd313-f319-c77e-e1f2-f4caca9f2c87/doc/4A23BC2F-F18E-4384-96A0-CC28554D239A/B3A2CE16-8EC9-430C-9695-C2842A3D1D37_2/w37rfBPqalyxb7DI52yfi0j4vKFXC3pij31Cjy4qyD8z/WeChat22f909aa70c05447c174ad79acff2b14.png" alt="WeChat22f909aa70c05447c174ad79acff2b14.png"></p><p><strong>API 网关</strong></p><h3 id="4-内容交付网络-CDN"><a href="#4-内容交付网络-CDN" class="headerlink" title="4. 内容交付网络 (CDN)"></a>4. 内容交付网络 (CDN)</h3><p>内容交付网络（CDN）是一个分布式服务器网络，用于存储和传递内容，如图像、视频、样式表和脚本，以使用户可以从地理位置更接近他们的位置访问这些内容。CDN旨在提高内容传递的性能、速度和可靠性，无论用户相对于原始服务器的位置如何。以下是CDN的运作方式：</p><p>1.当用户从网站或应用程序请求内容时，请求被定向到最近的CDN服务器，也称为边缘服务器。2.如果边缘服务器已经缓存了请求的内容，它将直接向用户提供内容。这个过程减少了延迟并提高了用户体验，因为内容传输的距离更短。3.如果边缘服务器没有缓存请求的内容，CDN将从原始服务器或附近的另一个CDN服务器检索内容。一旦内容被获取，它将被缓存在边缘服务器上并提供给用户。4.为了确保内容保持最新，CDN定期检查原始服务器以获取更改，并相应地更新其缓存。</p><p><img src="https://res.craft.do/user/full/c4fcd313-f319-c77e-e1f2-f4caca9f2c87/doc/4A23BC2F-F18E-4384-96A0-CC28554D239A/8F16CDFA-A6BF-4EF0-B255-1561D5B15668_2/Utyy4u8cXYJw1lMigHqx6kUrxQxY9xf9HEzu4dRzcx4z/WeChatc451501adf104c2494e86bd095b41249.png" alt="WeChatc451501adf104c2494e86bd095b41249.png"></p><p><strong>CDN</strong></p><h3 id="5-正向代理与反向代理"><a href="#5-正向代理与反向代理" class="headerlink" title="5. 正向代理与反向代理"></a>5. 正向代理与反向代理</h3><p>正向代理，也称为“代理服务器”或简称“代理”，是位于一个或多个客户机之前的服务器，充当客户机和互联网之间的中介。当客户机请求互联网上的资源时，请求首先发送到正向代理。正向代理然后代表客户机将请求发送到互联网，然后将</p><p>响应返回给客户机。</p><p>另一方面，反向代理是位于一个或多个Web服务器之前的服务器，充当Web服务器和互联网之间的中介。当客户端请求互联网上的资源时，请求首先发送到反向代理。反向代理然后将请求转发到其中一个Web服务器，然后将响应返回给客户端。</p><p><img src="https://res.craft.do/user/full/c4fcd313-f319-c77e-e1f2-f4caca9f2c87/doc/4A23BC2F-F18E-4384-96A0-CC28554D239A/E81692CA-56E1-40F6-AE65-CAEAC9BCE304_2/oLqKySBKilPBewMwpwsh8h6rlM11KLjM6qChoRMx3yYz/WeChate9fc5329308d7c48fd7180015ca4d82f.png" alt="WeChate9fc5329308d7c48fd7180015ca4d82f.png"></p><p><strong>正向代理与反向代理</strong></p><h3 id="6-缓存"><a href="#6-缓存" class="headerlink" title="6. 缓存"></a>6. 缓存</h3><p>缓存是位于应用程序和原始数据源（如数据库、文件系统或远程Web服务）之间的高速存储层。当应用程序请求数据时，首先检查缓存。如果数据存在于缓存中，将返回给应用程序。如果在缓存中找不到数据，则从其原始来源检索数据，将其存储在缓存中以备将来使用，然后返回给应用程序。在分布式系统中，缓存可以出现在多个位置，包括客户端、DNS、CDN、负载均衡器、API网关、服务器、数据库等等。</p><p><strong>缓存</strong></p><h3 id="7-数据分区"><a href="#7-数据分区" class="headerlink" title="7. 数据分区"></a>7. 数据分区</h3><p>在数据库中，<strong>水平分区</strong>，通常称为<strong>分片</strong>，涉及将表的行分成较小的表，并存储在不同的服务器或数据库实例上。这种方法用于在多个服务器之间分发数据库负载，从而提高性能。</p><p>相反，<strong>垂直分区</strong>涉及将表的列分成单独的表。这个技术旨在减少表中的列数，提高只访问有限数量列的查询性能。</p><p><img src="https://res.craft.do/user/full/c4fcd313-f319-c77e-e1f2-f4caca9f2c87/doc/4A23BC2F-F18E-4384-96A0-CC28554D239A/CEDAB7A3-D6A6-49F8-9EC7-296A481F2ABC_2/pGPAgDIixcrQIS2hbMg1ay7mbfF3vBHxtepOyOuZeKUz/WeChateeefc7380c587916ff83aa5921aa6418.png" alt="WeChateeefc7380c587916ff83aa5921aa6418.png"></p><p><strong>数据分区</strong></p><h3 id="8-数据库复制"><a href="#8-数据库复制" class="headerlink" title="8. 数据库复制"></a>8. 数据库复制</h3><p>数据库复制是一种用于在不同服务器或位置之间维护相同数据库的方法。数据库复制的主要目标是增加数据的可用性、冗余和容错性，以确保系统即使在硬件故障或其他问题出现时仍然可以正常运行。</p><p>在复制数据库配置中，一个服务器充当主数据库，而其他服务器则充当副本。这涉及在主数据库和副本之间同步数据，以确保它们都具有相同的最新信息。数据库复制提供了多个优点，包括：</p><p>1.改进性能：通过在多个副本之间分发读查询，可以减轻主数据库的负载，从而提高查询响应时间。2.高可用性：如果主数据库发生故障或停机，副本可以继续提供数据，确保对应用程序的不间断访问。3.增强的数据保护：在不同位置维护数据库的多个副本有助于防止由于硬件故障或其他灾难而导致的数据丢失。4.负载平衡：副本可以处理读查询，从而实现更好的负载分配并减轻主数据库的整体压力。</p><h3 id="9-分布式消息系统"><a href="#9-分布式消息系统" class="headerlink" title="9. 分布式消息系统"></a>9. 分布式消息系统</h3><p>分布式消息系统为多个可能分布在不同地理位置的应用程序、服务或组件之间交换消息提供了可靠、可扩展和容错的方式。这些系统通过解耦发送方和接收方组件，使它们能够独立开发和运行。分布式消息系统在大型或复杂系统中尤其有价值，比如微服务架构或分布式计算环境中。这些系统的示例包括Apache Kafka和RabbitMQ。</p><h3 id="10-微服务"><a href="#10-微服务" class="headerlink" title="10. 微服务"></a>10. 微服务</h3><p>微服务代表一种架构风格，其中一个应用程序被组织成一组小型、松散耦合的、可以独立部署的服务。每个微服务负责应用程序内的特定功能或领域，并通过明确定义的API与其他微服务通信。这种方法不同于传统的单体架构，传统单体架构将应用程序构建为单一、紧密耦合的单元。</p><p>微服务的主要特点包括：</p><p>1.独立部署：每个微服务可以独立开发、测试和部署，无需影响其他微服务。2.技术多样性：每个微服务可以使用不同的技术栈，以满足其特定需求。3.易于维护：由于微服务的规模较小，它们通常更易于维护、扩展和修改。4.可扩展性：可以根据需要扩展单独的微服务，而无需为整个应用程序进行扩展。</p><h3 id="11-数据库"><a href="#11-数据库" class="headerlink" title="11. 数据库"></a>11. 数据库</h3><p>数据库是一种结构化数据的持久存储系统，用于存储、检索和管理数据。数据库在各种应用程序和系统中都有广泛的应用，从基本的数据存储到复杂的分析和报告系统。主要的数据库类型包括：</p><p>•<strong>关系型数据库（RDBMS）：</strong> 使用表格结构来存储数据，并支持SQL查询语言。常见的关系型数据库包括MySQL、PostgreSQL、Oracle和Microsoft SQL Server。•<strong>NoSQL数据库：</strong> 这些数据库不使用传统的表格结构，而使用文档、列族、键值对或图形等非关系数据结构来存储数据。NoSQL数据库包括MongoDB、Cassandra、Redis和Elasticsearch。•<strong>NewSQL数据库：</strong> 这是一种中间方式，结合了关系数据库和NoSQL数据库的某些特性。NewSQL数据库旨在提供可扩展性、高性能和分布式能力。</p><h3 id="12-前端缓存"><a href="#12-前端缓存" class="headerlink" title="12. 前端缓存"></a>12. 前端缓存</h3><p>前端缓存是一种用于缓存Web应用程序的用户界面（HTML、CSS、JavaScript等）以提高性能的技术。前端缓存可以通过减少从服务器请求资源的次数、降低延迟并提供更快的用户体验来改进Web应用程序的性能。前端缓存通常采用浏览器缓存、CDN和缓存服务等多种形式。</p><h3 id="13-后端缓存"><a href="#13-后端缓存" class="headerlink" title="13. 后端缓存"></a>13. 后端缓存</h3><p>后端缓存是一种用于缓存应用程序的数据和计算结果以提高性能的技术。它将数据存储在内存中，以便将来更快地检索。后端缓存通常用于存储数据库查询结果、API响应和计算密集型任务的结果。一些常见的后端缓存技术包括Redis和Memcached。</p><h3 id="14-安全性"><a href="#14-安全性" class="headerlink" title="14. 安全性"></a>14. 安全性</h3><p>安全性是系统设计中至关重要的概念。它包括身份验证、授权、加密、跨站脚本（XSS）和跨站请求伪造（CSRF）防护、数据保护、网络安全等。系统设计应考虑各种威胁和安全攻击，以确保系统的数据和用户得到保护。</p><h3 id="15-高可用性与容错性"><a href="#15-高可用性与容错性" class="headerlink" title="15. 高可用性与容错性"></a>15. 高可用性与容错性</h3><p>高可用性和容错性是系统设计的关键目标。高可用性涉及确保系统在面临故障或中断时保持可用。容错性涉及系统在出现故障或错误时能够恢复正常运行。实现高可用性和容错性通常需要使用负载均衡、故障转移、冗余和监控等技术。</p><h3 id="16-事件驱动架构"><a href="#16-事件驱动架构" class="headerlink" title="16. 事件驱动架构"></a>16. 事件驱动架构</h3><p>事件驱动架构是一种应用程序架构，其中应用程序的不同组件通过事件进行通信。事件是应用程序中发生的特定动作或状态更改，可以触发其他组件的响应。事件驱动架构通常用于实现松散耦合的组件，以便能够更轻松地扩展和修改系统。</p><h3 id="17-日志和监控"><a href="#17-日志和监控" class="headerlink" title="17. 日志和监控"></a>17. 日志和监控</h3><p>在系统设计中，日志和监控是关键工具，用于识别和解决性能问题、故障和安全问题。日志记录有助于跟踪系统的操作和问题，而监控则提供了实时的性能数据和警报。在分布式系统中，有效的日志和监控可以帮助工程师快速诊断问题和优化系统。</p><h3 id="18-测试策略"><a href="#18-测试策略" class="headerlink" title="18. 测试策略"></a>18. 测试策略</h3><p>测试是系统设计和开发的关键组成部分。测试策略涉及确定测试范围、创建测试计划、编写测试用例、执行测试、自动化测试、性能测试等。有效的测试策略有助于确保系统的可靠性、性能和安全性。</p><p>这18个系统设计概念涵盖了构建可伸缩、高性能、高可用性和安全的系统所需的核心知识。</p><p>希望这篇文章对你有所帮助,没有浪费你的时间~</p>]]></content>
      
      
      <categories>
          
          <category> 系统设计,网络技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CDN,系统设计,网络技术 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CDN初学者指南：是什么以及如何工作</title>
      <link href="2023/10/22/systemDesign-cdn/"/>
      <url>2023/10/22/systemDesign-cdn/</url>
      
        <content type="html"><![CDATA[<p>内容交付网络（Content Delivery Network，CDN）是一种分布式服务器系统，旨在根据用户的地理位置提供网络内容。CDN的目标是减少加载时间、提高网站和在线应用程序性能。</p><p>当用户请求网页时，内容将通过距离最近的CDN服务器提供，而不是源服务器，即使源服务器可能位于用户数千英里之外。这样做可以显著加快加载时间，改善用户体验，并有助于提高搜索引擎排名，同时减少跳失率。此外，CDN还有助于减轻服务器过载风险，降低源服务器的负载。它通过在CDN服务器上缓存和存储经常访问的内容来实现。当源服务器面临高流量时，CDN服务器可提供缓存内容，防止源服务器超负荷和崩溃。此外，CDN还提供强化安全性，CDN提供商会提供DDoS防护和SSL加密，以保护内容交付过程并防止网络攻击对网站的威胁。</p><p>CDN对搜索引擎优化（SEO）至关重要。因为CDN提高了网站性能，因此页面加载速度更快，而这是搜索引擎排名的重要因素。例如，谷歌在对搜索结果页面排名时会考虑网站速度。</p><p><img src="https://res.craft.do/user/full/b313a1ab-3121-84d1-2506-d702b5c0ba9c/AD587214-47A6-4835-A618-4F5E56903CDD_2/7jJNHzE4eSyR3usN4yFyqRRsKhN7lnSVXezCvzVwVhUz/1rWNmcNuFktISaLlLw8EIWQ.png" alt="CDN图片"></p><p><strong>CDN速查表</strong></p><span id="more"></span><p>CDN有几种类型，包括：</p><h2 id="传统CDN"><a href="#传统CDN" class="headerlink" title="传统CDN"></a>传统CDN</h2><p>传统CDN是最常见的CDN类型，它基于全球范围内的服务器网络来缓存和传递内容。以下是传统CDN的工作原理：</p><ol><li>用户请求网站内容。</li><li>请求被重定向到最近的DNS服务器，该服务器将域名映射到IP地址并将请求重定向到最近的边缘服务器。</li><li>边缘服务器检查其缓存是否有所请求内容的副本。如果有可用内容，边缘服务器将其传递给用户。</li><li>如果缓存中没有所请求的内容，边缘服务器将请求源服务器检索内容。</li><li>源服务器将内容传递给边缘服务器，并在将来的请求中缓存内容的副本。</li><li>边缘服务器将内容传递给用户。</li><li>下次用户请求相同内容时，请求将被重定向到最近的边缘服务器，该服务器可以直接从其缓存中传递内容，提高性能并减少延迟。</li></ol><h2 id="推送CDN"><a href="#推送CDN" class="headerlink" title="推送CDN"></a>推送CDN</h2><p>推送CDN通过在用户请求之前主动将内容推送到边缘服务器上工作。它通常用于分发软件、大型媒体文件和实时数据（例如股票实时价格）。</p><h2 id="视频CDN"><a href="#视频CDN" class="headerlink" title="视频CDN"></a>视频CDN</h2><p>视频CDN专为传递视频内容而设计，它提供了自适应流媒体和实时转码等功能，对于改善流媒体视频、实时事件、广告插入和视频点播体验非常有用。</p><h2 id="私有CDN"><a href="#私有CDN" class="headerlink" title="私有CDN"></a>私有CDN</h2><p>私有CDN专为满足单个组织的特定需求而设计。与传统CDN不同，私有CDN通常由组织自己拥有和管理，而不是由第三方供应商提供。私有CDN在内容交付安全性、性能优化以及合规性与治理方面非常有用。</p><h1 id="面临的挑战"><a href="#面临的挑战" class="headerlink" title="面临的挑战"></a>面临的挑战</h1><p>尽管CDN具有许多优点，但其实施和使用也面临一些挑战。其中一些挑战包括：</p><ol><li><strong>成本</strong>：CDN服务可能很昂贵，特别对于大型网站或业务，特别是那些流量庞大的网站来说。</li><li><strong>集成</strong>：将CDN与现有网站或应用程序集成可能相当复杂，需要专业技术知识。</li><li><strong>配置</strong>：为特定的网站或应用程序优化CDN的配置需要精心规划和管理。</li><li><strong>内容一致性</strong>：确保在多个CDN节点上的缓存内容保持一致可能具有挑战性。</li><li><strong>安全性</strong>：CDN提供商负责保护其交付的内容，但如果管理不当，它们也可能引入新的安全漏洞。</li></ol><h1 id="边缘计算"><a href="#边缘计算" class="headerlink" title="边缘计算"></a>边缘计算</h1><p>边缘计算，也称为在CDN上计算（Compute on CDN），是一个相对较新的功能，由一些供应商提供。它允许开发人员在CDN的边缘服务器上直接运行无服务器代码。这可以通过减少用户和源服务器之间的往返时间来显著提高Web应用程序的性能和响应能力。</p><p>通过在CDN的边缘服务器上运行代码，开发人员可以在无服务器环境中编写代码，并将其部署以在边缘服务器上运行。该代码可以执行各种任务，例如动态内容生成、API调用和数据处理，而无需将请求发送回源服务器。</p><p>边缘计算对需要实时数据处理或需要从全球各地访问数据的Web应用程序特别有用。它还可以帮助提高Web应用程序的安全性，因为敏感数据可以在边缘服务器上直接处理，而无需发送回源服务器。</p><p>虽然边缘计算是一个强大的功能，但它需要仔细规划和管理，以确保有效使用。开发人员必须了解在边缘服务器上运行代码的限制和挑战，如资源限制和安全风险。通过正确的方法，边缘计算可以显著提高Web应用程序的性能和功能。</p><h1 id="云游戏"><a href="#云游戏" class="headerlink" title="云游戏"></a>云游戏</h1><p>边缘游戏，也称为云游戏，是CDN技术的一个相对较新应用，它允许用户在任何设备上玩游戏，而无需高端游戏硬件或下载。通过边缘游戏，运行现代视频游戏所需的大量处理工作被转移到靠近终端用户的云服务器上。</p><p>使用边缘服务器进行游戏，用户可以在任何有互联网连接的设备上玩高端游戏，而无需在本地设备上安装或更新游戏。游戏在云服务器上运行并实时流式传输到用户设备上。这种方法可以显著提高视频游戏的可访问性和可负担性，消除了需要昂贵的硬件升级和游戏分发成本。</p><p>边缘游戏还有助于游戏开发人员，因为它减少了为不同硬件配置优化游戏的需求。开发人员可以通过在云服务器上运行游戏，确保在其他设备和平台上获得一致和高质量的游戏体验。</p><p>然而，边缘游戏也面临一些挑战和限制。最大的挑战之一是延迟，因为即使是用户输入和游戏响应之间的微小延迟也会对游戏体验产生负面影响。CDN提供商必须仔细管理网络和服务器基础设施，以最小化延迟，确保流畅的游戏体验。</p><p>另一个挑战是带宽，因为流式传输高质量的视频和音频内容需要大量带宽。互联网连接较慢的用户可能会遇到较低质量或中断的游戏体验。CDN提供商正在开发新的技术来优化流式传输质量并减少带宽需求，以解决这个挑战。</p><p>根据其技术、基础设施和功能的不同，不同的云游戏服务可能对延迟和带宽有额外的要求和建议。例如，Nvidia GeForce Now要求最低25 Mbps的带宽以1080p分辨率和60 FPS的速度进行流式传输，并且延迟低于80毫秒。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>CDN是现代互联网应用程序的关键组成部分，对于提供高性能、安全和可访问性的用户体验至关重要。通过减少加载时间、提高性能和提高安全性，CDN将内容更靠近用户，提高了用户体验。</p><p>它的扩展应用，如边缘计算和云游戏，进一步提高了CDN技术的潜力。边缘计算使开发人员能够在CDN的边缘服务器上运行无服务器代码，从而提高应用程序的性能。云游戏将游戏的重要部分移动到云端，使用户能够在任何设备上畅玩高质量的游戏。</p><p>然而，CDN的实施和使用也面临一些挑战，包括成本、集成、配置、内容一致性和安全性等方面。对于边缘计算和云游戏，延迟和带宽是关键挑战，需要仔细的规划和管理。</p><p>综上所述，CDN是一种关键的网络技术，为Web应用程序和内容提供了更快、更可靠和更安全的交付方式，从而提供更好的用户体验。</p>]]></content>
      
      
      <categories>
          
          <category> CDN,系统设计,网络技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CDN,系统设计,网络技术 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>主从复制 (Master-Slave Replication) 在系统设计与网络技术中的应用</title>
      <link href="2023/10/22/systemDesign-replication/"/>
      <url>2023/10/22/systemDesign-replication/</url>
      
        <content type="html"><![CDATA[<p>在数据库复制中，我们创建相同数据库的副本，并将其分布在多个节点（副本）上。然而，在拥有多个副本的情况下，一个问题出现了：如何确保每次写操作后所有数据都传播到所有副本？最常见的解决方案是主从复制，也称为<strong>主动/被动</strong>或<strong>单主复制</strong>。</p><h2 id="什么是主从复制？"><a href="#什么是主从复制？" class="headerlink" title="什么是主从复制？"></a>什么是主从复制？</h2><p>主从复制中有两种类型的节点：主节点和从节点。单个<strong>主节点（Leader）</strong>作为主数据库，而一个或多个<strong>从节点（Follower）</strong>维护主节点数据的副本。</p><ul><li>主节点负责处理写查询，而从节点负责处理读查询。注意：如果需要，主节点也可以执行读查询。</li><li>每当主节点上进行写操作时，它将复制所有数据更改到所有从节点，以保持整个系统中数据的一致性。</li></ul><span id="more"></span><p>整个主从复制的思想如下：</p><ul><li>当客户端要执行写查询时，它们将请求发送到主节点，主节点首先将新数据写入其本地存储。</li><li>当主节点将新数据写入其本地存储时，它还会将数据更改作为复制日志发送给所有从节点。每个从节点通过从主节点接收日志并按照与主节点上处理它们相同的顺序更新其本地副本。</li><li>如果只有一个从数据库可用且它处于脱机状态，则读操作将暂时定向到主数据库，并且一个新的从数据库将取代旧的从数据库。</li><li>如果有多个从数据库可用，则读操作将重定向到其他健康的从数据库，并且新的数据库服务器将取代旧的从数据库。</li><li>如果主数据库处于脱机状态，一个从数据库将被提升为新的主数据库。现在，所有写操作将在新的主数据库上执行，并且一个新的从数据库将立即取代旧的从数据库进行数据复制。<strong>注意：</strong>提升新的主数据库更加复杂，因为从数据库中的数据可能不是最新的。如何更新缺失的数据？我们将在本文后面的部分讨论这个想法。</li></ul><h2 id="主从复制的应用场景"><a href="#主从复制的应用场景" class="headerlink" title="主从复制的应用场景"></a>主从复制的应用场景</h2><p>主从复制适用于读负载较重的情况下，并且需要将读请求分布在多个节点以提高系统性能。由于从节点可以处理读请求，因此它们可以从主节点卸载读流量，并允许主节点专注于处理写请求。</p><ul><li>此体系结构提供容错性，并且即使主节点失败，系统也可以继续运行。</li><li>主从复制在关系型数据库（如MySQL、PostgreSQL和Oracle）以及NoSQL数据库（如MongoDB、Cassandra、RethinkDB、Espresso等）中使用。</li><li>基于领导者的复制不仅局限于数据库。分布式消息代理（如Kafka和RabbitMQ）也使用它来提供高可用的队列。</li></ul><h2 id="同步复制与异步复制配置"><a href="#同步复制与异步复制配置" class="headerlink" title="同步复制与异步复制配置"></a>同步复制与异步复制配置</h2><p>在主从复制中，一个重要的方面是复制是否同步进行或异步进行。为了理解这一点，让我们考虑一个用户在社交媒体网站上更新个人图片的情况：客户端向Leader发送更新请求。一旦Leader收到请求，它会将数据更改转发给Follower。现在，关键问题是：从节点如何更新其数据？</p><p>在同步复制中，客户端在从节点确认更新在所有从节点都已经应用之前会等待Leader的确认。相反，在异步复制中，客户端在所有从节点都已经更新之前就会收到响应。</p><h2 id="同步复制和异步复制的优缺点"><a href="#同步复制和异步复制的优缺点" class="headerlink" title="同步复制和异步复制的优缺点"></a>同步复制和异步复制的优缺点</h2><p><strong>同步复制的缺点：</strong> 如果从节点没有响应（由于崩溃、网络故障或任何其他原因），则写操作无法被处理。</p><p><strong>同步复制的优点：</strong> 从节点保证具有与Leader一致的最新数据副本。如果Leader突然失败，我们可以确保从节点上仍然可用的数据。</p><p><img src="https://res.craft.do/user/full/c4fcd313-f319-c77e-e1f2-f4caca9f2c87/doc/F02E56CC-D70B-4A7E-B6D6-9295DB942209/4BF0271A-63A3-4C4A-B256-BE754C666729_2/7j0bzRjTABcx7ixTaxpftdm9qQkSYmUQCwvP352FuRoz/WeChat225d69a6b8c95b19af86f3cc6489a927.png" alt="WeChat225d69a6b8c95b19af86f3cc6489a927.png"></p><h2 id="异步复制的优点和缺点"><a href="#异步复制的优点和缺点" class="headerlink" title="异步复制的优点和缺点"></a>异步复制的优点和缺点</h2><p><strong>异步复制的缺点：</strong> 如果主节点失败且无法恢复，则尚未复制到从节点的所有写操作都将丢失。这意味着尽管已经向客户端确认，但写操作不保证持久。</p><p><strong>异步复制的优点：</strong> 即使所有从节点都已滞后，Leader仍可以继续处理写入。弱化持久性可能听起来像是一个坏的权衡，但异步复制仍然广泛使用，特别是如果有许多从节点或者它们分布在地理位置上。</p><p><img src="https://res.craft.do/user/full/c4fcd313-f319-c77e-e1f2-f4caca9f2c87/doc/F02E56CC-D70B-4A7E-B6D6-9295DB942209/C0F09C2C-264D-48D5-AA44-BC6B8CFB2A33_2/PWJusoieliKg3LeAG8OPxzCHr08yavfKHz1DmU0U2TUz/WeChat009de4a825bb455eafce982231561b58.png" alt="WeChat009de4a825bb455eafce982231561b58.png"></p><p>总体而言，选择同步复制或异步复制取决于<strong>一致性和性能之间的权衡</strong>。同步复制提供更强的一致性保证，但也可能导致较长的响应时间。另一方面，异步复制提供更快的响应时间</p><p>，但可能会牺牲一致性。</p><h2 id="异步复制中的关键问题"><a href="#异步复制中的关键问题" class="headerlink" title="异步复制中的关键问题"></a>异步复制中的关键问题</h2><ol><li>在异步复制中，如果Leader在失败之前尚未收到所有来自旧Leader的写入，可能会出现问题。当前Leader在新Leader产生后重新加入集群时，可能会出现冲突的写入。关键问题是：这些写</li></ol><p>入应该怎么处理？思考和探索！</p><ol start="2"><li>当用户进行写入时，新数据可能不会立即传达到所有从节点。如果用户在进行写入后立即尝试读取相同数据，从节点可能无法获得该数据，从而导致用户认为他们的数据丢失了。</li></ol><p>为了处理上述情况，一种解决方案是在读取用户可能已修改的某些内容时从Leader读取。否则，从Follower读取。例如，在社交媒体平台上，通常只有用户自己的配置文件是可编辑的。因此，最好总是从Leader读取用户自己的配置文件，从Follower读取其他用户的配置文件。</p><h1 id="一个共同点：半同步复制"><a href="#一个共同点：半同步复制" class="headerlink" title="一个共同点：半同步复制"></a>一个共同点：半同步复制</h1><p>在大多数情况下，复制是非常快速的，对Leader数据库所做的更改会快速传播到Follower。但在某些情况下，复制可能会延迟。例如，如果Follower正在从故障中恢复、系统正在以最大容量运行或节点之间存在网络问题。</p><p>另一方面，同步复制要求Leader数据库在Follower确认接收和存储数据之前阻止所有写操作。如果所有的副本都是同步的，这可能导致显著的延迟和性能问题。如果一个副本脱机，整个系统将受到影响。</p><p>一个很好的解决方案是使用<strong>半同步复制</strong>。在这种设置中，一个Follower被指定为同步，而其他Follower是异步的。这样，同步Follower将实时更新所有数据更改，而所有异步Follower将在后台逐渐更新数据。如果同步Follower出现问题或减慢，可以将异步Follower之一提升为替代。</p><p>这种配置确保至少两个节点（Leader和一个同步Follower）始终拥有最新的数据副本。让我们通过一个示例来理解：假设用户在网站上更新了他们的个人图片，并且有一个Leader和两个Follower。这里同步复制到Follower 1，异步复制到Follower 2。</p><p><img src="https://res.craft.do/user/full/c4fcd313-f319-c77e-e1f2-f4caca9f2c87/doc/F02E56CC-D70B-4A7E-B6D6-9295DB942209/BE8C99E3-3F54-462F-9AA9-1B41350FC0CC_2/UvAMrV5JvGARzWPEx9XY8uPKRZTbDS3Ei9lUQK0FHUYz/WeChatd715d5ec452cfe29fc87d77cc27ba872.png" alt="WeChatd715d5ec452cfe29fc87d77cc27ba872.png"></p><ul><li><strong>对于Follower 1：</strong> Leader等待直到Follower 1确认收到写入，然后向客户端报告成功，并在其他客户端上使写入可见。</li><li><strong>对于Follower 2：</strong> Leader发送消息但不等待来自Follower 2的响应。图示显示Follower 2处理消息之前有显着的延迟。</li></ul><h1 id="在主从复制中设置新的Follower"><a href="#在主从复制中设置新的Follower" class="headerlink" title="在主从复制中设置新的Follower"></a>在主从复制中设置新的Follower</h1><p>假设我们希望增加从节点的数量或替换故障的从节点。我们该如何做呢？如何确保新的从节点拥有主节点准确的数据副本？简单地将数据从主节点复制到新的从节点是不够的，因为客户端正在不断写入数据库。换句话说，标准的数据复制将在不同时间点看到数据库的不同部分。</p><p>一个解决方案是锁定Leader或主数据库以确保在复制过程中的一致性。然而，这种方法将不支持高可用性的目标，因为在复制过程中将使Leader数据库不可用于写入。</p><p>幸运的是，有一种方法可以在没有任何停机的情况下设置新的从节点。以下是步骤：</p><ol><li>在特定时间点对Leader数据库进行<strong>一致性快照</strong>。大多数数据库都有此功能，它允许在不锁定整个数据库的情况下进行一致性快照。</li><li>将快照复制到新的从节点。这样确保新的从节点在快照被拍摄时具有完整且准确的主节点数据副本。</li><li>将从节点连接到Leader，并请求从快照拍摄时起发生的所有数据更改。新的从节点必须将快照与主节点的<strong>复制日志</strong>中的特定位置相关联，以请求从那个点以后的所有数据更改。这个位置在不同的数据库中有不同的名称，例如PostgreSQL中的日志序列号（log sequence number）和MySQL中的binlog coordinates。</li><li>最后，新的从节点将处理自快照以来发生的更改。此过程在新的从节点赶上Leader并能够继续实时处理数据更改时完成。</li></ol><p>设置从节点的实际步骤可能因数据库管理系统（DBMS）的不同而大不相同。在某些系统中，该过程是完全自动化的，而在其他系统中，它可能需要管理员手动执行的多步工作流。</p><h1 id="处理节点故障和宕机"><a href="#处理节点故障和宕机" class="headerlink" title="处理节点故障和宕机"></a>处理节点故障和宕机</h1><p>由于故障或错误，系统中的任何节点都可能宕机。因此，我们的目标是保持系统在个别节点故障时继续运行，并尽量减少节点故障的影响。以下是处理基于Leader的复制中的节点故障的情况的讨论。</p><h2 id="处理从节点故障"><a href="#处理从节点故障" class="headerlink" title="处理从节点故障"></a>处理从节点故障</h2><p>每个从节点都维护其从Leader接收到的数据更改的日志。这个日志帮</p><p>助从节点在故障发生之前识别最后一个处理的事务。</p><p>因此，如果从节点发生故障（如崩溃、重新启动或暂时的网络中断），它可以连接到Leader并请求在它断开连接时发生的所有数据更改。一旦它应用这些更改，它将赶上Leader，并可以像以</p><p>前一样继续接收数据更改流。</p><h2 id="处理Leader故障"><a href="#处理Leader故障" class="headerlink" title="处理Leader故障"></a>处理Leader故障</h2><p>处理Leader故障有点复杂，并需要三个关键步骤：1）检测Leader节点故障 2）将一个从节点提升为新Leader 3）配置客户端将其写入发送给新Leader，并将其他从节点开始消费新Leader的数据更改。这个过程也被称为<strong>故障切换（failover）</strong>。</p><p><strong>步骤1：检测Leader故障：</strong> Leader故障可能由各种原因（崩溃、停电、网络问题等）引起。由于没有绝对可靠的方法来检测故障的原因，因此通常使用超时来假设Leader节点在一段时间内未响应时宕机，通常不超过30秒或1分钟。</p><p><strong>步骤2：选择新Leader：</strong> 这可以通过选举过程来实现，新Leader由大多数剩余副本选择。为了最小化数据丢失，通常选择具有最新数据更改的副本作为新Leader。但要使所有节点都同意一个新的Leader是一个共识问题。<strong>注意：</strong>我们将在单独的博客中讨论共识问题的想法。</p><p><strong>步骤3：重新配置系统使用新Leader：</strong> 客户端需要将其写入请求发送给新Leader。如果旧Leader恢复上线，它可能仍然认为自己是Leader，并不知道已被新Leader替换。因此，系统需要确保旧Leader成为从节点并识别新Leader。</p><p><strong>注意：</strong> 在半同步复制的情况下，我们将同步的从节点设为新的主节点，因为我们知道它是最新的，并且不会丢失数据。</p><h2 id="处理Leader故障时的一些关键挑战！"><a href="#处理Leader故障时的一些关键挑战！" class="headerlink" title="处理Leader故障时的一些关键挑战！"></a>处理Leader故障时的一些关键挑战！</h2><ul><li>在异步复制中，可能出现新Leader在故障之前尚未收到所有来自旧Leader的写入的情况。当前Leader重新加入集群后，可能会出现写入冲突的可能性。关键问题是：对这些写入应该采取什么措施？思考和探索！</li><li>在某些情况下，分布式系统中的两个节点可能认为自己是Leader，这被称为<strong>脑裂（split-brain）情况</strong>。这种情况可能非常棘手，因为两个Leader可能都会接受写入而没有解决冲突的过程，这可能导致数据丢失或损坏。如何预防或处理这种脑裂情况？</li><li>在声明Leader故障之前，什么是正确的超时时间？超时时间越长，在Leader故障时的恢复时间就越长。然而，如果超时时间太短，可能会出现不必要的故障切换。例如，临时增加负载可能会使节点响应时间超过超时时间，或者网络故障可能导致延迟的数据包。如果系统已经在处理高负载或网络问题，则不必要的故障切换可能会使情况变得更糟。</li></ul><p>这篇文章讨论了主从复制（Master-Slave Replication）的概念、应用场景以及相关的同步和异步复制策略，以及处理节点故障和故障切换的方法。主从复制是一种常用的数据库复制技术，用于提高系统性能、容错性和高可用性。了解这些复制策略和处理故障的方法对于设计和维护分布式系统非常重要。</p>]]></content>
      
      
      <categories>
          
          <category> 系统设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 主从复制,系统设计 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何有效地扩展数据库服务器以满足日益增长的工作量 - 数据库扩展策略</title>
      <link href="2023/10/22/systemDesign-db-extend/"/>
      <url>2023/10/22/systemDesign-db-extend/</url>
      
        <content type="html"><![CDATA[<p>在当今以数据为驱动的世界中，企业面临着一个挑战，即在保证应用程序的最佳性能的同时，管理迅速增长的数据量。扩展数据库服务器在满足这些需求方面起着至关重要的作用。本篇博客将探讨各种策略，以有效地扩展数据库服务器，以处理不断增加的工作量，提升性能并确保数据可用性。</p><h2 id="什么是数据库服务器扩展？"><a href="#什么是数据库服务器扩展？" class="headerlink" title="什么是数据库服务器扩展？"></a>什么是数据库服务器扩展？</h2><p>数据库服务器扩展是增加数据库服务器的容量和性能，以处理不断增长的数据量、用户请求和系统负载的过程。通过升级硬件组件，如 CPU、内存或存储，可以实现垂直扩展，这允许数据库服务器利用升级后硬件的改进能力来处理更大的工作量。垂直扩展通常受限于单个服务器的最大容量。</p><p><img src="https://res.craft.do/user/full/c4fcd313-f319-c77e-e1f2-f4caca9f2c87/doc/F02E56CC-D70B-4A7E-B6D6-9295DB942209/96A64AAA-6C98-47AC-9881-31AF9FA9D99F_2/vcI07aKM3g3GBDLwMhNNOqfyG81LNJyu0syQj8eeUpUz/6151697987454_.pic.jpeg" alt="6151697987454_.pic.jpeg"></p><span id="more"></span><h2 id="数据库服务器扩展的技术"><a href="#数据库服务器扩展的技术" class="headerlink" title="数据库服务器扩展的技术"></a>数据库服务器扩展的技术</h2><p>有多种方法可用于扩展数据库。它们是：</p><h3 id="1-垂直扩展"><a href="#1-垂直扩展" class="headerlink" title="1. 垂直扩展"></a>1. 垂直扩展</h3><p>在垂直扩展，也称为升级或降级，通过升级硬件组件，如 CPU、内存或存储，来增加服务器的资源。 这种方法允许数据库服务器通过利用升级后硬件的改进能力来处理更大的工作量。垂直扩展通常受限于单个服务器的最大容量。</p><h3 id="2-水平扩展"><a href="#2-水平扩展" class="headerlink" title="2. 水平扩展"></a>2. 水平扩展</h3><p>水平扩展关注的是向基础架构中添加更多数据库服务器。这种方法允许将工作负载分布在多个服务器上，减轻单个节点的负担。水平扩展也称为添加节点（扩展）或减少节点（收缩）。</p><p>根据实现方式的不同，水平扩展还可以提高数据库的整体可靠性。它消除了单点故障，因为您增加了在故障转移情况下可以使用的节点数。然而，水平扩展也增加了时间、精力（因此成本）方面的开销，因为您需要更多的节点（因此有更多的故障点）来保持数据库功能正常。</p><p>水平扩展比垂直扩展更困难，也更昂贵。</p><p><img src="https://res.craft.do/user/full/c4fcd313-f319-c77e-e1f2-f4caca9f2c87/doc/F02E56CC-D70B-4A7E-B6D6-9295DB942209/943617F4-4586-48D7-A71C-3D5FF352DDDB_2/8LFoBH9y929Fy1if7HeZItrjoRi7MPXOk45vCZIak0sz/6161697987454_.pic.jpeg" alt="6161697987454_.pic.jpeg"></p><p><strong>数据库集群和分片是实现水平扩展的常见技术。</strong></p><h3 id="3-数据库复制"><a href="#3-数据库复制" class="headerlink" title="3. 数据库复制"></a>3. 数据库复制</h3><p>数据库复制涉及创建多个数据库的副本，并将工作负载分布在它们之间。 它通过将读请求定向到副本来提高读取性能，同时保留主服务器用于写入操作。</p><p><img src="https://res.craft.do/user/full/c4fcd313-f319-c77e-e1f2-f4caca9f2c87/doc/F02E56CC-D70B-4A7E-B6D6-9295DB942209/8003376E-B7DC-44D8-B0F6-7B1B10AE7479_2/2ySUy6B1ONVKWtPZGBNL1v6PeQtMOZuzKlp6a73VemEz/6171697987454_.pic.jpeg" alt="6171697987454_.pic.jpeg"></p><p>因此，在这里，数据库的副本帮助我们分发请求，从而降低了对单个数据库的负载。</p><p>数据库复制涉及频繁地将数据从一个数据库或服务器复制或流式传输到另一个数据库，以便所有用户都可以访问同步的数据，而不管他们用来访问数据的是哪个系统。如果有数据更改，数据复制工具也会确保将更改应用于目标数据库。其结果是分布式数据存储网络，任何人都可以轻松地访问重要和相关的数据，并增加了不同位置之间的可用性。</p><h3 id="4-缓存"><a href="#4-缓存" class="headerlink" title="4. 缓存"></a>4. 缓存</h3><p>缓存是将数据存储并从缓存中访问的过程。但请等等，什么是缓存？缓存是一个旨在存储数据的软件或硬件组件，以便未来对相同数据的请求可以更快地得到服务。</p><p>缓存涉及将频繁访问的数据存储在内存中，以减少重复数据库查询的需求。</p><p><img src="https://res.craft.do/user/full/c4fcd313-f319-c77e-e1f2-f4caca9f2c87/doc/F02E56CC-D70B-4A7E-B6D6-9295DB942209/26EB2C68-0068-4E84-9C9A-D2D78C249D32_2/iT6mLAXyingRleNT2Gt8dALNGI0Z145s0o7TmvB73HEz/6181697987454_.pic.jpeg" alt="6181697987454_.pic.jpeg"></p><p>每当有新的请求到达时，首先会在缓存中搜索所请求的数据。当所请求的数据能够在缓存中找到时，称为“缓存命中”。相反，当无法在缓存中找到数据时，称为“缓存未命中”。显然，从缓存中读取所需数据被认为比重新计算结果或从原始数据存储中读取它更快。因此，从缓存中可以服务更多的请求，系统就越快。</p><p>通过实施内存缓存层，比如 Redis 或 Memcached，组织可以显著提升数据库性能。缓存通过直接从内存中提供数据来卸载数据库服务器，从而降低响应时间并提高可扩展性。</p><h3 id="5-分片"><a href="#5-分片" class="headerlink" title="5. 分片"></a>5. 分片</h3><p>分片是一种数据库分区的类型，其中将大型数据库分成较小的数据和不同节点。 分片涉及将数据分成较小的子集，并将其分布在多个服务器上。每个服务器处理特定的分区或分片，从而实现并行处理和改进性能。</p><p><img src="https://res.craft.do/user/full/c4fcd313-f319-c77e-e1f2-f4caca9f2c87/doc/F02E56CC-D70B-4A7E-B6D6-9295DB942209/1BA867CF-700A-42F7-B9FC-2AFCAC580D2F_2/ZgG0e1q27MAoEyfIASNHhfSLC069OiHQ2jTPzg2GEaIz/6191697987454_.pic.jpeg" alt="6191697987454_.pic.jpeg"></p><p>分片有两种类型：</p><ol><li>水平分片：在这种类型的分片中，数据库根据行进行分区。</li><li>垂直分片：在这种类型的分片中，数据库根据列进行分区。</li></ol><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>扩展数据库服务器是维持应用程序性能和适应不断增长的数据量的关键方面。通过采用垂直和水平扩展、复制、缓存和分区等策略，组织可以有效应对可扩展性挑战，并确保高效的数据库操作。然而，选择合适的扩展策略需要全面了解系统要求、工作负载模式和技术考虑因素。实施经过深思熟虑的扩展方法将使企业能够交付高性能的应用程序，同时有效地管理数据增长。</p>]]></content>
      
      
      <categories>
          
          <category> CDN,系统设计,网络技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CDN,系统设计,数据库扩展,数据处理,网络性能优化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于TCP的所有你想知道的</title>
      <link href="2023/10/14/internet-tcp-g/"/>
      <url>2023/10/14/internet-tcp-g/</url>
      
        <content type="html"><![CDATA[<h2 id="连接导向、可靠和比特流导向"><a href="#连接导向、可靠和比特流导向" class="headerlink" title="连接导向、可靠和比特流导向"></a>连接导向、可靠和比特流导向</h2><p>在网络层的IP协议是不可靠的。它负责将数据包从一个IP地址传递到另一个IP地址，但不对传递的数据包的交付、顺序或完整性做任何保证。这就是TCP发挥作用的地方，它确保数据传输的可靠性。</p><p>TCP具有以下三个重要特点：</p><ol><li>TCP是连接导向的。与将数据从一个服务器发送到多个服务器的UDP不同，TCP在两个特定服务器之间建立连接。</li><li>TCP是可靠的。TCP保证分段的传递，无论网络条件如何。</li><li>TCP是比特流导向的。使用TCP时，应用层数据被分段处理，传输层对消息的边界不可见。此外，这些分段必须按顺序处理，并且重复的分段将被丢弃。</li></ol><p>为了标识唯一的TCP连接，我们使用以下字段，通常称为四元组：</p><ul><li>源IP地址和目标IP地址：位于IP头中，用于指导IP协议进行数据路由。</li><li>源端口和目标端口：位于TCP头中，用于指示TCP协议将分段传递给哪个进程。</li></ul><span id="more"></span><h2 id="TCP头部的更多信息"><a href="#TCP头部的更多信息" class="headerlink" title="TCP头部的更多信息"></a>TCP头部的更多信息</h2><p>我们已经提到了TCP头部中的源端口和目标端口。让我们进一步研究TCP头部中的其他字段，特别是在建立TCP连接时至关重要的字段。下面的图表突出显示了这些重要字段。</p><ul><li>序列号（Sequence Number）：在建立新的TCP连接时，会分配一个随机的32位值作为初始序列号。接收端使用此序列号发送一个确认回复。序列号用作确保接收端对分段进行顺序处理的机制。</li><li>确认号（Acknowledgment Number）：接收端使用这个32位的数字来请求下一个TCP分段。这个值是序列号加一。当发送端接收到这个确认回复时，可以假定之前的所有数据都已成功接收。这个机制可以防止数据丢失。</li><li>标志位（Flags）：也称为控制位，标志位指示TCP消息的目的。接下来我们将在下一部分中探讨不同类型的TCP消息。控制位指示消息是用于建立连接、传输数据还是终止连接。<ul><li>ACK：用于确认。</li><li>RST：用于在发生无法恢复的错误时重置连接。</li><li>SYN：用于初始的三次握手。序列号字段必须被设置。</li><li>FIN：用于终止连接。</li></ul></li></ul><p><img src="https://res.craft.do/user/full/b313a1ab-3121-84d1-2506-d702b5c0ba9c/9E78E1A8-8CB2-44ED-B83C-F685864A37D2_2/fpNrZ2USy77He2Pluziwm0ALlXp8PcgTHytTUWZsy9gz/30a07a70-c0dd-4e5e-b949-042c7368cc39_1600x934.png" alt="30a07a70-c0dd-4e5e-b949-042c7368cc39_1600x934.png"></p><p>在下面，我们将看到这些字段在TCP连接建立过程中的使用方式。</p><h2 id="建立TCP连接：三次握手"><a href="#建立TCP连接：三次握手" class="headerlink" title="建立TCP连接：三次握手"></a>建立TCP连接：三次握手</h2><p>让我们探讨TCP如何建立连接，这个过程被称为三次握手。下面的图表展示了三次握手的过程。</p><p>步骤0：最初，客户端和服务器都处于CLOSE状态。服务器通过在特定端口上监听传入连接来开始。</p><p>步骤1：客户端通过向服务器发送一个SYN分段来发起连接。它为序列号分配一个随机数，称为初始序列号（ISN）。将SYN控制位设置为1，将客户端转换为SYN-SENT状态。</p><p>步骤2：服务器在接收到SYN分段后，为序列号分配一个随机数，并将确认号设置为<em>client_isn+1</em>。然后，它将SYN和ACK控制位都设置为1，并将此分段发送回客户端。此时，服务器进入SYN-RECEIVED状态。</p><p>步骤3：客户端在接收到SYN+ACK分段后，发送一个ACK分段，并将确认号设置为<em>server_isn+1</em>。此时，该分段可以携带应用层数据，并且客户端进入ESTABLISHED状态。一旦服务器接收到ACK分段，它也进入ESTABLISHED状态。</p><p>值得注意的是，前两次握手不能携带数据，但第三次握手可以。在完成三次握手后，客户端和服务器可以开始交换数据。</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F781159a5-f60e-4c94-b815-c8abd8d73b12_1600x1442.png" alt="781159a5-f60e-4c94-b815-c8abd8d73b12_1600x1442.png"></p><p>TCP是可靠的，那么当一个分段丢失时会发生什么呢？</p><ul><li>如果SYN分段丢失：如果客户端在设定的时间范围内没有收到SYN+ACK，它会重新发送SYN分段多次（默认为5次）。如果仍然没有收到SYN+ACK分段，客户端会终止连接，从SYN_SENT状态转换到CLOSED状态。</li><li>如果SYN+ACK分段丢失：客户端无法区分SYN分段丢失还是SYN+ACK分段丢失，因此它会重新发送SYN分段，并在多次尝试后关闭连接。如果服务器在一定时间内没有收到ACK分段，它会重新发送SYN+ACK分段，并在多次尝试后关闭连接。</li><li>如果ACK分段丢失：如果服务器没有收到ACK分段，它会发起重发操作。请注意，客户端不会重新发送ACK分段。如果服务器即使重发了ACK分段仍然无法收到，它会关闭连接。</li></ul><h2 id="关闭TCP连接：四次握手"><a href="#关闭TCP连接：四次握手" class="headerlink" title="关闭TCP连接：四次握手"></a>关闭TCP连接：四次握手</h2><p>现在让我们转向TCP连接的终止过程。客户端和服务器都可以启动终止。在下图中，客户端启动了终止过程。</p><p>步骤1：客户端通过向服务器发送一个FIN分段来启动终止过程，进入FIN_WAIT_1状态。</p><p>步骤2：服务器在收到</p><p>FIN分段后，回复一个ACK分段，并进入CLOSE_WAIT状态。在收到ACK分段后，客户端进入FIN_WAIT_2状态。</p><p>步骤3：服务器完成处理后，向客户端发送一个FIN分段，并进入LAST_ACK状态。</p><p>步骤4：客户端在收到FIN分段后，发送一个ACK分段，并进入TIME_WAIT状态。服务器在收到ACK分段后，进入CLOSED状态。等待2MSL（最大报文生存时间）的持续时间后，客户端也转换到CLOSED状态。MSL是TCP分段在网络中存在的最长时间，任意地定义为2分钟。</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e386fb3-7fc6-477a-aa50-c314a462a349_1600x1591.png" alt="1e386fb3-7fc6-477a-aa50-c314a462a349_1600x1591.png"></p><p>当我们深入研究TCP握手时，让我们考虑三种边缘情况：</p><ol><li>客户端宕机</li><li>服务器宕机</li><li>网络电缆损坏</li></ol><p>如果客户端在建立TCP连接后宕机会发生什么？</p><p>假设在客户端和服务器之间建立了TCP连接，然后客户端突然断线。会发生什么？</p><p>如果服务器不尝试向客户端发送数据，服务器无法了解客户端的状态。服务器将保持在ESTABLISHED状态。解决这个问题的方法是实现TCP保活。</p><p>使用TCP保活，一组计时器与建立的TCP连接关联。当保活计时器超时时，服务器向客户端发送一个保活探测。该探测是一个不携带数据的ACK分段。如果连续发送多个探测分段而没有客户端的响应，服务器将认为TCP连接已经断开。</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d679ed7-acee-4b70-8536-867bf71a50bc_1486x1600.png" alt="5d679ed7-acee-4b70-8536-867bf71a50bc_1486x1600.png"></p><p>现在让我们更深入地探讨TCP保活的四种情况：</p><ol><li>客户端正常工作。服务器发送一个保活探测并收到回复。保活计时器重置，服务器在计时器再次超时时发送下一个探测。</li><li>客户端进程关闭。在客户端上，当操作系统回收进程资源时，它向服务器发送一个FIN分段。</li><li>客户端机器离线并重新启动。如下图所示，当客户端重新上线时，它对先前的连接一无所知。当服务器尝试通过这个失效的连接向客户端发送数据时，客户端会回复一个RST分段，强制服务器关闭连接。</li><li>客户端机器离线并且不恢复。我们已经讨论过这种情况-在几次无应答的探测之后，服务器将认为连接已经断开。</li></ol><p>对于服务器在建立TCP连接后宕机的情况，类似的机制也适用，因为TCP是一种双工协议。</p>]]></content>
      
      
      <categories>
          
          <category> network </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tcp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络协议驱动互联网</title>
      <link href="2023/10/14/internet-tcp-h/"/>
      <url>2023/10/14/internet-tcp-h/</url>
      
        <content type="html"><![CDATA[<p>在分布式系统中，数据通过各种网络协议在网络中传输。作为应用程序开发者，这往往在问题出现之前似乎是一个黑盒子。</p><p>在本文中，我们将解释常见网络协议的工作原理，它们在分布式系统中的应用以及我们如何解决常见问题。后续还会介绍一些常见的面试问题，例如：</p><ul><li>在输入网址到浏览器时会发生什么？</li><li>什么是TCP三次握手？</li><li>TCP的time_wait状态是什么意思？</li><li>HTTP 1/2/3是什么？</li><li>为什么HTTP 3使用UDP？</li><li>HTTPS是如何工作的？</li><li>为什么UDP被认为是“不可靠”的？</li></ul><p>让我们首先了解网络协议的使用情况。</p><span id="more"></span><h2 id="互联网和OSI模型"><a href="#互联网和OSI模型" class="headerlink" title="互联网和OSI模型"></a>互联网和OSI模型</h2><p>互联网连接了世界各地的各种计算设备。我们可以从下面的图表中大致了解。假设我们从智能手机或笔记本电脑访问一个网站，它连接到一个移动网络基站。基站连接到路由器，然后通过互联网服务提供商（ISP）访问互联网。数据包被转发到本地ISP，然后到达托管网站的网络。一旦数据包到达公司网络，它们经过链路层交换机并到达适当的服务器。</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F83a3c8d3-7fc7-4d71-91f7-64adfe65a65e_1169x1600.png" alt="83a3c8d3-7fc7-4d71-91f7-64adfe65a65e_1169x1600.png"></p><p>路由器和链路层交换机都是数据包交换机，它们的工作是转发数据包。区别在于，路由器通常用于网络核心连接多个网络，而链路层交换机用于访问网络（物理连接终端系统和边缘路由器的网络），在单个网络中连接多个设备。</p><p>为什么我们需要网络协议？互联网连接的设备需要使用它们可以理解的语言进行通信。各种计算机系统使用OSI（开放系统互连）模型规定的标准相互通信。OSI模型有七个抽象层，每个层都有独特的职责和协议。</p><p>下图显示了OSI模型中各层的作用。每个中间层为上面的层提供一类功能，并由下面的层提供服务。</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c53f73a-c6ec-45cc-afb5-4018ac97a488_1600x1085.png" alt="8c53f73a-c6ec-45cc-afb5-4018ac97a488_1600x1085.png"></p><h3 id="应用层"><a href="#应用层" class="headerlink" title="应用层"></a>应用层</h3><p>应用层最接近最终用户。大多数应用程序位于此层。我们向后端服务器请求数据，无需了解数据传输的具体细节。此层的协议包括HTTP、SMTP、FTP、DNS等，我们稍后会详细介绍它们。</p><h3 id="表示层"><a href="#表示层" class="headerlink" title="表示层"></a>表示层</h3><p>该层处理数据编码、加密和压缩，为应用层准备数据。例如，HTTPS使用TLS（传输层安全）在客户端和服务器之间进行安全通信。</p><h3 id="会话层"><a href="#会话层" class="headerlink" title="会话层"></a>会话层</h3><p>该层在两个设备之间建立和关闭通信。如果数据量较大，会话层设置检查点以避免从头重新发送。</p><h3 id="传输层"><a href="#传输层" class="headerlink" title="传输层"></a>传输层</h3><p>该层处理两个设备之间的端到端通信。它在发送端将数据分割为段，并在接收端重新组装它们。此层具有流量控制以防止拥塞。在该层中的关键协议是TCP和UDP，我们稍后会讨论它们。</p><h3 id="网络层"><a href="#网络层" class="headerlink" title="网络层"></a>网络层</h3><p>该层实现不同网络之间的数据传输。它将段或数据报进一步分割为较小的数据包，并使用IP地址找到到达目标的最佳路由。这个过程称为路由。</p><h3 id="数据链路层"><a href="#数据链路层" class="headerlink" title="数据链路层"></a>数据链路层</h3><p>该层允许在同一网络上的设备之间进行数据传输。数据包被分割为帧，并限制在本地区域网络中。</p><h3 id="物理层"><a href="#物理层" class="headerlink" title="物理层"></a>物理层</h3><p>该层通过电缆和交换机发送比特流，因此与设备之间的物理连接密切相关。</p><p>与OSI模型相比，TCP/IP模型只有4层。在讨论层次结构时，重要的是要指定上下文。</p><p>现在我们了解了每个层的职责，让我们通过以下图表总结数据传输过程。这被称为封装和解封装。封装是在数据朝向目的地的过程中添加头部信息。解封装则是去除这些头部以恢复原始数据。</p><p><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98d7dda0-c161-4568-80f2-6f06d25eb804_1600x1147.png" alt="98d7dda0-c161-4568-80f2-6f06d25eb804_1600x1147.png"></p><p><strong>步骤1</strong>：当设备A使用HTTP通过网络向设备B发送数据时，应用层会添加HTTP头部。</p><p><strong>步骤2</strong>：在传输层，TCP或UDP头部会添加到数据中。数据会在传输层被封装成TCP段。头部包含源端口、目标端口和序列号。</p><p><strong>步骤3</strong>：接下来，段会在网络层被封装成IP头部。IP头部包含源IP地址和目标IP地址。</p><p><strong>步骤4</strong>：在数据链路层，MAC头部会添加到IP数据报中，其中包含源MAC地址和目标MAC地址。</p><p><strong>步骤5</strong>：封装后的帧会发送到物理层，并以比特流的形式通过网络发送。</p><p><strong>步骤6-10</strong>：当设备B从网络接收到比特流时，每一层都会解封装数据，并将其传递到相应的层。</p>]]></content>
      
      
      <categories>
          
          <category> network </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tcp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>设计自定义线程池</title>
      <link href="2023/10/14/java-threadpool/"/>
      <url>2023/10/14/java-threadpool/</url>
      
        <content type="html"><![CDATA[<h2 id="什么是线程池？"><a href="#什么是线程池？" class="headerlink" title="什么是线程池？"></a>什么是线程池？</h2><p>线程池是一组预初始化的工作线程，由线程池管理器进行管理。线程池管理器负责将任务分发给工作线程并管理任务的执行。</p><p>线程池不是为每个任务创建一个新线程，这样做可能效率低下并导致资源争用。线程池允许一组线程被创建一次，然后用于多个任务。这可以提高应用程序的性能和可伸缩性。</p><p><img src="https://miro.medium.com/v2/resize:fit:1400/1*pOec-wF1ytIlwMIxQkQM3A.png" alt="1*pOec-wF1ytIlwMIxQkQM3A.png"></p><span id="more"></span><h2 id="设计线程池："><a href="#设计线程池：" class="headerlink" title="设计线程池："></a>设计线程池：</h2><p>要设计一个线程池，我们需要以下实体：</p><ol><li>线程池：将任务加入阻塞队列。</li><li>阻塞队列：存储任务。</li><li>任务执行器：执行任务。</li></ol><p><img src="https://miro.medium.com/v2/resize:fit:782/1*iOx_kUIuKsO2RLjtAdQHuA.png" alt="1*iOx_kUIuKsO2RLjtAdQHuA.png"></p><h2 id="线程池："><a href="#线程池：" class="headerlink" title="线程池："></a>线程池：</h2><ol><li>线程池类通过构造函数初始化阻塞队列的大小和线程池中可用的线程数。</li><li>在构造函数中，我们创建给定数量的线程，并将任务执行器（实现了Runnable接口）的引用传递给线程并启动它们。</li><li>线程池类具有submit(Runnable runnable)方法，用于将任务加入阻塞队列。</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.concurrent.BlockingQueue;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.LinkedBlockingDeque;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ThreadPool</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> BlockingQueue&lt;Runnable&gt; blockingQueue;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 定义队列的大小和线程数</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ThreadPool</span><span class="params">(<span class="keyword">int</span> queueSize, <span class="keyword">int</span> noOfThreads)</span> </span>&#123;</span><br><span class="line">        blockingQueue = <span class="keyword">new</span> LinkedBlockingDeque&lt;&gt;(queueSize);</span><br><span class="line">        TaskExecutor taskExecutor = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; noOfThreads; i++) &#123;</span><br><span class="line">            taskExecutor = <span class="keyword">new</span> TaskExecutor(blockingQueue);</span><br><span class="line">            Thread thread = <span class="keyword">new</span> Thread(taskExecutor);</span><br><span class="line">            thread.start();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">submit</span><span class="params">(Runnable runnable)</span> </span>&#123;</span><br><span class="line">        blockingQueue.add(runnable);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="任务执行器："><a href="#任务执行器：" class="headerlink" title="任务执行器："></a>任务执行器：</h2><ol><li>任务执行器是一个实现了Runnable接口的类，负责从阻塞队列中获取任务并执行它们。</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TaskExecutor</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> BlockingQueue&lt;Runnable&gt; blockingQueue;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">TaskExecutor</span><span class="params">(BlockingQueue&lt;Runnable&gt; blockingQueue)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.blockingQueue = blockingQueue;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="comment">// 从队列中取出任务并执行</span></span><br><span class="line">                Runnable runnable = blockingQueue.take();</span><br><span class="line">                runnable.run();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>现在，我们来测试一下我们的线程池：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestThreadPool</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        ThreadPool threadPool = <span class="keyword">new</span> ThreadPool(<span class="number">3</span>, <span class="number">2</span>);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> taskNumber = <span class="number">1</span>; taskNumber &lt;= <span class="number">7</span>; taskNumber++) &#123;</span><br><span class="line">            TestTask testTask1 = <span class="keyword">new</span> TestTask(<span class="string">&quot;abcd_&quot;</span> + taskNumber);</span><br><span class="line">            threadPool.submit(testTask1);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>我想补充一点，为什么我们使用阻塞队列来保存任务？</p></blockquote><blockquote><p>答案很简单，<code>BlockingQueue</code>允许线程在队列为空时等待新任务，并且只在有空间可用时才接受新任务，防止系统一次性处理过多任务导致超载。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 系统设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 线程池 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SQL和NoSQL数据库的便捷速查表</title>
      <link href="2023/10/14/mysql-sql/"/>
      <url>2023/10/14/mysql-sql/</url>
      
        <content type="html"><![CDATA[<p><img src="https://res.craft.do/user/full/b313a1ab-3121-84d1-2506-d702b5c0ba9c/27149C4F-836E-4A35-8682-0B86BD695B46_2/Y6zIOTYcFX6SHA2sjkHGZkEzk3a90teEIhQXLJyduacz/ae256384-ff3f-4fe8-9456-f6be80132cc7_1780x1536.jpeg" alt="ae256384-ff3f-4fe8-9456-f6be80132cc7_1780x1536.jpeg"></p><p>在项目成功的过程中选择合适的数据库非常重要。以下是关键要点的总结：</p><ul><li>SQL数据库提供结构化数据存储、SQL支持和关系能力。</li><li>NoSQL数据库提供灵活性、可扩展性和分布式架构。</li><li>专门的数据库，如列存储、图形数据库、空间数据库和时间序列数据库，满足特定需求。</li><li>评估关键功能、优势和提供商，以做出明智的决策。</li></ul><span id="more"></span><h2 id="SQL数据库"><a href="#SQL数据库" class="headerlink" title="SQL数据库"></a>SQL数据库</h2><p>SQL（Structured Query Language）数据库使用表格结构来存储数据，并使用SQL语言进行查询和操作。以下是一些SQL数据库的主要特点：</p><ul><li>结构化数据存储：数据以表格的形式组织，每个表格有预定义的列和数据类型。</li><li>关系能力：通过主键和外键，表格之间可以建立关系。</li><li>SQL支持：使用SQL语言进行查询、插入、更新和删除数据。</li><li>数据一致性和完整性：通过事务处理和约束条件来确保数据的一致性和完整性。</li><li>可扩展性：支持垂直和水平扩展以处理大规模数据。</li></ul><p>常见的SQL数据库包括MySQL、PostgreSQL、Oracle和Microsoft SQL Server等。</p><h2 id="NoSQL数据库"><a href="#NoSQL数据库" class="headerlink" title="NoSQL数据库"></a>NoSQL数据库</h2><p>NoSQL（Not Only SQL）数据库是一种非关系型数据库，不使用表格结构，而是使用键值对、文档、列族或图形等方式来存储数据。以下是一些NoSQL数据库的主要特点：</p><ul><li>灵活性：数据模型可以根据需求自由更改，无需事先定义表格结构。</li><li>可扩展性：采用分布式架构，可以轻松扩展以处理大规模数据。</li><li>高性能：通过优化数据访问模式和数据存储方式，实现高速读写操作。</li><li>无固定模式：不需要遵循严格的模式，可以存储各种类型的数据，包括结构化、半结构化和非结构化数据。</li></ul><p>常见的NoSQL数据库包括MongoDB、Cassandra、Redis和Amazon DynamoDB等。</p><h2 id="特殊数据库"><a href="#特殊数据库" class="headerlink" title="特殊数据库"></a>特殊数据库</h2><p>除了传统的SQL和NoSQL数据库之外，还有一些专门用于特定需求的数据库：</p><ul><li>列存储数据库：适用于大规模数据分析和查询，数据以列的方式存储。</li><li>图形数据库：用于存储和处理具有复杂关系和</li></ul><p>连接的数据，如社交网络关系图。</p><ul><li>空间数据库：用于存储和查询地理空间数据，如地图数据和位置信息。</li><li>时间序列数据库：专门用于存储和分析时间序列数据，如传感器数据和日志数据。</li></ul><p>根据项目的具体需求，可以选择适合的特殊数据库来优化数据存储和查询的性能。</p><h2 id="如何选择数据库"><a href="#如何选择数据库" class="headerlink" title="如何选择数据库"></a>如何选择数据库</h2><p>在选择数据库时，需要考虑以下因素：</p><ul><li>功能需求：根据项目的功能需求，选择具备所需功能的数据库。</li><li>性能要求：评估数据库的性能指标，包括读写速度、吞吐量和响应时间。</li><li>可扩展性：考虑数据库的扩展性，以便在需要时能够处理增长的数据量和用户访问量。</li><li>数据模型：根据数据的结构和关系，选择适合的数据模型（表格、文档、图形等）。</li><li>成本效益：综合考虑数据库的许可费用、维护成本和云服务费用等方面的成本。</li><li>社区支持和生态系统：选择具有活跃社区和完善生态系统的数据库，以便获取支持和扩展功能。</li></ul><p>通过综合评估以上因素，可以做出明智的决策，选择适合项目的数据库。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>选择合适的数据库对于项目的成功非常重要。SQL数据库提供结构化数据存储和关系能力，适用于需要严格数据模型和事务处理的场景。NoSQL数据库提供灵活性和可扩展性，适用于需要处理大规模数据和快速读写操作的场景。此外，还有一些特殊数据库可根据特定需求选择。</p><p>在选择数据库时，需要考虑功能需求、性能要求、可扩展性、数据模型、成本效益以及社区支持和生态系统等因素。通过综合评估这些因素，可以做出明智的决策，为项目选择合适的数据库。</p><p>希望本篇技术文章能够帮助您更好地理解SQL和NoSQL数据库，并在选择合适的数据库时提供一些指导</p>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis — 不仅仅是缓存</title>
      <link href="2023/10/14/redis-redis/"/>
      <url>2023/10/14/redis-redis/</url>
      
        <content type="html"><![CDATA[<p><img src="https://miro.medium.com/v2/resize:fit:1400/1*qIy3PMmEWNcD9Czh_21C8g.png" alt="1*qIy3PMmEWNcD9Czh_21C8g.png"></p><p>Redis是一种快速、开源的内存键值（NoSQL）数据库，远远超越了缓存的功能。Redis使用RAM进行操作，提供亚毫秒级的响应时间，支持每秒数百万次请求。Redis主要用于缓存，但它也可以作为那些数据不经常变化的应用程序的主要数据库。Redis内置了复制、服务端脚本（使用Lua脚本）、LRU驱逐、定时过期和事务支持。</p><p>Redis的用例包括：</p><ul><li>数据投影服务</li><li>临时消息代理</li><li>事件溯源系统</li></ul><p><em>注意：Redis是使用C语言编写的。</em></p><span id="more"></span><h2 id="Redis为什么快？"><a href="#Redis为什么快？" class="headerlink" title="Redis为什么快？"></a>Redis为什么快？</h2><ul><li>Redis是基于RAM的。RAM访问速度比随机磁盘访问快。</li><li>使用IO多路复用和单线程执行循环来提高执行效率。</li><li>使用高效的底层数据结构（SDS、ZipList、SkipList、分层索引）。</li></ul><h2 id="Linux安装步骤"><a href="#Linux安装步骤" class="headerlink" title="Linux安装步骤"></a>Linux安装步骤</h2><p>创建文件<code>/etc/yum.repos.d/redis.repo</code>，内容如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[Redis]</span><br><span class="line">name&#x3D;Redis</span><br><span class="line">baseurl&#x3D;http:&#x2F;&#x2F;packages.redis.io&#x2F;rpm&#x2F;rhel7</span><br><span class="line">enabled&#x3D;1</span><br><span class="line">gpgcheck&#x3D;1</span><br></pre></td></tr></table></figure><p>然后运行以下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl -fsSL https:&#x2F;&#x2F;packages.redis.io&#x2F;gpg &gt; &#x2F;tmp&#x2F;redis.key</span><br><span class="line">sudo rpm --import &#x2F;tmp&#x2F;redis.key</span><br><span class="line">sudo yum install epel-release</span><br><span class="line">sudo yum install redis-stack-server</span><br></pre></td></tr></table></figure><h2 id="高级CLI命令"><a href="#高级CLI命令" class="headerlink" title="高级CLI命令"></a>高级CLI命令</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">$ redis-cli</span><br><span class="line"></span><br><span class="line">INFO - 获取有关集群的信息</span><br><span class="line">SELECT - 选择命名空间&#x2F;数据库</span><br><span class="line">DBSIZE - 获取键的数量</span><br><span class="line">KEYS * - 列出所有键（模式匹配）（优先使用SCAN命令）</span><br><span class="line">SCAN - 用游标返回结果的子集</span><br><span class="line">EXISTS - 检查键是否存在</span><br><span class="line">TYPE - 检查键的数据类型</span><br><span class="line">EXPIRE - 设置键的过期时间</span><br><span class="line">RENAME - 将键重命名为新名称</span><br><span class="line">FLUSHDB - 清除命名空间中的所有键</span><br><span class="line">FLUSHALL - 清除所有命名空间中的所有键</span><br><span class="line">ROLE - 检查节点角色（主节点、从节点、哨兵节点）</span><br><span class="line">CLEAR - 清除CLI上下文终端</span><br><span class="line">QUIT - 退出CLI</span><br><span class="line"></span><br><span class="line"># redis-cli --pipe #从文件或stdin流式传输命令到Redis</span><br><span class="line"># redis-cli --hotkeys #查找热键</span><br></pre></td></tr></table></figure><h2 id="关于一些命令的几点说明"><a href="#关于一些命令的几点说明" class="headerlink" title="关于一些命令的几点说明"></a>关于一些命令的几点说明</h2><ul><li>Redis数据库是创建键的逻辑方式，用于创建键的隔离和命名空间。默认情况下，Redis有0-15个数据库索引。在集群模式下，这些数据库不存在。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT index_no</span><br></pre></td></tr></table></figure><ul><li>以下命令通常会添加</li></ul><p>后缀。这些命令根据键的存在与否采取不同的行为。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">NX - 如果不存在</span><br><span class="line">XX - 如果存在</span><br></pre></td></tr></table></figure><p>注意：通常在命令前加上”M”表示多，例如MGET与GET。类似地，在命令前加上”P”表示基于模式的命令。</p><ul><li>KEYS命令是顺序的（O(n)）和同步的（阻塞的）。在应用程序中，优先使用SCAN而不是KEYS。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RedisInsight - 这是一个与Redis服务器交互的用户界面工具。</span><br></pre></td></tr></table></figure><h2 id="支持的数据结构"><a href="#支持的数据结构" class="headerlink" title="支持的数据结构"></a>支持的数据结构</h2><p><img src="https://miro.medium.com/v2/resize:fit:1400/1*f96hoFTEAiCt2jCF-s7EmA.png" alt="1*f96hoFTEAiCt2jCF-s7EmA.png"></p><h2 id="String（字符串）"><a href="#String（字符串）" class="headerlink" title="String（字符串）"></a>String（字符串）</h2><ul><li>最基本和常见的Redis数据类型</li><li>Redis字符串存储字节序列</li><li>最大大小为512 MB</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SET | GET | DEL</span><br><span class="line">INCR | INCRBY | INCRBYFLOAT</span><br><span class="line">MSET | MGET</span><br><span class="line"></span><br><span class="line">注意：DEL是阻塞的，而UNLINK是非阻塞的</span><br></pre></td></tr></table></figure><h2 id="List（列表）"><a href="#List（列表）" class="headerlink" title="List（列表）"></a>List（列表）</h2><p><img src="https://miro.medium.com/v2/resize:fit:1400/1*-DoC-iO1T8qRKUgd9mEG5A.png" alt="1*-DoC-iO1T8qRKUgd9mEG5A.png"></p><ul><li>字符串值的链表</li><li>元素的集合</li><li>每个元素都是一个字符串</li><li>可以包含超过40亿个元素</li><li>元素顺序基于插入顺序</li><li>编码和内存优化</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">LPUSH | LRANGE | RPUSH | LPOP | RPOP | LLEN</span><br><span class="line">LTRIM | LINDEX | LINSERT | LSET | LPOS | LREM</span><br></pre></td></tr></table></figure><h2 id="Set（集合）"><a href="#Set（集合）" class="headerlink" title="Set（集合）"></a>Set（集合）</h2><ul><li>Redis集合是一组无序的唯一字符串（成员），用于跟踪唯一元素。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SADD | SREM | SCARD | SMEMBERS | SDIFF | SDIFFSTORE</span><br><span class="line">SISMEMBER | SMISMEMBER | SMOVE | SPOP</span><br></pre></td></tr></table></figure><h2 id="Hash（哈希）"><a href="#Hash（哈希）" class="headerlink" title="Hash（哈希）"></a>Hash（哈希）</h2><p><img src="https://miro.medium.com/v2/resize:fit:1400/1*nBB3vFuBYooNrPuS-Fnz9Q.png" alt="1*nBB3vFuBYooNrPuS-Fnz9Q.png"></p><ul><li>Redis哈希是作为字段-值对集合结构化的记录类型。每个哈希可以存储多达42亿个（2^32-1）个字段-值对。哈希可用于在应用程序中存储会话和个人资料。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HSET | HGET | HGETALL | HDEL | HEXIST | HMSET | HMGET</span><br></pre></td></tr></table></figure><h2 id="Sorted-Set（有序集合）"><a href="#Sorted-Set（有序集合）" class="headerlink" title="Sorted Set（有序集合）"></a>Sorted Set（有序集合）</h2><p><img src="https://miro.medium.com/v2/resize:fit:1310/1*CkISVoBW8dIyC4YOu9005Q.png" alt="1*CkISVoBW8dIyC4YOu9005Q.png"></p><ul><li>Redis有序集合是一组唯一字符串（成员），按相关分数进行排序的集</li></ul><p>合。它可以用于排行榜、优先级队列、二级索引和速率限制器。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ZADD | ZCARD | ZSCORE | ZRANK | ZREVRANK | ZREM | ZRANGE</span><br></pre></td></tr></table></figure><h2 id="HyperLogLog"><a href="#HyperLogLog" class="headerlink" title="HyperLogLog"></a>HyperLogLog</h2><blockquote><p>HyperLogLog是一种用于估计集合基数的数据结构。它可用于跟踪唯一访问者数量。HyperLogLog的实现使用了多达12KB的空间。<br>PFADD | PFCOUNT | PFMERGE</p></blockquote><h2 id="Streams"><a href="#Streams" class="headerlink" title="Streams"></a>Streams</h2><p><img src="https://miro.medium.com/v2/resize:fit:1400/1*8NRb5TeJ34Jf08do8OzGxg.png" alt="1*8NRb5TeJ34Jf08do8OzGxg.png"></p><p>Redis流是一种类似追加日志的数据结构。您可以使用流记录和同时传播实时事件。</p><p>XADD | XREAD | XTRIM | XDEL</p><p>XGROUP CREATE | XGROUP DESTROY | XREADGROUP</p><p>XGROUP CREATECONSUMER | XGROUP DELCONSUMER</p><p>Redis Streams允许At-most-once或At-least-once的消息传递。Redis Streams支持同步和异步读取。</p><h2 id="Bitmap"><a href="#Bitmap" class="headerlink" title="Bitmap"></a>Bitmap</h2><p>Redis位图是字符串数据类型的扩展，它允许您将字符串视为位向量。</p><p>BITOP | BITPOS | BITCOUNT</p><p><img src="https://miro.medium.com/v2/resize:fit:1400/1*QZ7buW1SRfDIeccgmiXxGw.png" alt="1*QZ7buW1SRfDIeccgmiXxGw.png"></p><p>图片来源 — <a target="_blank" rel="noopener" href="http://bytebytego.com/">bytebytego.com</a></p><h2 id="Bitfield"><a href="#Bitfield" class="headerlink" title="Bitfield"></a>Bitfield</h2><p>Redis位字段允许您设置、增加和获取任意位长度的整数值。</p><h2 id="Geospatial"><a href="#Geospatial" class="headerlink" title="Geospatial"></a>Geospatial</h2><blockquote><p>Redis地理空间索引允许您存储坐标并进行搜索，查找给定半径或边界框内的附近点。<br>GEOADD | GEODIST | GEORADIUS | GEOSEARCH | GEOPOS</p></blockquote><ul><li><em>Redis使用Haversine公式计算距离。</em></li><li><em>Redis将地理空间点存储在有序集合中。集合的分数用于编码坐标对。</em></li></ul><h2 id="Key-Expiration"><a href="#Key-Expiration" class="headerlink" title="Key Expiration"></a>Key Expiration</h2><p><img src="https://miro.medium.com/v2/resize:fit:1400/1*tf8z_SgKoz69y4sXtpwIxg.png" alt="1*tf8z_SgKoz69y4sXtpwIxg.png"></p><blockquote><p>EX — 指定秒数后过期</p></blockquote><blockquote><p>PX — 指定毫秒数后过期</p></blockquote><blockquote><p>EXAT — 指定时间戳后过期（秒）</p></blockquote><blockquote><p>PXAT — 指定时间戳后过期（毫秒）</p></blockquote><blockquote><p>TTL — 键的剩余生存时间（近似值）</p></blockquote><blockquote><p>PERSIST — 移除当前的过期时间</p></blockquote><h2 id="Pipelining"><a href="#Pipelining" class="headerlink" title="Pipelining"></a>Pipelining</h2><p>Redis遵循客户端-服务器模型。客户端发送请求，服务器处理请求并返回响应。吞吐量主要由往返时间（通常在毫秒级别，请求处理通常在微秒级别）决定。Redis流水线是一种提高性能的技术，它可以一次性发出多个命令，而无需等待每个单独命令的响应。这是一种网络优化，因为我们减少了客户端和服务器之间的多次往返。</p><p><img src="https://res.craft.do/user/full/b313a1ab-3121-84d1-2506-d702b5c0ba9c/doc/7DEE7354-305E-4372-A775-D871034E4CA3/FC223F37-4E85-4EE0-9E7A-6DEC9FDCCC72_2/eoba36BzrySg2QA4b1hf6GnSaxP4vtjxsH6jqwuZN7gz/Image.tiff" alt="Image.tiff"></p><p><em>注意：1. 管道不保证命令执行顺序。2. 在管道中不允许在写操作之后进行读操作，因为所有命令的结果将在最后一起返回。3. 在进行管道操作时，需要使用哈希标记（hash-tags），以便将键强制映射到同一个分片上。4. 管道不是原子性的。5. Python库中的管道被包装在MULTI/EXEC中。</em></p><h2 id="Scripting"><a href="#Scripting" class="headerlink" title="Scripting"></a>Scripting</h2><p>调用服务器端Lua脚本的执行。</p><p>SCRIPT LOAD | FUNCTION LOAD | EVAL | FCALL | FUNCTION KILL | SCRIPT KILL</p><p><em>注意：Lua脚本是原子的且是阻塞的。</em></p><h2 id="Pub-Sub"><a href="#Pub-Sub" class="headerlink" title="Pub/Sub"></a>Pub/Sub</h2><p>Redis通过发布/订阅机制提供了一种解耦的消息传递范式。发布者将消息发送到频道，订阅者确认对一个或多个频道感兴趣，并接收感兴趣的消息。</p><p><img src="https://miro.medium.com/v2/resize:fit:1400/1*tV8vZ9MMnYPok7PiTKKjyQ.png" alt="1*tV8vZ9MMnYPok7PiTKKjyQ.png"></p><p>SUBSCRIBE | PUBLISH | PUBSUB CHANNELS | UNSUBSCRIBE</p><p><em>注意：发布/订阅与键空间无关。</em></p><h2 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h2><p>Redis事务允许将一组命令作为单个步骤执行，它们围绕以下命令展开：</p><blockquote><p>MULTI — 事务的开始</p></blockquote><blockquote><p>EXEC — 事务的结束</p></blockquote><blockquote><p>DISCARD — 取消事务</p></blockquote><blockquote><p>WATCH — 持续监视键是否在我们开始监视后被修改</p></blockquote><p><img src="https://miro.medium.com/v2/resize:fit:1400/1*mLHM_sFayUdEoT3AOKs5tg.png" alt="1*mLHM_sFayUdEoT3AOKs5tg.png"></p><blockquote><p>UNWATCH<br>事务中的所有命令都是串行化执行的。在Redis事务的执行过程中，不会在执行Redis事务的过程中为另一个客户端服务。</p></blockquote><h2 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h2><p>在Redis中，如果启用持久化，数据会被持久化到磁盘。重新启动时，它会将数据加载到内存中进行计算。</p><p><img src="https://miro.medium.com/v2/resize:fit:1400/1*r497z2Kjtg3iEa12LmDHsw.png" alt="1*r497z2Kjtg3iEa12LmDHsw.png"></p><blockquote><p>RDB — 在特定间隔的特定时间点进行快照AOF — 记录每个写操作的日志，每秒同步一次，后台线程，在恢复时回放日志<br>注意：您可以通过发出BGSAVE命令手动进行快照。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Google Drive 和 Dropbox 系统设计概述</title>
      <link href="2023/08/25/systemDesign-gd/"/>
      <url>2023/08/25/systemDesign-gd/</url>
      
        <content type="html"><![CDATA[<p>在现代信息世界中，我们有许多照片、文件、视频等需要存储。我相信几乎所有人都尝试过使用 Google Drive 或 Dropbox。</p><h3 id="功能需求"><a href="#功能需求" class="headerlink" title="功能需求"></a>功能需求</h3><ol><li>用户可以从任何设备上传和下载文件。</li><li>用户可以通过替换相同的文件名来更新文件。</li><li>用户可以通过电子邮件链接将文件和文件夹分享给其他人。</li><li>用户可以随时从任何设备删除文件和文件夹。</li><li>删除的文件和文件夹将在回收站中存储 15 天。</li><li>系统应该支持离线编辑。用户可以在离线状态下添加/修改文件和文件夹名称，一旦网络恢复，更改将与远程服务器同步。</li><li>用户可以进行文件版本管理，以恢复文件的先前版本。（系统可以支持多次更改的同一文件的多个版本，带宽和所需空间将显著增加）</li><li>系统可以支持跨设备的文件和文件夹同步。</li><li>系统允许每个用户免费上传高达 10 GB 的文件。</li><li>系统将为不同存储大小提供不同的市场计划。</li></ol><span id="more"></span><h3 id="非功能需求"><a href="#非功能需求" class="headerlink" title="非功能需求"></a>非功能需求</h3><ol><li>系统必须高度可靠。任何上传的文件都不得丢失。用户可以恢复其重要文件。</li><li>系统可以支持每周 7 天 24 小时。</li><li>用户可以随时升级其计划，并立即使用系统。</li><li>用户必须能够轻松地将其系统与其他应用程序集成。例如，系统支持通过其他应用程序共享文档。</li><li>系统可以提供延迟或并发利用（这意味着以高效的方法从云中反复上传和下载完整文件）。</li></ol><h3 id="存储估算"><a href="#存储估算" class="headerlink" title="存储估算"></a>存储估算</h3><ol><li>用户数量 = 5 亿</li><li>活跃用户数量 = 1 亿</li><li>用户平均存储的文件数量 = 300</li><li>每个文件的平均大小 = 200 KB</li><li>总文件数量 = 5 亿 * 300 = 1500 亿</li><li>需要的总存储空间 = 1500 亿 * 200 KB = 30 PB</li></ol><h3 id="系统组件"><a href="#系统组件" class="headerlink" title="系统组件"></a>系统组件</h3><ol><li><strong>客户端</strong>（安装在您的桌面或移动应用程序中，用于访问与存储相关的应用程序）<ul><li>监视用户机器上的工作区文件夹，并通过与远程服务器同步文件来维护一致性。因此，它必须由 4 个基本组件组成，即<strong>监视器、分块器、索引器和内部数据库</strong>。</li><li><strong>监视器</strong>将监视本地工作区文件夹，并通知索引器用户执行的任何操作（添加、删除、替换和更新文件或文件夹），并追踪来自其他设备的任何更改，这些更改由同步服务广播。</li><li><strong>分块器</strong>将文件分成更小的块，并从这些块中重建文件，以便完整的文件可以在没有任何丢失块的情况下传输。分块算法将检测用户修改的文件部分，并仅将已修改的部分传输到云存储，从而节省带宽和同步时间。</li><li><strong>索引器</strong>将处理来自监视器的事件，并更新内部元数据数据库。一旦成功从云存储下载或上传了块，索引器将与远程同步服务通信，广播更改给其他客户端，并更新远程元数据数据库。</li><li><strong>内部元数据数据库</strong>将跟踪所有文件、块、任何已更新的版本以及其在文件系统中的位置。</li><li>客户端应用程序将通过请求上传、下载和编辑 API 与后端云存储服务器进行通信。客户端还与远程同步服务进行交互，以处理任何文件元数据更新，例如文件名、大小、修改日期等。</li></ul></li><li><strong>元数据数据库</strong><ul><li>保持有关文件、块、用户、设备、工作区和存储位置的版本和元数据信息。</li><li>元数据数据库可以是关系数据库，如 MySQL，也可以是 NoSQL 数据库服务，如 DynamoDB。</li><li>同步服务在多个用户同时处理同一文件时，提供文件的一致视图。</li><li>由于 NoSQL 数据存储不支持 ACID 属性，编程代码会将 ACID 属性与 NoSQL 数据库结合在一起，用于同步服务的逻辑。</li></ul></li><li><strong>同步服务</strong><ul><li>更新客户端创建的文件或文件夹。</li><li>将客户端的本地数据库与存储在远程元数据数据库中的信息同步。</li><li>使用 HTTP 长轮询从云存储获取响应，或在脱机一段时间后将文件和更新发送到云存储，一旦重新脱机，将向所有设备或用户发送通知。</li><li>同步服务还尝试在客户端和云存储之间传输更少的数据，以实现更快的响应时间，因此使用差异化算法来减少需要同步的数据量。不再将整个文件从客户端传输到服务器，而是传输两个版本文件之间的差异。仅传输已更改的部分（块）。这减少了终端用户的带宽消耗和</li></ul></li></ol><p>云数据存储。服务器和客户端将计算哈希值，以查看是否更新修改的块。该过程称为数据去重。</p><ol start="4"><li><strong>消息队列服务</strong><ul><li>这是一个处理读写请求数量的消息中间件。</li><li>一个可扩展的消息队列服务，支持客户端和同步服务之间的异步通信。</li><li>可用性和可靠性必须被设计得最适合消息队列服务。</li><li><strong>请求队列</strong>：此队列将在所有客户端之间共享。当客户端执行任何更新和请求时，此请求将发送到消息队列服务，然后由同步服务进一步处理，最后更新元数据数据库。</li><li><strong>响应队列</strong>：每个客户端都有一个相关的响应队列，因为每个客户端都有一个单独的响应队列。</li><li>一旦文件更新，同步服务将通知所有响应队列有关更改的信息，然后响应队列将通知每个客户端进行的更改。</li></ul></li><li><strong>云/块存储</strong><ul><li>存储文件的块</li><li>使用 Amazon S3 服务</li><li>客户端将使用 API 服务与云存储进行交互</li></ul></li></ol><p><img src="https://miro.medium.com/v2/resize:fit:1380/0*zJz9WxZ9MEEO3zmE.png" alt="0*zJz9WxZ9MEEO3zmE.png"></p><ul><li><p><strong>文件处理工作流程</strong>：客户端 A 将块上传到云存储，然后更新元数据并提交更改，然后获得确认。服务器将通知客户端 B 和 C 有关更改的信息。客户端 B 和 C 接收元数据更改并下载更新的块。</p></li><li><p><strong>数据去重</strong>：消除数据的重复副本。这还可以减少相同数据传输（发送的字节数）以提高传输速率。对于每个传入的块，都会打上一个哈希标签，然后计算并将该哈希与现有块的所有其他哈希进行比较。</p><p>a) <strong>后处理去重</strong>：新块存储在存储设备上，并且将分析块以了解它们是否是重复的。优点是，客户端不需要等待哈希计算或查找完成，然后再存储数据，这会提高存储性能。缺点是短时间内会存储不必要的重复数据，并且会传输和消耗带宽。</p><p>b) <strong>内联去重</strong>：去重哈希计算可以实时执行，以便系统可以识别重复块，然后仅存储不存在的块。优点是优化网络和存储使用。缺点是消耗用户的时间并降低存储性能。</p></li></ul><ol start="6"><li><strong>缓存</strong><ul><li>在 Google Drive / Dropbox 系统设计中有两种类型的缓存</li><li>用于块存储的缓存</li><li>使用像 Memcache 这样的现成解决方案的缓存，可以存储带有其相应 ID/哈希的整个块和块服务器</li><li>可以采用最近最少使用（LRU）缓存策略。</li></ul></li><li><strong>负载均衡器（LB）</strong><ul><li>在客户端和块服务器之间</li><li>在客户端和元数据服务器之间</li><li>在后端服务器之间平均分配传入的请求</li></ul></li><li><strong>安全性/权限和文件共享</strong><ul><li>上传/下载的文件将与远程服务器同步</li><li>不允许对单个文件进行多个操作（并发问题）</li><li>如果在某个过程中出现了某些连接问题，客户端必须重新上传或下载整个文件，或者恢复下载或上传块。</li></ul></li></ol><p><strong>系统 API</strong></p><ol><li>Upload(string uploadToken, fileInfo file, userInfo user)</li><li>Edit(string authToken, fileInfo file, userInfo user)</li><li>Delete(string authToken, fileInfo file, userInfo user)</li><li>Download(string authToken, fileInfo file, userInfo user)</li><li>GenerateToken (string userName, string password)</li></ol><p><strong>高级系统架构</strong></p><p><strong>详细系统架构</strong></p><p><img src="https://miro.medium.com/v2/resize:fit:1400/0*ujFLQbJIrcSd7LKu" alt="Image.png"></p>]]></content>
      
      
      <categories>
          
          <category> system design </category>
          
      </categories>
      
      
        <tags>
            
            <tag> system design </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>通知系统设计：如何将其集成到我们的基础架构中</title>
      <link href="2023/08/12/systemDesign-msg/"/>
      <url>2023/08/12/systemDesign-msg/</url>
      
        <content type="html"><![CDATA[<h2 id="什么是面向企业的通知？"><a href="#什么是面向企业的通知？" class="headerlink" title="什么是面向企业的通知？"></a>什么是面向企业的通知？</h2><p>毫无疑问，没有任何数字化企业可以在没有通知的情况下生存。通过通过电子邮件、短信或推送通知等各种渠道发送及时通知，企业可以提高客户参与度和留存率，促使重复购买。通知还为企业提供了一个机会，可以收集客户反馈和见解，这可以用于改善其产品或服务。</p><p>最终，一个设计良好的通知服务可以帮助企业与客户建立牢固持久的关系，从而实现长期的成功。因此，无论何时，所有产品都需要为技术提供通知集成的要求。</p><h2 id="规划集成"><a href="#规划集成" class="headerlink" title="规划集成"></a>规划集成</h2><p>由于通知的功能性/非功能性要求在公司/企业之间基本相似，并且每个人都了解什么是通知功能，因此我们可以迅速记录一些业务需求，并立即开始讨论技术方面的问题。</p><span id="more"></span><ol><li>从业务角度看，系统中发生的任何事情都可以触发通知。</li><li>要发送的通知可以定向到一个或多个接收者或一组接收者。</li><li>我们需要支持不同的通知渠道：电子邮件、短信、Android/iOS设备的推送、应用内通知。</li><li>通知应该是本地化的，必须能够支持不同的语言和时区。</li><li>用户应该能够访问他们以前/旧的通知（也称为通知中心）。</li><li>一些推送通知或电子邮件通知不应该在用户的通知中心中被记录/显示（例如有关折扣的营销警报或其他短期警报），反之亦然，一些在用户的通知中心中可见的通知不应该生成警报，如推送通知（或已发送电子邮件）。</li><li>用户应该能够自定义通知的消耗方式（频率、类别、渠道等），例如为某种类型的通知设置首选渠道，甚至关闭它。</li></ol><p>因此，上述要求是大多数公司中关于通知的基本业务需求。我们需要设计一个满足这些需求的服务/基础架构，并通过满足一些直接影响整体开发的关键技术需求来鼓励无缝的开发过程。其中一些是：</p><ol><li>设置代码应易于理解/维护。</li><li>集成新通知简单、快速和直接，无需修改任何现有代码，只需按照用于先前通知的模式/约定进行扩展即可。</li><li>更改现有通知很容易，而不会影响其他部分（例如，删除特定类型的推送通道，而无需触及任何设置代码，而不会影响其他通知）。</li><li>轻松添加新的通道/提供商的方法（例如，浏览器通知、WhatsApp消息）。</li><li>一种非常简单的方式来添加/编辑特定通知的新翻译（本地化）。并且快速甚至立即反映新的翻译到工作系统中。</li><li>添加用户自定义通知设置不是一件头痛的事情。</li><li>整体服务易于测试，因此覆盖集成/后端端到端测试不会耗费太多时间。</li><li>易于调试特定情况。</li></ol><p><strong>现在让我们进入技术设计的详细说明</strong></p><p>由于我们的基础架构由多个小型服务组成，每个服务都在整个系统中具有清晰的职责，因此我们的通知系统也将是一个或几个小型服务，通过同步和异步方法与其他服务进行通信。至少，我们将需要一个后端服务来处理触发器并执行与通知相关的核心操作。</p><h2 id="系统设计"><a href="#系统设计" class="headerlink" title="系统设计"></a>系统设计</h2><p>主要而言，任何通知都将始于一个事件，无论是来自业务服务还是特殊的事件服务。事件本身将被发布到事件总线中。稍后，通知服务（核心服务）将获取通知需要的数据，使用事件提供的数据。然后，它将使用准备/映射的数据来构建一个通知案例，这是处理通知的声明性机制。</p><p>在发送通知之前，它应该被“转换”为特定提供程序/通道期望的一种内容/有效载荷类型。为此，我们使用模板化服务来获取根据特定模板使用数据（参数）和用户语言填充的电子邮件内容。</p><p>对于推送通知或短信通知，这更容易，因为它只是一个文本。因此，我们使用用户语言简单地获取翻译文本并替换参数/属性。</p><p>在翻译方面，每次调用本地化服务都没有意义，因此解决方案可能是临时在每个通知服务副本中本地持久化与通知相关的翻译，并通过简单地轮询以获取本地化服务中的新更改来维护更新。或者我们可以采用基于事件的方法。或者通过维护的分布式缓存机制也可以轻松解决此问题。</p><p>在我们拥有内容/有效载荷之后，通知服务只需通过发送它来向提供程序（通道提供程序）发出 HTTP 调用，然后铃铃铃，我们得到了推送通知。</p><p>此外，通知服务将为用户公开端点，以便获取其通知，将这些标记为已读/未读等。它还将为管理应用程序公开另一组端点，用于管理通知、相关配置等。或者甚至用于创建营销通知，例如警示整个商店折扣。</p><p>基础架构中的通知块将如下图所示：</p><p><img src="https://miro.medium.com/v2/resize:fit:601/1*__c9SfKrNN9Mz91-7-LENA.png" alt="1*__c9SfKrNN9Mz91-7-LENA.png"></p><p>微服务中的通知系统</p><p>在我们确定了高层架构之后，就是深入研究特定组件并通过更具体的设计决策来使这些组件更加清晰。我们可以决定这个服务将使用哪种编程语言。此外，数据库用于存储数据。为了利用严格的模式（在这里我们没有任何任意的数据，一切都是预先决定的）、关系、约束和 ACID，我们选择了关系数据库，如 MySQL 或 PostgreSQL。</p><h2 id="服务架构"><a href="#服务架构" class="headerlink" title="服务架构"></a>服务架构</h2><p>现在让我们设计实体及其关系。</p><p><img src="https://miro.medium.com/v2/resize:fit:700/1*75wkf5igdSJ9xJUpKstZSQ.png" alt="1*75wkf5igdSJ9xJUpKstZSQ.png"></p><p>微服务实体关系图</p><p>上述 ERD 可能会稍微更改以根据公司的需求进行定制。但是，它很简单，已规范化到 5NF，不仅是一个起点，而且是一个最终的模式，只要我们没有可能影响 ERD 的特定要求。当然，我们存在一些冗余，但这不是在服务/数据库级别上，而是在基础架构级别上。例如，这里有一个用户表的小副本，这在微服务中是完全正常的。另一个注意点是，我们不想为用户记录生成主键（PKs），而是使用我们在用户服务中的主用户表中具有的相同 UUID（因为我们知道如果用户未注册，即用户没有在用户服务中的记录，他将不会在此处记录）。在我们的情况下，这种方法的优点大于缺点。</p><p>现在让我们更详细地描述服务。</p><p><strong>消费者</strong></p><p>通知服务有特定于领域的消费者，例如订单消费者，它具有订单相关事件的消费者处理程序。当触发它时，它调用特定于领域的服务，如订单服务。</p><p><strong>服务</strong></p><p>订单服务构建一个名为 Case（通知案例）的实体。订单服务还可以根据需要与其他微服务进行同步通信，以获取构建特定通知案例所需的更多数据。</p><p><strong>案例</strong></p><p>一个 Case 是一个实体，表示一个特定的通知案例，它有一个类型，这是一个具体的通知类型。每个案例都继承了一个称为 BaseCase 的类，它是一个包含一些可重用逻辑、一些抽象属性和方法的抽象类。因此，每个案例都必须在被视为完整通知案例之前实现一些基本要求。在每次触发通知时，都会创建 Case 的新实例，该实例表示发送给一个或多个接收者的特定通知，以及有关如何处理此确切通知的一些指令。它已准备好由通知引擎处理。</p><p><strong>通知引擎</strong></p><p>它是一个小引擎，知道如何处理任何通知案例。我们可以说通知引擎知道如何做，但不知道要做什么。但通知案例对如何做没有任何想法/指示，但知道应该做什么。因此，案例与引擎的协作完成了整个工作。通知引擎是一个小型处理器，可以执行与通知相关的所有例程，例如调用通知服务以在数据库中创建通知和通知接收者记录；调用模板化和翻译服务以准备通知有效载荷；调用通知传输模块（通道提供商）以发送实际通知（如果需要）；甚至知道如何处理可能在流程中发生的常见异常。</p><p>通过采用这种架构，我们可以编写尽可能少的代码来创建新的通知。这就像只需添加特定事件的消费者并创建一个新的通知 Case 类，这就是为一个通知添加更多通知的全部工作。</p><p><strong>模板化模块</strong></p><p>基本上是一个用于模板化服务的 HTTP 提供程序。它使用 HTTP 请求根据特定模板使用数据（参数）和用户语言构建电子邮件内容。</p><p>对于推送通知，它接受翻译后的文本和属性，并返回准备发送的有效载荷。</p><p><strong>本地化模块</strong></p><p>此模块具有两个关键功能：</p><ol><li><p>从本地化微服务请求完整的翻译并维护它。有几种解决方案可以解决翻译的维护问题，如上述，通过轮询获取新的翻译更新、基于事件的更新，或分布式缓存。所有方法都有其优缺点。</p></li><li><p>翻译通知类型。通知案例的翻译变得很容易，因为每个通知案例都有一个通知类型，并且通知翻译键可以通过遵循使用通知类型的约定来创建。例如，</p><p>`app.notifications.cases..title</p><p>app.notifications.cases..body`。</p><p>因此，现在我们可以通过使用此键来获取任何通知案例的正文翻译。</p></li></ol><p><strong>用户模块</strong></p><p>它是公司用户的一个小副本。包括为了发送电子邮件而进行的相同 id，以及用户类型。它还可以具有一些对于通知服务非常重要的额外字段。</p><p>对于推送通知，每个用户可以有一个或多个设备。设备是根据接收者 id（用户 id）在需要构建接收者的通知时获取的，并且也用于通过设备令牌发送通知。</p><p><strong>通道提供商</strong></p><p>这是处理引擎的最后一步，因此它只需调用 <code>provider.send(payload, device)</code>。我们创建自定义客户端，例如，对于 APNS 调用，我们使用 http2 和 p12 证书创建 APNS 客户端，该客户端知道如何发送和处理来自 APNS 的响应，同时<a target="_blank" rel="noopener" href="https://developer.apple.com/documentation/usernotifications/setting_up_a_remote_notification_server/sending_notification_requests_to_apns">发送推送通知</a>。对于电子邮件或 Android 通知也是类似。这样便宜又可靠。正是我们想要的。</p><p><strong>暴露的 API</strong></p><p>我们公开了两种类型的 API：</p><ol><li><p>针对客户（常规用户）至少要</p><p>• 发送设备令牌和其他设备相关信息</p><p>• 列出通知</p><p>• 将一个或多个通知标记为已读/未读</p><p>• 更改与通知相关的首选项</p></li><li><p>针对“管理员”用户以</p><p>• 管理通知</p><p>• 管理各种配置</p><p>• 发送/操作新/现有通知</p><p>• 监视</p></li></ol><p>通知核心服务的简要图示如下：😉</p><p><img src="https://miro.medium.com/v2/resize:fit:700/1*3hVxlKhVGBgRqERO2hGqIg.png" alt="1*3hVxlKhVGBgRqERO2hGqIg.png"></p><p>通知服务架构</p><blockquote><p><em>💡</em>构建通知系统可能会很复杂，但通过采用微服务架构并在识别和隔离每个微服务时做出正确的决策，可以大大减少代码重复并增加系统的模块化和可扩展性。</p></blockquote><blockquote><p>将微服务架构视为可组合的构建块是关键，</p></blockquote><p>通过清晰定义各个组件的职责和交互方式，可以在系统中保持良好的解耦，使系统更容易维护、扩展和创新。</p>]]></content>
      
      
      <categories>
          
          <category> system design </category>
          
      </categories>
      
      
        <tags>
            
            <tag> system design </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>系统设计蓝图 / 备忘单</title>
      <link href="2023/08/12/systemDesign-system-road/"/>
      <url>2023/08/12/systemDesign-system-road/</url>
      
        <content type="html"><![CDATA[<p>开发一个强大、可扩展和高效的系统可能会令人望而却步。然而，了解关键概念和组件可以使这个过程更可管理。在本博客文章中，我们将探讨系统设计的关键概念和组件，如DNS、负载均衡、API网关等，以及一个简明的备忘单，可以帮助开发人员设计不同复杂性的系统。</p><h1 id="系统设计蓝图-备忘单"><a href="#系统设计蓝图-备忘单" class="headerlink" title="系统设计蓝图 / 备忘单"></a>系统设计蓝图 / 备忘单</h1><p>这是一份全面的视觉指南，为开发人员提供了一个快速、简单的参考，涵盖了系统设计中的关键概念和最佳实践。这个便捷的备忘单或蓝图涵盖了诸如DNS、负载均衡、API网关、视频和图像处理、缓存、数据库、唯一ID生成、支付和推荐服务等标准组件，以及聊天和流媒体协议。有了这个宝贵的资源，你将能够应对设计和实施可扩展、高效和可靠系统的挑战。</p><p><img src="https://miro.medium.com/v2/resize:fit:2000/1*QSFihi7zXbR5X915MDmKyQ.png" alt="1*QSFihi7zXbR5X915MDmKyQ.png"></p><span id="more"></span><h1 id="第一部分：系统设计原则"><a href="#第一部分：系统设计原则" class="headerlink" title="第一部分：系统设计原则"></a>第一部分：系统设计原则</h1><h2 id="1-1：模块化"><a href="#1-1：模块化" class="headerlink" title="1.1：模块化"></a>1.1：模块化</h2><p>将系统划分为更小、更可管理的模块有助于减少复杂性、提高可维护性和增加可重用性。</p><h2 id="1-2：抽象化"><a href="#1-2：抽象化" class="headerlink" title="1.2：抽象化"></a>1.2：抽象化</h2><p>隐藏实现细节，只显示必要的特性有助于简化复杂的系统并促进模块化。</p><h2 id="1-3：分层"><a href="#1-3：分层" class="headerlink" title="1.3：分层"></a>1.3：分层</h2><p>将系统组织成不同的层次，每个层次提供特定的功能集，促进关注点分离，增强可维护性。</p><h2 id="1-4：可扩展性"><a href="#1-4：可扩展性" class="headerlink" title="1.4：可扩展性"></a>1.4：可扩展性</h2><p>通过添加更多资源（横向扩展）或优化系统容量（纵向扩展）来设计系统以处理增加的负载。</p><h2 id="1-5：性能"><a href="#1-5：性能" class="headerlink" title="1.5：性能"></a>1.5：性能</h2><p>优化系统的响应时间、吞吐量和资源利用率对于成功的设计至关重要。</p><h2 id="1-6：安全性"><a href="#1-6：安全性" class="headerlink" title="1.6：安全性"></a>1.6：安全性</h2><p>通过实施适当的安全措施和实践，确保系统的机密性、完整性和可用性。</p><h2 id="1-7：容错和弹性"><a href="#1-7：容错和弹性" class="headerlink" title="1.7：容错和弹性"></a>1.7：容错和弹性</h2><p>设计系统以经受故障，并从错误中恢复，确保可靠性和可用性。</p><h1 id="第二部分：系统设计的关键组件"><a href="#第二部分：系统设计的关键组件" class="headerlink" title="第二部分：系统设计的关键组件"></a>第二部分：系统设计的关键组件</h1><h2 id="2-1：DNS（域名系统）"><a href="#2-1：DNS（域名系统）" class="headerlink" title="2.1：DNS（域名系统）"></a>2.1：DNS（域名系统）</h2><p>DNS是一个分层和去中心化的命名系统，用于将连接到Internet或私有网络的计算机、服务或其他资源的人类可读域名（<a target="_blank" rel="noopener" href="http://例如www.example.com/">例如www.example.com</a>）转换为IP地址，使用户能够更有效地访问网站和服务。</p><p><img src="https://miro.medium.com/v2/resize:fit:1400/1*ER77NyMrUYhlYcdj81rgxA.png" alt="1*ER77NyMrUYhlYcdj81rgxA.png"></p><h2 id="2-2：负载均衡"><a href="#2-2：负载均衡" class="headerlink" title="2.2：负载均衡"></a>2.2：负载均衡</h2><p>负载均衡是指将网络流量分布到多个服务器上，以确保没有单个服务器被过载。这种方法可以提高系统的可用性、可靠性和性能。常见的负载均衡算法包括循环调度、最小连接数和IP哈希</p><h2 id="2-3：API网关"><a href="#2-3：API网关" class="headerlink" title="2.3：API网关"></a>2.3：API网关</h2><p>API网关是在分布式系统中充当客户端和微服务之间中介的服务器。它管理和路由请求，强制执行安全策略，并可以提供附加功能，如缓存、日志记录和监控。</p><h2 id="2-4：内容分发网络（CDN）"><a href="#2-4：内容分发网络（CDN）" class="headerlink" title="2.4：内容分发网络（CDN）"></a>2.4：内容分发网络（CDN）</h2><p>CDN是一个分布在各个位置的服务器网络，旨在以较低的延迟和更高的带宽向用户提供内容。CDN在靠近终端用户的边缘服务器上缓存内容，提高系统的性能，并减少对源服务器的负载</p><h2 id="2-5：消息队列"><a href="#2-5：消息队列" class="headerlink" title="2.5：消息队列"></a>2.5：消息队列</h2><p>消息队列通过临时将消息存储在队列中促进分布式系统组件之间的通信。它们支持异步处理，并帮助解耦组件，提高系统的可扩展性和容错性。</p><h2 id="2-6：通信协议"><a href="#2-6：通信协议" class="headerlink" title="2.6：通信协议"></a>2.6：通信协议</h2><p>系统设计中使用不同的通信协议，如HTTP/HTTPS、WebSocket和gRPC。这些协议具有各自的优点和权衡，选择取决于延迟、安全性和数据传输要求等因素。</p><h2 id="2-7：缓存"><a href="#2-7：缓存" class="headerlink" title="2.7：缓存"></a>2.7：缓存</h2><p>缓存是一种临时技术，用于存</p><p>储数据的副本，以便在将来的请求中更快地检索。它有助于减少延迟、服务器负载和带宽消耗。常见的缓存机制包括内存缓存、分布式缓存和浏览器缓存</p><h2 id="2-8：数据库"><a href="#2-8：数据库" class="headerlink" title="2.8：数据库"></a>2.8：数据库</h2><p>选择适合系统的数据库取决于数据结构、可扩展性、一致性和延迟。常见的数据库类型包括关系数据库（如MySQL、PostgreSQL）、NoSQL数据库（如MongoDB、Cassandra）和NewSQL数据库（如Cockroach DB、Google Spanner）。</p><h2 id="2-9：复制技术"><a href="#2-9：复制技术" class="headerlink" title="2.9：复制技术"></a>2.9：复制技术</h2><p>复制是在不同节点上维护多个数据副本以增加可靠性、可用性和容错性的过程。常见的复制技术包括同步复制、异步复制和半同步复制。</p><h2 id="2-10：分布式唯一ID生成"><a href="#2-10：分布式唯一ID生成" class="headerlink" title="2.10：分布式唯一ID生成"></a>2.10：分布式唯一ID生成</h2><p>在分布式系统中创建唯一标识符可能具有挑战性，但对于保持数据一致性和完整性非常重要。</p><h1 id="第三部分：使用签名URL以块的形式上传视频和图像"><a href="#第三部分：使用签名URL以块的形式上传视频和图像" class="headerlink" title="第三部分：使用签名URL以块的形式上传视频和图像"></a>第三部分：使用签名URL以块的形式上传视频和图像</h1><p>在本节中，我们将探讨如何使用签名URL以块的形式上传大型视频和图像文件。这种方法可以显著提高文件上传的效率和可靠性，特别是在网络条件不理想的情况下。</p><h2 id="3-1：什么是签名URL？"><a href="#3-1：什么是签名URL？" class="headerlink" title="3.1：什么是签名URL？"></a>3.1：什么是签名URL？</h2><p>签名URL是专门设计的URL，授予对特定资源（如云存储中的对象）的临时安全访问权限。这些URL包含一个认证签名，允许用户在有限的时间内执行特定操作，例如上传或下载文件。常见的云存储提供商如Amazon S3和Google Cloud Storage支持生成签名URL。以下是签名URL的一个示例：</p><p><a target="_blank" rel="noopener" href="https://example-bucket.s3.amazonaws.com/my-file.txt">https://example-bucket.s3.amazonaws.com/my-file.txt</a>?</p><p>X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;</p><p>X-Amz-Credential=AKIAIOSFODNN7EXAMPLE%2F20220407%2Fus-east-1%2Fs3%2Faws4_request&amp;</p><p>X-Amz-Date=20220407T123456Z&amp;</p><p>X-Amz-Expires=3600&amp;</p><p>X-Amz-SignedHeaders=host&amp;</p><p>X-Amz-Signature=a9c8a7d1644c7b351ef3034f4a1b4c9047e891c7203eb3a9f29d8c7a74676d88</p><h2 id="3-2：以块的形式上传"><a href="#3-2：以块的形式上传" class="headerlink" title="3.2：以块的形式上传"></a>3.2：以块的形式上传</h2><p>将大型文件作为单个请求上传可能会导致超时、高内存消耗以及由于网络不稳定而增加故障风险。相反，将大型文件分成较小的块，并按顺序或并行方式上传，可以提高上传效率和可靠性。这种方法被称为“块式”或“多部分”上传。</p><h2 id="3-3：结合签名URL和块式上传"><a href="#3-3：结合签名URL和块式上传" class="headerlink" title="3.3：结合签名URL和块式上传"></a>3.3：结合签名URL和块式上传</h2><p>要使用签名URL以块的形式上传视频和图像文件，请按照以下一般步骤进行操作：</p><ol><li><strong>将文件分成较小的块</strong>：在客户端上使用JavaScript将大型文件拆分成较小的块。块的大小可以根据需要进行调整，但平衡请求数量和每个块的大小以优化上传性能是重要的。</li><li><strong>为每个块请求签名URL</strong>：向服务器发送请求，为每个块生成一个具有适当权限和过期时间的签名URL，并将其返回给客户端。</li><li><strong>使用签名URL上传块</strong>：使用签名URL将每个块上传到云存储服务。根据所需的并发级别和网络条件，可以顺序或并行地进行这些上传。</li><li><strong>确认成功上传并重新组装</strong>：一旦所有块都成功上传，通知服务器确认上传过程的完成。然后，服务器可以重新组装块为原始文件，并执行任何必要的处理或验证。</li><li><strong>处理上传失败</strong>：如果任何块上传失败，可以使用新的签名URL重试上传，或者实施错误处理策略以确保平滑的用户体验。</li></ol><p>通过使用签名URL和块式上传，开发人员可以高效、安全地处理大型视频和图像上传，提高系统的可靠性和性能。</p><h1 id="第四部分：聊天和流媒体协议"><a href="#第四部分：聊天和流媒体协议" class="headerlink" title="第四部分：聊天和流媒体协议"></a>第四部分：聊天和流媒体协议</h1><p>本节将讨论各种聊天和流媒体协议，促进客户端和服务器之间的实时通信和数据流传输。了解这些协议可以帮助开发人员构建响应快、交互式的应用程序。</p><h2 id="4-1：RTMP（实时消息传输协议）"><a href="#4-1：RTMP（实时消息传输协议）" class="headerlink" title="4.1：RTMP（实时消息传输协议）"></a>4.1：RTMP（实时消息传输协议）</h2><p>RTMP是由Adobe Systems开发的用于在Internet上流式传输音频、视频和数据的专有协议。它通常用于视频流应用程序，提供客户端和服务器之间的低延迟通信。然而，由于其依赖Flash Player，它在近年来的流行度有所下降。</p><h2 id="4-2：WebRTC（Web实时通信）"><a href="#4-2：WebRTC（Web实时通信）" class="headerlink" title="4.2：WebRTC（Web实时通信）"></a>4.2：WebRTC（Web实时通信）</h2><p>WebRTC是一个开源项目，可以在Web浏览器和移动应用程序中实现实时音频、视频和数据通信。它支持点对点连接，降</p><p>低延迟和服务器负载。WebRTC广泛应用于视频会议、在线游戏和其他需要实时通信的应用程序。</p><h2 id="4-3：WebSocket"><a href="#4-3：WebSocket" class="headerlink" title="4.3：WebSocket"></a>4.3：WebSocket</h2><p>WebSocket是一种通信协议，可以在客户端和服务器之间建立双向、全双工的通信连接。由于其低延迟和高效的通信能力，WebSocket通常用于聊天、通知和实时更新等实时应用程序。</p><h2 id="4-4：SSE（服务器推送事件）"><a href="#4-4：SSE（服务器推送事件）" class="headerlink" title="4.4：SSE（服务器推送事件）"></a>4.4：SSE（服务器推送事件）</h2><p>服务器推送事件（SSE）是一种技术，使服务器能够通过HTTP连接向客户端推送更新。它设计用于服务器向客户端进行单向实时通信，适用于实时更新、新闻提要和通知等应用程序。</p><h2 id="4-5：HTTP短轮询"><a href="#4-5：HTTP短轮询" class="headerlink" title="4.5：HTTP短轮询"></a>4.5：HTTP短轮询</h2><p>短轮询涉及客户端反复向服务器发送HTTP请求以检查新的更新。虽然实现简单，但短轮询可能会导致高服务器负载和增加的延迟，特别是当更新不频繁时。</p><h2 id="4-6：HTTP长轮询"><a href="#4-6：HTTP长轮询" class="headerlink" title="4.6：HTTP长轮询"></a>4.6：HTTP长轮询</h2><p>长轮询是对短轮询的改进，其中客户端发送请求到服务器，服务器保持请求打开，直到有新数据可用。这种方法减少了请求的数量和服务器负载，但仍可能存在延迟问题，并需要对服务器资源进行谨慎管理。</p><h2 id="4-7：Webhook"><a href="#4-7：Webhook" class="headerlink" title="4.7：Webhook"></a>4.7：Webhook</h2><p>Webhook是由系统中特定事件触发的用户定义的HTTP回调。当事件发生时，源站点向为Webhook配置的URL发出HTTP请求。这种方法允许不同系统或服务之间进行高效的事件驱动通信。</p><h2 id="4-8：流式API"><a href="#4-8：流式API" class="headerlink" title="4.8：流式API"></a>4.8：流式API</h2><p>流式API允许客户端从服务器消费连续的数据流，通常使用HTTP或WebSocket连接。这些API设计用于需要实时更新的应用程序，例如社交媒体动态、股票市场数据或实时分析。</p><p>通过了解和利用这些聊天和流媒体协议，开发人员可以构建响应快、实时的应用程序，满足各种用例，并提供引人入胜的用户体验。</p><h1 id="第五部分：系统设计中的常见组件"><a href="#第五部分：系统设计中的常见组件" class="headerlink" title="第五部分：系统设计中的常见组件"></a>第五部分：系统设计中的常见组件</h1><p>本节将探讨现代系统设计中常见的一些标准组件。了解这些组件可以帮助开发人员将其无缝集成到系统中，并增强整体功能。</p><h2 id="5-1：支付服务"><a href="#5-1：支付服务" class="headerlink" title="5.1：支付服务"></a>5.1：支付服务</h2><p>支付服务处理客户和企业之间的交易。集成可靠的支付服务对于电子商务和订阅型平台至关重要。常见的支付服务提供商包括Stripe、PayPal和Square。这些服务通常提供API以便于安全的交易处理和管理重复付款、退款等。</p><h2 id="5-2：分析服务"><a href="#5-2：分析服务" class="headerlink" title="5.2：分析服务"></a>5.2：分析服务</h2><p>分析服务实现数据收集、处理和可视化，帮助企业做出明智决策。这些服务可以跟踪用户行为、监控系统性能和分析趋势。常见的分析服务提供商包括Google Analytics、Mixpanel和Amplitude。将分析服务集成到系统中可以帮助企业优化其产品并改善用户体验。</p><h2 id="5-3：通知"><a href="#5-3：通知" class="headerlink" title="5.3：通知"></a>5.3：通知</h2><p>通知服务使用户及时了解更新、警报和重要信息。这些服务可以通过电子邮件、短信和推送通知等多种渠道传递通知。通知服务提供商的示例包括Firebase Cloud Messaging (FCM)、Amazon Simple Notification Service (SNS)和Twilio。</p><h2 id="5-4：搜索"><a href="#5-4：搜索" class="headerlink" title="5.4：搜索"></a>5.4：搜索</h2><p>集成强大的搜索组件对于具有大量数据或内容的系统至关重要。搜索服务应提供快速、相关和可扩展的搜索功能。Elasticsearch、Apache Solr和Amazon CloudSearch是实现搜索功能的常用选择。这些服务通常支持全文搜索、分面搜索和过滤，使用户能够快速高效地找到所需的信息。</p><h2 id="5-5：推荐服务"><a href="#5-5：推荐服务" class="headerlink" title="5.5：推荐服务"></a>5.5：推荐服务</h2><p>推荐服务使用算法根据用户的偏好、行为和其他因素提供个性化建议。这些服务可以显著提高用户参与度和满意度。生成推荐的技术包括协同过滤、基于内容的过滤和混合方法。机器学习算法，如矩阵分解和深度学习，也可以用于生成更复杂的推荐。</p><p>通过将这些标准组件整合到系统设计中，开发人员可以增强其应用程序的功能，并为用户提供更流畅和引人入胜的体验。</p><h1 id="第六部分：系统设计的最佳实践"><a href="#第六部分：系统设计的最佳实践" class="headerlink" title="第六部分：系统设计的最佳实践"></a>第六部分：系统设计的最佳实践</h1><h2 id="6-1：需求收集"><a href="#6-1：需求收集" class="headerlink" title="6.1：需求收集"></a>6.1：需求收集</h2><p>在开始设计过程之前，充分了解并记录系统需求。</p><h2 id="6-2：设计模式"><a href="#6-2：设计模式" class="headerlink" title="6.2：设计模式"></a>6.2：设计模式</h2><p>利用经过验证的设计模式来解决反复出现的设计问题，改进整体架构。</p><h2 id="6-3：文档"><a href="#6-3：文档" class="headerlink" title="6.3：文档"></a>6.3：文档</h2><p>记录设计决策、假设和基本原理，以确保更好的沟通和可维护性。</p><h2 id="6-4：迭代设计"><a href="#6-4：迭代设计" class="headerlink" title="6.4：迭代设计"></a>6.4：迭代设计</h2><p>通过多次迭代和反馈改进设计，使其不断演进和改进。</p><h2 id="6-5：测试和验证"><a href="#6-5：测试和验证" class="headerlink" title="6.5：测试和验证"></a>6.5：测试和验证</h2><p>根据要求验证设计并进行测试，以识别和解决潜在问题。</p><h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p>总之，系统设计是一个多方面、复杂的过程，需要深入了解各种组件、协议和技术。本博客文章概述了关键主题，如DNS、负载均衡、API网关、</p><p>缓存、数据库和聊天/流媒体协议等。同时，提供了一个系统设计蓝图/备忘单，可帮助开发人员设计和实施各种复杂性的系统。</p><p>通过理解系统设计原则和最佳实践，开发人员可以设计出强大、可扩展和高效的系统，满足用户需求并提供卓越的用户体验。</p><p>然而，需要注意的是，系统设计是一个不断演化和改进的过程。根据具体的应用场景和需求，开发人员应灵活应对，并根据实际情况做出相应的调整和优化。随着技术的不断发展和创新，也要保持对新技术和趋势的关注，以不断提升系统设计的能力和效果。</p>]]></content>
      
      
      <categories>
          
          <category> system design </category>
          
      </categories>
      
      
        <tags>
            
            <tag> system design </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Discord如何存储数万亿条消息</title>
      <link href="2023/04/01/discord/"/>
      <url>2023/04/01/discord/</url>
      
        <content type="html"><![CDATA[<p>Discord是一款专为社群设计的免费网络实时通话软件与数字发行平台，主要针对游戏玩家、教育人士、朋友及商业人士，用户之间可以在软体的聊天频道通过消息、图片、视频和音频进行交流。这款软件可以在Microsoft Windows、macOS、Android、iOS、Linux和网页上运行。</p><p>下面的图展示了Discord消息存储的演变历程：</p><p><img src="https://res.craft.do/user/full/8cf3a6c7-2a00-8ee8-0195-0eb38fda2eeb/5915084F-1F12-445D-B6F4-BE12D63C75AE_2/y6PCZxe8EwmpdNacqIRuPwKScgJthxcgJyg1eKOEYdsz/67b3962d-becb-4fba-a9ae-115692dfa6e1_3576x3033.jpeg" alt="67b3962d-becb-4fba-a9ae-115692dfa6e1_3576x3033.jpeg"></p><span id="more"></span><p>MongoDB ➡️ Cassandra ➡️ ScyllaDB</p><p>2015年，Discord的第一个版本建立在一个单独的MongoDB副本之上。到了2015年11月左右，MongoDB存储了1亿条消息，但是RAM已经无法再容纳数据和索引了。此时延迟变得不可预测。因此，需要将消息存储转移到另一个数据库。最终选择了Cassandra。</p><p>2017年，Discord有12个Cassandra节点，并存储了数十亿条消息。</p><p>到2022年初，它已经有177个节点，并存储了数万亿条消息。此时，延迟变得不可预测，并且维护操作的成本变得太高。</p><p>问题的原因有以下几点：</p><ul><li>Cassandra使用LSM树作为内部数据结构。读操作比写操作更昂贵。在具有数百个用户的服务器上可能有很多并发读取，从而导致热点问题。</li><li>维护集群（如压缩SSTables）会影响性能。</li><li>垃圾回收暂停会导致显著的延迟峰值。</li></ul><p>ScyllaDB是一个兼容Cassandra的数据库，用C++编写。Discord重新设计了其架构，具有单片API、用Rust编写的数据服务和基于ScyllaDB的存储。</p><p>在ScyllaDB中，p99读取延迟为15毫秒，而Cassandra中为40-125毫秒。p99写入延迟为5毫秒，而Cassandra中为5-70毫秒。</p><p>ScyllaDB是一个快速、可扩展和高可用的分布式数据库，适用于大规模数据处理和高吞吐量应用程序。它已被广泛应用于云计算、物联网、金融服务、在线广告和游戏等领域，被视为具有很高性价比的数据库解决方案。</p><p>以下是一个使用 Java 驱动程序连接 ScyllaDB 并执行查询的示例</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">import com.datastax.driver.core.*;</span><br><span class="line"></span><br><span class="line">public class ScyllaDBExample &#123;</span><br><span class="line">  public static void main(String[] args) &#123;</span><br><span class="line">    &#x2F;&#x2F; Connect to the cluster and keyspace</span><br><span class="line">    Cluster cluster &#x3D; Cluster.builder().addContactPoint(&quot;127.0.0.1&quot;).build();</span><br><span class="line">    Session session &#x3D; cluster.connect(&quot;test&quot;);</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; Execute a simple query</span><br><span class="line">    ResultSet results &#x3D; session.execute(&quot;SELECT * FROM users&quot;);</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; Print the results</span><br><span class="line">    for (Row row : results) &#123;</span><br><span class="line">      System.out.format(&quot;%d %s %s\n&quot;, row.getInt(&quot;id&quot;), row.getString(&quot;name&quot;), row.getString(&quot;email&quot;));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; Close the session and cluster</span><br><span class="line">    session.close();</span><br><span class="line">    cluster.close();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个例子使用 DataStax Java 驱动程序连接 ScyllaDB 并执行一个简单的查询来获取所有用户的记录。它打印查询结果，然后关闭会话和集群。</p><p>要运行这个示例，你需要将 DataStax Java 驱动程序添加到你的 Java 项目中。可以通过 Maven 或 Gradle 添加以下依赖项：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">  &lt;groupId&gt;com.datastax.cassandra&lt;&#x2F;groupId&gt;</span><br><span class="line">  &lt;artifactId&gt;cassandra-driver-core&lt;&#x2F;artifactId&gt;</span><br><span class="line">  &lt;version&gt;4.14.0&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure><p>在这个示例中，我们使用了默认的本地节点 IP 地址 127.0.0.1，也可以使用 ScyllaDB 集群中的其他节点 IP 地址。在实际应用中，建议使用连接池和预处理语句来提高性能。</p><p>参考资料：</p><p><a target="_blank" rel="noopener" href="http://scylladb.com/product/technology/shard-per-core-architecture/">scylladb.com/product/technology/shard-per-core-architecture/</a></p><p><a target="_blank" rel="noopener" href="http://discord.com/blog/how-discord-stores-trillions-of-messages">discord.com/blog/how-discord-stores-trillions-of-messages</a></p>]]></content>
      
      
      <categories>
          
          <category> 设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>什么是gRPC？有什么优点？</title>
      <link href="2023/04/01/grpc/"/>
      <url>2023/04/01/grpc/</url>
      
        <content type="html"><![CDATA[<p>RPC（远程过程调用）被称为“远程”，是因为它可以在微服务架构下将服务部署在不同的服务器上时，在远程服务之间进行通信。从用户的角度来看，它就像是一个本地函数调用。</p><p>下面的图表说明了gRPC的整体数据流程。</p><p><img src="https://res.craft.do/user/full/8cf3a6c7-2a00-8ee8-0195-0eb38fda2eeb/5610CB5D-8792-4108-B0B9-D1582C6C9B59_2/bOxnEzyEycV4MsFrPOFkkGcHzgT4O1YNv1fHHOJTy6kz/b98afdcd-b567-4c90-9f47-5358df0adda6_1280x1619.jpeg" alt="b98afdcd-b567-4c90-9f47-5358df0adda6_1280x1619.jpeg"></p><span id="more"></span><p>第1步：客户端发出REST调用。请求正文通常以JSON格式呈现。</p><p>第2-4步：订单服务（gRPC客户端）接收REST调用，对其进行转换，并向付款服务发出RPC调用。gPRC将客户端存根编码为二进制格式并将其发送到底层传输层。</p><p>第5步：gRPC通过HTTP2将数据包通过网络发送。由于二进制编码和网络优化，gRPC的速度比JSON快5倍。</p><p>第6-8步：付款服务（gRPC服务器）接收来自网络的数据包，对其进行解码并调用服务器应用程序。</p><p>第9-11步：结果从服务器应用程序返回，并被编码并发送到传输层。</p><p>第12-14步：订单服务接收数据包，对其进行解码，并将结果发送到客户端应用程序。</p><p>在使用gRPC时，需要定义protobuf消息和服务定义。protobuf消息是通信中传输的数据类型，而服务定义则描述了如何使用这些消息来实现RPC方法。</p><h3 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h3><p>下面是一个使用gRPC实现简单加法功能的代码示例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">syntax &#x3D; &quot;proto3&quot;;</span><br><span class="line">package calculator;</span><br><span class="line"></span><br><span class="line">service Calculator &#123;</span><br><span class="line">  rpc Add (AddRequest) returns (AddResponse) &#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">message AddRequest &#123;</span><br><span class="line">  int32 a &#x3D; 1;</span><br><span class="line">  int32 b &#x3D; 2;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">message AddResponse &#123;</span><br><span class="line">  int32 result &#x3D; 1;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的代码定义了一个名为<code>Calculator</code>的服务，该服务具有一个名为<code>Add</code>的RPC方法。此方法将一个请求消息<code>AddRequest</code>作为输入，并返回一个响应消息<code>AddResponse</code>。</p><p><code>AddRequest</code>和<code>AddResponse</code>是protobuf消息。它们都具有简单的整数字段。<code>AddRequest</code>包含两个整数字段a和b，表示要相加的两个数字。<code>AddResponse</code>包含一个整数字段result，表示加法的结果。</p><p>现在，我们需要在客户端和服务器上实现这个服务。在开始实现客户端代码之前，需要先引入gRPC依赖库。可以通过在Maven或Gradle中添加以下依赖项来实现：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; Maven</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">  &lt;groupId&gt;io.grpc&lt;&#x2F;groupId&gt;</span><br><span class="line">  &lt;artifactId&gt;grpc-netty-shaded&lt;&#x2F;artifactId&gt;</span><br><span class="line">  &lt;version&gt;1.42.0&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; Gradle</span><br><span class="line">implementation &#39;io.grpc:grpc-netty-shaded:1.42.0&#39;</span><br></pre></td></tr></table></figure><p>接下来，我们可以编写一个简单的Java客户端程序来调用我们之前定义的加法服务</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">import io.grpc.ManagedChannel;</span><br><span class="line">import io.grpc.ManagedChannelBuilder;</span><br><span class="line">import io.grpc.StatusRuntimeException;</span><br><span class="line">import com.example.grpc.AddRequest;</span><br><span class="line">import com.example.grpc.AddResponse;</span><br><span class="line">import com.example.grpc.MathServiceGrpc;</span><br><span class="line"></span><br><span class="line">public class MathClient &#123;</span><br><span class="line">    private final ManagedChannel channel;</span><br><span class="line">    private final MathServiceGrpc.MathServiceBlockingStub blockingStub;</span><br><span class="line"></span><br><span class="line">    public MathClient(String host, int port) &#123;</span><br><span class="line">        channel &#x3D; ManagedChannelBuilder.forAddress(host, port)</span><br><span class="line">                .usePlaintext()</span><br><span class="line">                .build();</span><br><span class="line">        blockingStub &#x3D; MathServiceGrpc.newBlockingStub(channel);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void shutdown() throws InterruptedException &#123;</span><br><span class="line">        channel.shutdown().awaitTermination(5, TimeUnit.SECONDS);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void add(int a, int b) &#123;</span><br><span class="line">        AddRequest request &#x3D; AddRequest.newBuilder()</span><br><span class="line">                .setA(a)</span><br><span class="line">                .setB(b)</span><br><span class="line">                .build();</span><br><span class="line">        AddResponse response;</span><br><span class="line">        try &#123;</span><br><span class="line">            response &#x3D; blockingStub.add(request);</span><br><span class="line">        &#125; catch (StatusRuntimeException e) &#123;</span><br><span class="line">            System.err.println(&quot;RPC failed: &quot; + e.getStatus());</span><br><span class="line">            return;</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(&quot;Result: &quot; + response.getResult());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws Exception &#123;</span><br><span class="line">        MathClient client &#x3D; new MathClient(&quot;localhost&quot;, 50051);</span><br><span class="line">        try &#123;</span><br><span class="line">            client.add(1, 2);</span><br><span class="line">        &#125; finally &#123;</span><br><span class="line">            client.shutdown();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在此代码中，我们首先创建了一个<code>ManagedChannel</code>实例，该实例连接到我们的服务器。然后，我们使用这个<code>ManagedChannel</code>实例创建一个新的<code>MathServiceGrpc.MathServiceBlockingStub</code>实例，该实例是通过gRPC自动生成的，可以用来调用我们定义的加法方法。</p><p>在<code>add</code>方法中，我们首先构建一个<code>AddRequest</code>实例，该实例包含了我们需要相加的两个整数。然后，我们使用我们之前创建的<code>MathServiceGrpc.MathServiceBlockingStub</code>实例调用<code>add</code>方法，并传递这个<code>AddRequest</code>实例作为参数。最后，我们将结果打印出来。</p><p>在<code>main</code>方法中，我们创建一个新的<code>MathClient</code>实例，并使用它来调用<code>add</code>方法。最后，我们在<code>finally</code>块中关闭了<code>MathClient</code>实例。</p><p>这个Java客户端代码可以通过以下命令来编译：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ javac MathClient.java</span><br></pre></td></tr></table></figure><p>然后，我们可以使用以下命令来运行它：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ java MathClient</span><br></pre></td></tr></table></figure><p>运行这个程序后，将输出以下内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Result: 3</span><br></pre></td></tr></table></figure><p>这表明我们的加法服务已经成功地在客户端和服务器之间通信了。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul><li>gRPC可以实现简单的RPC方法，在客户端和服务器之间成功地进行通信。</li><li>protobuf消息和服务定义使得定义和使用RPC方法更容易。</li><li>gRPC提供高效的网络传输和编码，从而提高了通信速度和可靠性。</li><li>gRPC为开发人员提供了轻松构建分布式系统的强大工具。</li><li>在微服务架构下，gRPC使服务之间的通信更加容易和高效。</li><li>在实际开发中需要注意潜在的问题，例如网络延迟和数据大小限制，需要仔细设计服务接口和消息类型，以确保通信的稳定性和可靠性。</li><li>gRPC是值得尝试的分布式系统开发工具，提供高效的RPC通信和易于使用的接口定义。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用OpenAI的ChatGPT进行智能问答交互的实现</title>
      <link href="2023/03/11/gpt-%E4%BD%BF%E7%94%A8OpenAI%E7%9A%84ChatGPT%E8%BF%9B%E8%A1%8C%E6%99%BA%E8%83%BD%E9%97%AE%E7%AD%94%E4%BA%A4%E4%BA%92%E7%9A%84%E5%AE%9E%E7%8E%B0/"/>
      <url>2023/03/11/gpt-%E4%BD%BF%E7%94%A8OpenAI%E7%9A%84ChatGPT%E8%BF%9B%E8%A1%8C%E6%99%BA%E8%83%BD%E9%97%AE%E7%AD%94%E4%BA%A4%E4%BA%92%E7%9A%84%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<p><img src="https://res.craft.do/user/full/d3f184bd-2fc6-ae80-c9ed-d9b26e0cd7ba/doc/99C67034-A284-44CC-BA81-7A7B4D3DCA90/43D821FF-FDCD-4E5A-9C9F-BD794E1D6E9A_2/NhN9dKLPx9s5yKJFd9dGhJXkmymvbS4to6YKR3NFu5Az/Image.png" alt="Image.png"></p><p>当使用 ChatGPT 进行问答交互时，用户输入的问题需要经过多个组件进行处理，其中包括内容审核、ChatGPT 模型生成回答以及回答的内容审核等。在本文中，我们将详细介绍 ChatGPT 的工作原理，并提供相应的代码示例。</p><span id="more"></span><h2 id="ChatGPT-的工作原理"><a href="#ChatGPT-的工作原理" class="headerlink" title="ChatGPT 的工作原理"></a>ChatGPT 的工作原理</h2><h3 id="1-模型训练"><a href="#1-模型训练" class="headerlink" title="1. 模型训练"></a>1. 模型训练</h3><p>ChatGPT 是基于 GPT 模型的变种之一，GPT（Generative Pre-trained Transformer）是一种基于 Transformer 的无监督语言模型。ChatGPT 是在 GPT 模型的基础上进行微调得到的，它使用了类似于语言模型的方式来生成回答。</p><h3 id="2-问答交互过程"><a href="#2-问答交互过程" class="headerlink" title="2. 问答交互过程"></a>2. 问答交互过程</h3><p>当用户输入问题并提交后，ChatGPT 模型开始进行处理。整个过程主要分为以下几个步骤：</p><h4 id="2-1-内容审核"><a href="#2-1-内容审核" class="headerlink" title="2.1 内容审核"></a>2.1 内容审核</h4><p>用户输入的问题首先会经过内容审核组件进行处理。该组件负责检测问题是否包含敏感信息、违规内容等，确保问题的安全性和合法性。如果问题未通过内容审核，则会直接返回固定的提示信息。</p><h4 id="2-2-ChatGPT-模型生成回答"><a href="#2-2-ChatGPT-模型生成回答" class="headerlink" title="2.2 ChatGPT 模型生成回答"></a>2.2 ChatGPT 模型生成回答</h4><p>如果问题通过了内容审核，它将被送往 ChatGPT 模型进行处理。ChatGPT 模型使用了前文提到的 GPT 模型，对于输入的问题，模型会生成一个相应的回答。</p><h4 id="2-3-回答内容审核"><a href="#2-3-回答内容审核" class="headerlink" title="2.3 回答内容审核"></a>2.3 回答内容审核</h4><p>在生成回答后，回答会再次经过内容审核组件进行处理。该组件主要检测回答是否包含敏感信息、违规内容、不当言论等，确保回答的安全性和合法性。如果回答未通过内容审核，则会直接返回固定的提示信息。</p><h4 id="2-4-返回结果"><a href="#2-4-返回结果" class="headerlink" title="2.4 返回结果"></a>2.4 返回结果</h4><p>如果回答通过了内容审核，则会将回答展示给用户；否则，将返回固定的提示信息。整个过程中，ChatGPT 还会对用户的提问行为进行学习，以不断优化生成的回答。</p><h2 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h2><p>下面是一个简单的 Python 代码示例，它展示了如何使用 ChatGPT 进行问答交互。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">import openai</span><br><span class="line">import re</span><br><span class="line"></span><br><span class="line"># 定义 OpenAI API 访问密钥</span><br><span class="line">openai.api_key &#x3D; &quot;YOUR_API_KEY&quot;</span><br><span class="line"></span><br><span class="line"># 定义问题和模型 ID</span><br><span class="line">question &#x3D; &quot;Explain how a classification algorithm works&quot;</span><br><span class="line">model_engine &#x3D; &quot;davinci&quot;</span><br><span class="line"></span><br><span class="line"># 进行内容审核</span><br><span class="line">def content_moderation(text):</span><br><span class="line">    # 检测敏感信息</span><br><span class="line">    if re.search(&#39;敏感词&#39;, text, re.IGNORECASE):</span><br><span class="line">        return &quot;Sorry, your question contains sensitive information.&quot;</span><br><span class="line">    # 检测违规内容</span><br><span class="line">    elif re.search(&#39;违规词&#39;, text, re.IGNORECASE):</span><br><span class="line">        return &quot;Sorry, your question contains inappropriate</span><br></pre></td></tr></table></figure><p>接下来，我们来演示如何使用ChatGPT进行问答交互。</p><p>首先，我们需要使用OpenAI提供的API key来创建一个OpenAI API client。在代码中，我们使用了openai包提供的API类来创建一个API client：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import openai</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">openai.api_key &#x3D; os.environ[&quot;OPENAI_API_KEY&quot;]</span><br><span class="line">api &#x3D; openai.api_key</span><br></pre></td></tr></table></figure><p>接下来，我们需要指定一个prompt，即用户提出的问题。在本例中，我们将输入“什么是机器学习？”，作为我们的prompt。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">prompt &#x3D; &quot;什么是机器学习？&quot;</span><br></pre></td></tr></table></figure><p>然后，我们需要设置一个模型ID来指定使用哪个模型进行推理。在这里，我们使用的是OpenAI官方提供的GPT-3模型（即davinci模型）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model_engine &#x3D; &quot;davinci&quot;</span><br></pre></td></tr></table></figure><p>接下来，我们需要调用openai包中的Completion API来对prompt进行推理，并获取AI返回的答案。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">response &#x3D; openai.Completion.create(</span><br><span class="line">    engine&#x3D;model_engine,</span><br><span class="line">    prompt&#x3D;prompt,</span><br><span class="line">    max_tokens&#x3D;1024,</span><br><span class="line">    n&#x3D;1,</span><br><span class="line">    stop&#x3D;None,</span><br><span class="line">    temperature&#x3D;0.5,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">answer &#x3D; response.choices[0].text.strip()</span><br></pre></td></tr></table></figure><p>在这里，我们设置了max_tokens参数来控制AI生成的答案长度，设置了n参数为1，表示只生成一条答案。我们还设置了temperature参数来控制AI生成答案的创新程度。temperature值越高，生成的答案越随机和创新，但也可能越不准确。在这里，我们将temperature设置为0.5，既能保证答案的准确性，又能保证一定的创新度。</p><p>最后，我们将AI生成的答案输出到控制台：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(answer)</span><br></pre></td></tr></table></figure><p>这就是使用ChatGPT进行问答交互的基本流程。你可以根据实际需求调整参数，从而得到更加准确的答案。</p>]]></content>
      
      
      <categories>
          
          <category> ChatGPT </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ChatGPT </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>API网关的工作原理与实战案例</title>
      <link href="2023/03/09/gateway-API%E7%BD%91%E5%85%B3%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/"/>
      <url>2023/03/09/gateway-API%E7%BD%91%E5%85%B3%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/</url>
      
        <content type="html"><![CDATA[<p><img src="https://res.craft.do/user/full/d3f184bd-2fc6-ae80-c9ed-d9b26e0cd7ba/doc/52741EAB-FA8B-4F0B-995B-7E0073E6BFE4/6E9D2C7C-B75E-4CBF-BCFD-493C7BB284B3_2/22KDf95eaVwEmpeHBkKPvRBS0Enubdr8y5tBMQpxPgcz/Image.png" alt="Image.png"></p><h1 id="API网关的工作原理与实战案例"><a href="#API网关的工作原理与实战案例" class="headerlink" title="API网关的工作原理与实战案例"></a>API网关的工作原理与实战案例</h1><p>API网关是一个在微服务架构中起到重要作用的组件。它可以处理所有客户端请求并对它们进行统一的管理和路由。本文将介绍API网关的工作原理，并给出一个基于Spring Cloud Gateway的实战案例。</p><span id="more"></span><h2 id="API网关的工作原理"><a href="#API网关的工作原理" class="headerlink" title="API网关的工作原理"></a>API网关的工作原理</h2><p>API网关的工作流程如下：</p><ol><li>客户端向API网关发送HTTP请求。</li><li>API网关解析并验证HTTP请求中的属性。</li><li>API网关执行白名单或黑名单检查。</li><li>API网关与身份提供者进行身份验证和授权。</li><li>限流规则应用于请求。如果超过限制，则请求被拒绝。</li><li>现在请求已经通过基本检查，API网关通过路径匹配找到相应的服务进行路由。</li><li>API网关将请求转换为适当的协议并将其发送到后端微服务。</li><li>API网关可以适当地处理错误，并在错误需要更长时间恢复时处理故障（熔断）。它还可以利用ELK（Elastic-Logstash-Kibana）堆栈进行日志记录和监视。我们有时会在API网关中缓存数据。</li></ol><p>API网关可以在多个方面帮助您的微服务架构，包括：</p><ul><li>提高安全性：通过身份验证和授权，API网关可以确保只有授权用户可以访问您的微服务。</li><li>提高可靠性：通过限流规则和熔断机制，API网关可以防止服务过载，并保持系统的稳定性。</li><li>提高性能：通过缓存数据和负载均衡，API网关可以提高系统的性能。</li></ul><h2 id="基于Spring-Cloud-Gateway的实战案例"><a href="#基于Spring-Cloud-Gateway的实战案例" class="headerlink" title="基于Spring Cloud Gateway的实战案例"></a>基于Spring Cloud Gateway的实战案例</h2><p>Spring Cloud Gateway是Spring Cloud的一部分，它提供了一种轻量级的方式来构建API网关。以下是一个基于Spring Cloud Gateway的实战案例：</p><h2 id="Spring-Cloud-Gateway的基本用法"><a href="#Spring-Cloud-Gateway的基本用法" class="headerlink" title="Spring Cloud Gateway的基本用法"></a>Spring Cloud Gateway的基本用法</h2><p>Spring Cloud Gateway的基本用法可以分为以下几个步骤：</p><ol><li>在pom.xml中添加Spring Cloud Gateway的依赖：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-cloud-starter-gateway&lt;&#x2F;artifactId&gt;</span><br><span class="line">  &lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure><ol start="2"><li>在application.yml或application.properties中添加路由规则：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">spring:</span><br><span class="line">  cloud:</span><br><span class="line">    gateway:</span><br><span class="line">      routes:</span><br><span class="line">        - id: route1</span><br><span class="line">          uri: http:&#x2F;&#x2F;localhost:8081</span><br><span class="line">          predicates:</span><br><span class="line">            - Path&#x3D;&#x2F;api&#x2F;**</span><br><span class="line">        - id: route2</span><br><span class="line">          uri: http:&#x2F;&#x2F;localhost:8082</span><br><span class="line">          predicates:</span><br><span class="line">            - Path&#x3D;&#x2F;user&#x2F;**</span><br></pre></td></tr></table></figure><ol start="3"><li>启动Spring Boot应用程序，并访问<a target="_blank" rel="noopener" href="http://localhost:8080/api/hello%E6%88%96http://localhost:8080/user/list">http://localhost:8080/api/hello或http://localhost:8080/user/list</a></li></ol><h2 id="Spring-Cloud-Gateway的高级用法"><a href="#Spring-Cloud-Gateway的高级用法" class="headerlink" title="Spring Cloud Gateway的高级用法"></a>Spring Cloud Gateway的高级用法</h2><p>Spring Cloud Gateway的高级用法可以包括以下几个方面：</p><h3 id="过滤器"><a href="#过滤器" class="headerlink" title="过滤器"></a>过滤器</h3><p>过滤器是Spring Cloud Gateway的核心概念之一，它可以在请求和响应之间执行各种操作，例如身份验证、流控、路由、日志等</p><p>接下来，我们将进一步探讨Spring Cloud Gateway的高级用法。具体来说，我们将介绍以下几点：</p><ul><li>自定义过滤器</li><li>动态路由</li><li>限流策略</li><li>断路器</li></ul><h3 id="自定义过滤器"><a href="#自定义过滤器" class="headerlink" title="自定义过滤器"></a>自定义过滤器</h3><p>Spring Cloud Gateway的过滤器是请求和响应的处理器，可以在请求被路由到目标服务之前或之后进行一些操作。过滤器可以用来处理身份验证、路由跟踪、访问日志等任务。</p><p>下面是一个自定义请求过滤器的例子，它会在请求头中添加一个自定义的跟踪ID：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">@Component</span><br><span class="line">public class AddTraceIdFilter implements GlobalFilter, Ordered &#123;</span><br><span class="line"></span><br><span class="line">    private static final String TRACE_ID_HEADER &#x3D; &quot;X-Trace-Id&quot;;</span><br><span class="line">    private static final int ORDER &#x3D; 1;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123;</span><br><span class="line">        String traceId &#x3D; UUID.randomUUID().toString();</span><br><span class="line">        ServerHttpRequest request &#x3D; exchange.getRequest().mutate()</span><br><span class="line">                .header(TRACE_ID_HEADER, traceId)</span><br><span class="line">                .build();</span><br><span class="line">        ServerWebExchange mutatedExchange &#x3D; exchange.mutate()</span><br><span class="line">                .request(request)</span><br><span class="line">                .build();</span><br><span class="line">        return chain.filter(mutatedExchange);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public int getOrder() &#123;</span><br><span class="line">        return ORDER;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个过滤器实现了Spring Cloud Gateway的GlobalFilter接口，并重写了其中的filter和getOrder方法。在filter方法中，它生成了一个随机的跟踪ID，并将它添加到请求头中。在getOrder方法中，它指定了过滤器的执行顺序。</p><h3 id="动态路由"><a href="#动态路由" class="headerlink" title="动态路由"></a>动态路由</h3><p>动态路由是指在运行时根据配置动态地将请求路由到不同的后端服务。Spring Cloud Gateway提供了一些机制来实现动态路由，比如使用Eureka或Consul作为服务发现组件，并结合Spring Cloud Config Server来管理路由规则。</p><p>以下是一个简单的动态路由配置的例子，它将根据请求路径将请求路由到不同的后端服务</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">spring:</span><br><span class="line">  cloud:</span><br><span class="line">    gateway:</span><br><span class="line">      routes:</span><br><span class="line">        - id: service1</span><br><span class="line">          uri: lb:&#x2F;&#x2F;service1</span><br><span class="line">          predicates:</span><br><span class="line">            - Path&#x3D;&#x2F;service1&#x2F;**</span><br><span class="line">        - id: service2</span><br><span class="line">          uri: lb:&#x2F;&#x2F;service2</span><br><span class="line">          predicates:</span><br><span class="line">            - Path&#x3D;&#x2F;service2&#x2F;**</span><br></pre></td></tr></table></figure><p>这个配置文件中定义了两个路由规则，它们分别将以/service1和/service2开头的请求路由到service1和service2这两个后端服务</p><h3 id="限流策略"><a href="#限流策略" class="headerlink" title="限流策略"></a>限流策略</h3><p>限流策略通常基于令牌桶算法或漏桶算法实现。这些算法都是一种流量控制算法，通过控制流量的输入速率来保护后端服务。</p><ul><li>令牌桶算法：在一定的时间间隔内，按照固定的速率往桶中放入令牌。当请求到来时，如果桶中有足够的令牌，则将请求处理掉，并从桶中扣除相应数量的令牌；否则，请求被拒绝。</li><li>漏桶算法：设定一个容量为b的漏桶，每单位时间流出r个请求。当请求到来时，如果桶未满，则将请求放入桶中，并等待r秒钟；否则，请求被拒绝。</li></ul><p>在Spring Cloud Gateway中，可以通过自定义GatewayFilter实现限流策略。在GatewayFilter中，可以通过RateLimiterRegistry创建限流器，并在过滤器链中进行限流操作。</p><ol><li>添加依赖</li></ol><p>在pom.xml中添加spring-cloud-starter-gateway和spring-boot-starter-actuator依赖。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependencies&gt;</span><br><span class="line">  &lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-cloud-starter-gateway&lt;&#x2F;artifactId&gt;</span><br><span class="line">  &lt;&#x2F;dependency&gt;</span><br><span class="line">  &lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-boot-starter-actuator&lt;&#x2F;artifactId&gt;</span><br><span class="line">  &lt;&#x2F;dependency&gt;</span><br><span class="line">&lt;&#x2F;dependencies&gt;</span><br></pre></td></tr></table></figure><ol start="2"><li>配置限流策略</li></ol><p>在配置文件中添加限流策略。这里我们以令牌桶算法为例，设置限流速率为10个请求/秒</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">spring:</span><br><span class="line">  cloud:</span><br><span class="line">    gateway:</span><br><span class="line">      default-filters:</span><br><span class="line">        - name: RequestRateLimiter</span><br><span class="line">          args:</span><br><span class="line">            key-resolver: &quot;#&#123;@userKeyResolver&#125;&quot;</span><br><span class="line">            rate-limiter: &quot;#&#123;@redisRateLimiter&#125;&quot;</span><br><span class="line">      routes:</span><br><span class="line">        - id: test_route</span><br><span class="line">          uri: http:&#x2F;&#x2F;localhost:8080</span><br><span class="line">          predicates:</span><br><span class="line">            - Path&#x3D;&#x2F;test&#x2F;**</span><br><span class="line">          filters:</span><br><span class="line">            - name: RequestRateLimiter</span><br><span class="line">              args:</span><br><span class="line">                key-resolver: &quot;#&#123;@userKeyResolver&#125;&quot;</span><br><span class="line">                rate-limiter: &quot;#&#123;@redisRateLimiter&#125;&quot;</span><br></pre></td></tr></table></figure><ol start="3"><li>实现GatewayFilter</li></ol><p>创建一个实现GatewayFilter的类，用于创建限流器并进行限流操作。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">@Component</span><br><span class="line">public class RateLimitFilter implements GatewayFilter, Ordered &#123;</span><br><span class="line"></span><br><span class="line">    private final RateLimiter rateLimiter;</span><br><span class="line"></span><br><span class="line">    public RateLimitFilter(RateLimiter rateLimiter) &#123;</span><br><span class="line">        this.rateLimiter &#x3D; rateLimiter;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123;</span><br><span class="line">        String ip &#x3D; exchange.getRequest().getRemoteAddress().getAddress().getHostAddress();</span><br><span class="line">        if (rateLimiter.tryAcquire(ip)) &#123;</span><br><span class="line">            return chain.filter(exchange);</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            exchange.getResponse().setStatusCode(HttpStatus.TOO_MANY_REQUESTS);</span><br><span class="line">            return exchange.getResponse().setComplete();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public int getOrder() &#123;</span><br><span class="line">        return -1;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在上面的代码中，我们首先创建了一个名为RateLimitFilter的类，并实现了GatewayFilter接口。构造函数中传入了一个RateLimiter对象，用于进行限流操作。在filter方法中，我们通过ServerWebExchange对象获取请求的IP地址，并尝试获取令牌进行限流。如果获取到令牌，则将请求传递给下一个过滤器或处理程序，否则返回“too many requests”错误响应。</p><p>另外，我们还重写了getOrder方法并返回-1，以确保这个过滤器在所有其他过滤器之前运行。这是因为我们希望在进行任何其他操作之前先进行限流。</p><p>现在我们已经创建了一个基于网关的限流策略，并使用RateLimiter对象实现了基于令牌桶的算法进行限流操作。接下来我们需要将该过滤器添加到Spring Cloud Gateway中。</p><p>我们可以在配置文件中使用路由ID将过滤器应用于特定的路由。例如，假设我们要将上述限流过滤器应用于名为“foo”的路由，我们可以将以下代码添加到application.yml配置文件中：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">spring:</span><br><span class="line">  cloud:</span><br><span class="line">    gateway:</span><br><span class="line">      routes:</span><br><span class="line">        - id: foo</span><br><span class="line">          uri: http:&#x2F;&#x2F;localhost:8081</span><br><span class="line">          predicates:</span><br><span class="line">            - Path&#x3D;&#x2F;foo&#x2F;**</span><br><span class="line">          filters:</span><br><span class="line">            - name: RateLimiter</span><br><span class="line">              args:</span><br><span class="line">                redis-rate-limiter.replenishRate: 10</span><br><span class="line">                redis-rate-limiter.burstCapacity: 20</span><br></pre></td></tr></table></figure><p>在这个示例中，我们使用路由ID“foo”来标识我们想要应用这个过滤器的路由。我们还定义了一个名为“RateLimiter”的过滤器，并将其添加到路由的过滤器链中。</p><p>在这个示例中，我们使用了Redis限流器来实现限流。我们设置了刷新速率为每秒10个请求，突发容量为20个请求。</p><p>当用户请求“/foo”下的任何端点时，我们的限流过滤器会在网关层面上限制请求速率。如果请求速率超过限制，则该请求将被拒绝。</p>]]></content>
      
      
      <categories>
          
          <category> gateway </category>
          
      </categories>
      
      
        <tags>
            
            <tag> gateway </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo 博客加载优化</title>
      <link href="2022/12/24/hexo-hexo-y/"/>
      <url>2022/12/24/hexo-hexo-y/</url>
      
        <content type="html"><![CDATA[<h1 id="hexo-博客加载优化"><a href="#hexo-博客加载优化" class="headerlink" title="hexo 博客加载优化"></a>hexo 博客加载优化</h1><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>最近趁着周末折腾自己博客的时候,发现刷页面的时候会有点卡顿,感觉页面性能很低,所以开始了下面的优化,分析下来结果还不错比之前快了很多,那让我们开始吧!</p><p><img src="https://res.craft.do/user/full/d3f184bd-2fc6-ae80-c9ed-d9b26e0cd7ba/doc/1050E4F2-AB1F-423B-8DE0-393C1A892684/3E8FC5EB-EEB0-4C2D-94EC-C948F99002CA_2/D2DBPCbNGLqxlHxMmGlIfcTaOf8xxt6pIZxuqnXNyMwz/Image.png" alt="Image.png"></p><p>简单的来说主要以下几个部分的优化:</p><ul><li><strong>压缩静态资源,提高访问速度</strong></li><li><strong>图片懒加载</strong></li></ul><span id="more"></span><h3 id="压缩静态资源"><a href="#压缩静态资源" class="headerlink" title="压缩静态资源"></a>压缩静态资源</h3><p>安装插件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-neat --save</span><br></pre></td></tr></table></figure><p>然后我们需要在站点配置文件_config.yml 中添加以下代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># 博文压缩</span><br><span class="line">neat_enable: true</span><br><span class="line"># 压缩html</span><br><span class="line">neat_html:</span><br><span class="line">  enable: true</span><br><span class="line">  exclude:</span><br><span class="line"># 压缩css</span><br><span class="line">neat_css:</span><br><span class="line">  enable: true</span><br><span class="line">  exclude:</span><br><span class="line">    - &#39;**&#x2F;*.min.css&#39;</span><br><span class="line"># 压缩js</span><br><span class="line">neat_js:</span><br><span class="line">  enable: true</span><br><span class="line">  mangle: true</span><br><span class="line">  output:</span><br><span class="line">  compress:</span><br><span class="line">  exclude:</span><br><span class="line">    - &#39;**&#x2F;*.min.js&#39;</span><br><span class="line">    - &#39;**&#x2F;jquery.fancybox.pack.js&#39;</span><br><span class="line">    - &#39;**&#x2F;index.js&#39;</span><br><span class="line">    - &#39;**&#x2F;fireworks.js&#39;</span><br></pre></td></tr></table></figure><h3 id="图片懒加载"><a href="#图片懒加载" class="headerlink" title="图片懒加载"></a>图片懒加载</h3><p>安装插件:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-lazyload-image --save</span><br></pre></td></tr></table></figure><p>_config.yml 中添加以下代码:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 图片懒加载</span><br><span class="line">lazyload:</span><br><span class="line">  enable: true</span><br><span class="line">  onlypost: false</span><br><span class="line">  loadingImg: &#x2F;images&#x2F;loading.gif</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Nagle和延迟确认带来的性能问题</title>
      <link href="2022/12/23/internet-nagle/"/>
      <url>2022/12/23/internet-nagle/</url>
      
        <content type="html"><![CDATA[<h1 id="Nagle和延迟确认带来的性能问题"><a href="#Nagle和延迟确认带来的性能问题" class="headerlink" title="Nagle和延迟确认带来的性能问题"></a>Nagle和延迟确认带来的性能问题</h1><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>从网上看到的一个问题的跟踪@林沛满 ，觉得很有意思记录下来</p><h3 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h3><p>从AIX备份数据到Windows极其缓慢，只有1MB/s，备份所用的协议是SFTP，看到这个问题第一反应抓个包，试试Wireshark的三板斧</p><h3 id="抓包三板斧"><a href="#抓包三板斧" class="headerlink" title="抓包三板斧"></a>抓包三板斧</h3><ol><li>从Statistics →Summary菜单可见，平均速度是11 Mbit/s，的确只比1 MB/s高一些</li></ol><span id="more"></span><p><img src="https://res.craft.do/user/full/d3f184bd-2fc6-ae80-c9ed-d9b26e0cd7ba/doc/0DEEB625-00C3-41BD-B624-683B699924E8/EF3B1138-D940-4964-B487-C60AC4E5D08F_2/EtZkFgVqobsgX247lVw9nQzEXGuQWP3e8G4Qyyzmwh0z/Image.png" alt="Image.png"></p><ol start="2"><li>从Analyze →Expert Infos菜单看，网络状况堪称完美。连一个Warnings和Notes都没有。这样的网络性能怎么会差？</li></ol><p><img src="https://res.craft.do/user/full/d3f184bd-2fc6-ae80-c9ed-d9b26e0cd7ba/doc/0DEEB625-00C3-41BD-B624-683B699924E8/0A35D2DB-D49E-47D3-9A85-5030507663E0_2/WweckqTyOemsxBQ7nxDxF33Pph8lDpQPhwWfKe48Nb0z/Image.png" alt="Image.png"></p><p>3．选定一个从AIX发往Windows的包，然后点击Statistics→TCP StreamGraph→TCP Sequence Graph（Stevens）菜单，从图3可见，这60秒中数据传输得很均匀，没有TCP Zero Window或者死机导致的暂停。</p><p><img src="https://res.craft.do/user/full/d3f184bd-2fc6-ae80-c9ed-d9b26e0cd7ba/doc/0DEEB625-00C3-41BD-B624-683B699924E8/AF93E34F-32EF-4367-84A7-FA0CAC47D1E2_2/rMHgascgFBacaJhygVrPR4ut4KYUHQzMUjuxylt600wz/Image.png" alt="Image.png"></p><p>试完三板斧，我们只能得到一个结论：备份的确进行得很慢，但是仅凭Wireshark自带的分析工具找不出根本原因，这也许意味着问题不在网络上，而是在接收方或者发送方上。幸好<strong>Wireshark不但能发现网络上的问题，也能反映出接收方和发送方的一些配置，只是需要一些技巧来发现</strong>。</p><p>因为数据是从AIX备份到Windows的，所以如果把SFTP（SSH File Transfer Protocol）包过滤出来，理论上应该看到大多数时间花在了从AIX到Windows的传输上。可是由图4发现，从AIX到Windows的包虽然占多数，但没花多少时间。反而从Windows到AIX的两个包（533和535）之间竟然隔了0.2秒。该现象在整个传输过程中出现得很频繁，说不定性能差的原因就在此处了。只要把根本原因找出来，就有希望解决问题。</p><p><img src="https://res.craft.do/user/full/d3f184bd-2fc6-ae80-c9ed-d9b26e0cd7ba/doc/0DEEB625-00C3-41BD-B624-683B699924E8/AE3CDB44-D330-47AC-92D3-32D6CA9DD39A_2/gCQjzWaAFAnEdgrLQEO0HcQ3LV9TaNU6EVLKTbPl6Sgz/Image.png" alt="Image.png"></p><p>那么这0.2秒之间究竟发生了什么呢？我把过滤条件去掉后得到了图5所示的包。可见Windows发出533号包之后就停下来等，直到0.2秒之后AIX的Ack（534号包）到达了才发出535号。Windows停下来的原因是什么呢？它在这两个包里总共才发了700多字节（96+656）的数据，肯定不会是因为TCP窗口受约束所致。</p><p><img src="https://res.craft.do/user/full/d3f184bd-2fc6-ae80-c9ed-d9b26e0cd7ba/doc/0DEEB625-00C3-41BD-B624-683B699924E8/DC666B15-A553-4A1F-BEC2-610F6BE84D33_2/du6xMWrJDCw4SIgAHtWkNhxiVNXUtTJwp8fwCjPG1qkz/Image.png" alt="Image.png"></p><p>如果你研究过TCP协议，可能已经想到了愚笨窗口综合症（Silly window syndrome）和纳格（Nagle）算法。在某些情况下，应用层传递给TCP层的数据量很小，比如在SSH客户端以一般速度打字时，几乎是逐个字节传递到TCP层的。传输这么少的数据量却要耗费20字节IP头+20字节TCP头，是非常浪费的，这种情况称为发送方的愚笨窗口综合症，也叫“小包问题”（small packet problem）。为了提高传输效率，纳格提出了一个算法，用程序员喜闻乐见的方式表达就是这样的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">if有新数据要发送</span><br><span class="line">  if数据量超过MSS（即一个TCP包所能携带的最大数据量）</span><br><span class="line">    立即发送</span><br><span class="line">  else</span><br><span class="line">    if之前发出去的数据尚未确认</span><br><span class="line">      把新数据缓存起来，凑够MSS或等确认到达再发送</span><br><span class="line">    else</span><br><span class="line">      立即发送</span><br><span class="line">    end if</span><br><span class="line">  end if</span><br><span class="line">end if</span><br></pre></td></tr></table></figure><p>所示的状况恰好就是小包问题。Windows发了533号包之后，本应该立即发送535的，但是由于535携带的数据量小于MSS，是个小包，根据Nagle算法只好等到533被确认（即收到534）才能接着发。这一等就是0.2秒，所以性能受到了大幅度影响。那为什么AIX要等那么久才确认呢？因为它启用<strong>延迟确认</strong>了。</p><h3 id="原因定位"><a href="#原因定位" class="headerlink" title="原因定位"></a>原因定位</h3><p>Nagle和延迟确认本身都没有问题，但一起用就会影响性能。解决方法很简单，要么在Windows上关闭Nagle算法，要么在AIX上关闭延迟确认。这位客户最终选择了前者，性能立即提升了20倍。如果你足够细心，也许已经意识到图3有问题——既然传输过程中会频繁地停顿0.2秒，为什么图3显示数据传输很均匀呢？这是因为抓包时间太长了，有60秒，所以0.2秒的停顿在图上看不出来。假如只截取其中的一秒钟来分析，再点击Statistics →TCP StreamGraph→TCP Sequence Graph（Stevens）菜单，你就能看到图6的结果，0.2秒的停顿就很明显了</p><p><img src="https://res.craft.do/user/full/d3f184bd-2fc6-ae80-c9ed-d9b26e0cd7ba/doc/0DEEB625-00C3-41BD-B624-683B699924E8/7B35CAAB-7898-4F0A-AACA-8B750ED9BF16_2/IHeN7rWRRA6hwp37slXx3R9gZ1arZodWDbC3Dx5QjYYz/Image.png" alt="Image.png"></p><p>文章到尾声，按理说这种情况，世界到处都有同时启用Nagle和延迟确认的设置在通信，那为什么很少有人发现这个问题呢？估计大部分人都以为是带宽不足吧。</p><p>当然网上也有类型的分享，感兴趣的可以看看</p><p><a target="_blank" rel="noopener" href="https://www.diglog.com/story/1036249.html">https://www.diglog.com/story/1036249.html</a></p><p><a target="_blank" rel="noopener" href="http://www.stuartcheshire.org/papers/nagledelayedack/">http://www.stuartcheshire.org/papers/nagledelayedack/</a></p>]]></content>
      
      
      <categories>
          
          <category> network </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tcp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TCP 的那些事儿（下）</title>
      <link href="2022/12/23/internet-tcp-e/"/>
      <url>2022/12/23/internet-tcp-e/</url>
      
        <content type="html"><![CDATA[<h1 id="TCP-的那些事儿（下）"><a href="#TCP-的那些事儿（下）" class="headerlink" title="TCP 的那些事儿（下）"></a>TCP 的那些事儿（下）</h1><p>这篇文章是下篇，所以如果你对TCP不熟悉的话，还请你先看看上篇《<a href="https://smalltechnologyjun.com/2022/12/23/internet-tcp-f/">TCP的那些事儿（上）</a>》 上篇中，我们介绍了TCP的协议头、状态机、数据重传中的东西。但是TCP要解决一个很大的事，那就是要在一个网络根据不同的情况来动态调整自己的发包的速度，小则让自己的连接更稳定，大则让整个网络更稳定。在你阅读下篇之前，你需要做好准备，本篇文章有好些算法和策略，可能会引发你的各种思考，让你的大脑分配很多内存和计算资源，所以，不适合在厕所中阅读。</p><h4 id="TCP的RTT算法"><a href="#TCP的RTT算法" class="headerlink" title="TCP的RTT算法"></a>TCP的RTT算法</h4><p>从前面的TCP重传机制我们知道Timeout的设置对于重传非常重要。</p><ul><li>设长了，重发就慢，丢了老半天才重发，没有效率，性能差；</li><li>设短了，会导致可能并没有丢就重发。于是重发的就快，会增加网络拥塞，导致更多的超时，更多的超时导致更多的重发。</li></ul><p>而且，这个超时时间在不同的网络的情况下，根本没有办法设置一个死的值。只能动态地设置。 为了动态地设置，TCP引入了RTT——Round Trip Time，也就是一个数据包从发出去到回来的时间。这样发送端就大约知道需要多少的时间，从而可以方便地设置Timeout——RTO（Retransmission TimeOut），以让我们的重传机制更高效。 听起来似乎很简单，好像就是在发送端发包时记下t0，然后接收端再把这个ack回来时再记一个t1，于是RTT = t1 – t0。没那么简单，这只是一个采样，不能代表普遍情况。</p><span id="more"></span><h4 id="经典算法"><a href="#经典算法" class="headerlink" title="经典算法"></a>经典算法</h4><p><a target="_blank" rel="noopener" href="https://tools.ietf.org/html/rfc793">RFC793</a> 中定义的经典算法是这样的：</p><p>1）首先，先采样RTT，记下最近好几次的RTT值。</p><p>2）然后做平滑计算SRTT（ Smoothed RTT）。公式为：（其中的 α 取值在0.8 到 0.9之间，这个算法英文叫Exponential weighted moving average，中文叫：加权移动平均）</p><p><strong>SRTT = ( α * SRTT ) + ((1- α) * RTT)</strong></p><p>3）开始计算RTO。公式如下：</p><p><strong>RTO = min [ UBOUND,  max [ LBOUND,   (β * SRTT) ]  ]</strong></p><p>其中：</p><ul><li>UBOUND是最大的timeout时间，上限值</li><li>LBOUND是最小的timeout时间，下限值</li><li>β 值一般在1.3到2.0之间。</li></ul><h4 id="Karn-Partridge-算法"><a href="#Karn-Partridge-算法" class="headerlink" title="Karn / Partridge 算法"></a>Karn / Partridge 算法</h4><p>但是上面的这个算法在重传的时候会出有一个终极问题——你是用第一次发数据的时间和ack回来的时间做RTT样本值，还是用重传的时间和ACK回来的时间做RTT样本值？</p><p>这个问题无论你选那头都是按下葫芦起了瓢。 如下图所示：</p><ul><li>情况（a）是ack没回来，所以重传。如果你计算第一次发送和ACK的时间，那么，明显算大了。</li><li>情况（b）是ack回来慢了，但是导致了重传，但刚重传不一会儿，之前ACK就回来了。如果你是算重传的时间和ACK回来的时间的差，就会算短了。</li></ul><p><img src="https://res.craft.do/user/full/d3f184bd-2fc6-ae80-c9ed-d9b26e0cd7ba/doc/A1206DF9-3CED-4694-A792-06A1E444D13B/361E07DB-7AFA-4AED-995A-F491516E97DD_2/2DlxiM9BnxMTpaIljpNxnMYThtQI10efa8OLmELjsXwz/Image.png" alt="Image.png"></p><p>所以1987年的时候，搞了一个叫<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Karn's_Algorithm">Karn / Partridge Algorithm</a>，这个算法的最大特点是——<strong>忽略重传，不把重传的RTT做采样</strong>（你看，你不需要去解决不存在的问题）。</p><p>但是，这样一来，又会引发一个大BUG——<strong>如果在某一时间，网络闪动，突然变慢了，产生了比较大的延时，这个延时导致要重转所有的包（因为之前的RTO很小），于是，因为重转的不算，所以，RTO就不会被更新，这是一个灾难</strong>。 于是Karn算法用了一个取巧的方式——只要一发生重传，就对现有的RTO值翻倍（这就是所谓的 Exponential backoff），很明显，这种死规矩对于一个需要估计比较准确的RTT也不靠谱。</p><h4 id="Jacobson-Karels-算法"><a href="#Jacobson-Karels-算法" class="headerlink" title="Jacobson / Karels 算法"></a>Jacobson / Karels 算法</h4><p>前面两种算法用的都是“加权移动平均”，这种方法最大的毛病就是如果RTT有一个大的波动的话，很难被发现，因为被平滑掉了。所以，1988年，又有人推出来了一个新的算法，这个算法叫Jacobson / Karels Algorithm（参看<a target="_blank" rel="noopener" href="https://tools.ietf.org/html/rfc6298">RFC6289</a>）。这个算法引入了最新的RTT的采样和平滑过的SRTT的差距做因子来计算。 公式如下：（其中的DevRTT是Deviation RTT的意思）</p><p><strong>SRTT</strong> <strong>= S****RTT</strong> <strong>+ α</strong> (<strong>RTT <strong>– SRTT</strong>)</strong> —— 计算平滑RTT</p><p><strong>DevRTT</strong> <strong>= (1-β**</strong>)<em><strong>DevRTT</strong> <strong>+ β</strong></em>(|<strong>RTT-SRTT</strong>|)** ——计算平滑RTT和真实的差距（加权移动平均）</p><p>*RTO= µ * SRTT + ∂ <em>DevRTT</em> —— 神一样的公式</p><p>（其中：在Linux下，α = 0.125，β = 0.25， μ = 1，∂ = 4 ——这就是算法中的“调得一手好参数”，nobody knows why, it just works…） 最后的这个算法在被用在今天的TCP协议中（Linux的源代码在：<a target="_blank" rel="noopener" href="http://lxr.free-electrons.com/source/net/ipv4/tcp_input.c?v=2.6.32#L609">tcp_rtt_estimator</a>）。</p><h4 id="TCP滑动窗口"><a href="#TCP滑动窗口" class="headerlink" title="TCP滑动窗口"></a>TCP滑动窗口</h4><p>需要说明一下，如果你不了解TCP的滑动窗口这个事，你等于不了解TCP协议。我们都知道，<strong>TCP必需要解决的可靠传输以及包乱序（reordering）的问题</strong>，所以，TCP必需要知道网络实际的数据处理带宽或是数据处理速度，这样才不会引起网络拥塞，导致丢包。</p><p>所以，TCP引入了一些技术和设计来做网络流控，Sliding Window是其中一个技术。 前面我们说过，<strong>TCP头里有一个字段叫Window，又叫Advertised-Window，这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据</strong>。<strong>于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来</strong>。 为了说明滑动窗口，我们需要先看一下TCP缓冲区的一些数据结构：</p><p><img src="https://res.craft.do/user/full/d3f184bd-2fc6-ae80-c9ed-d9b26e0cd7ba/doc/A1206DF9-3CED-4694-A792-06A1E444D13B/7ACFF727-288A-45BF-A9FF-713DB88FD6C5_2/aqQvbtcBrEBDdyyQpca6nNN5gH0nsPcqQkCKwgC6CxIz/Image.png" alt="Image.png"></p><p>上图中，我们可以看到：</p><ul><li>接收端LastByteRead指向了TCP缓冲区中读到的位置，NextByteExpected指向的地方是收到的连续包的最后一个位置，LastByteRcved指向的是收到的包的最后一个位置，我们可以看到中间有些数据还没有到达，所以有数据空白区。</li><li>发送端的LastByteAcked指向了被接收端Ack过的位置（表示成功发送确认），LastByteSent表示发出去了，但还没有收到成功确认的Ack，LastByteWritten指向的是上层应用正在写的地方。</li></ul><p>于是：</p><ul><li>接收端在给发送端回ACK中会汇报自己的AdvertisedWindow = MaxRcvBuffer – LastByteRcvd – 1;</li><li>而发送方会根据这个窗口来控制发送数据的大小，以保证接收方可以处理。</li></ul><p>下面我们来看一下发送方的滑动窗口示意图：</p><p><img src="https://res.craft.do/user/full/d3f184bd-2fc6-ae80-c9ed-d9b26e0cd7ba/doc/A1206DF9-3CED-4694-A792-06A1E444D13B/AB245E70-1506-4BA0-8F7A-DDB4D06EE4B3_2/iruBPuFwz4ayJ1yeNUlDYV2kyX3uuMeX4swWVWIkI5Iz/Image.png" alt="Image.png"></p><p>（<a target="_blank" rel="noopener" href="http://www.tcpipguide.com/free/t_TCPSlidingWindowAcknowledgmentSystemForDataTranspo-6.htm">图片来源</a>）</p><p>上图中分成了四个部分，分别是：（其中那个黑模型就是滑动窗口）</p><ul><li>#1已收到ack确认的数据。</li><li>#2发还没收到ack的。</li><li>#3在窗口中还没有发出的（接收方还有空间）。</li><li>#4窗口以外的数据（接收方没空间）</li></ul><p>下面是个滑动后的示意图（收到36的ack，并发出了46-51的字节）：</p><p><img src="https://res.craft.do/user/full/d3f184bd-2fc6-ae80-c9ed-d9b26e0cd7ba/doc/A1206DF9-3CED-4694-A792-06A1E444D13B/860DD86C-2EF8-42FC-9403-C3EA0E2ED656_2/HL6M84NMNnTonsGRkEXhg1JcDFXdqWyoL5YPvqltLQoz/Image.png" alt="Image.png"></p><p>下面我们来看一个接受端控制发送端的图示：</p><p><img src="https://res.craft.do/user/full/d3f184bd-2fc6-ae80-c9ed-d9b26e0cd7ba/doc/A1206DF9-3CED-4694-A792-06A1E444D13B/3EFE1B7B-95FF-42A6-B628-4C19520E5096_2/qdFxZEf7YtoeIsxFyJ2dSOMbOLISRpuptztFX4COrk8z/Image.png" alt="Image.png"></p><p>（<a target="_blank" rel="noopener" href="http://www.tcpipguide.com/free/t_TCPWindowSizeAdjustmentandFlowControl-2.htm">图片来源</a>）</p><h4 id="Zero-Window"><a href="#Zero-Window" class="headerlink" title="Zero Window"></a>Zero Window</h4><p>上图，我们可以看到一个处理缓慢的Server（接收端）是怎么把Client（发送端）的TCP Sliding Window给降成0的。此时，你一定会问，如果Window变成0了，TCP会怎么样？是不是发送端就不发数据了？是的，发送端就不发数据了，你可以想像成“Window Closed”，那你一定还会问，如果发送端不发数据了，接收方一会儿Window size 可用了，怎么通知发送端呢？</p><p>解决这个问题，TCP使用了Zero Window Probe技术，缩写为ZWP，也就是说，发送端在窗口变成0后，会发ZWP的包给接收方，让接收方来ack他的Window尺寸，一般这个值会设置成3次，第次大约30-60秒（不同的实现可能会不一样）。如果3次过后还是0的话，有的TCP实现就会发RST把链接断了。</p><p><strong>注意</strong>：只要有等待的地方都可能出现DDoS攻击，Zero Window也不例外，一些攻击者会在和HTTP建好链发完GET请求后，就把Window设置为0，然后服务端就只能等待进行ZWP，于是攻击者会并发大量的这样的请求，把服务器端的资源耗尽。（关于这方面的攻击，大家可以移步看一下<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Sockstress">Wikipedia的SockStress词条</a>）</p><p>另外，Wireshark中，你可以使用tcp.analysis.zero_window来过滤包，然后使用右键菜单里的follow TCP stream，你可以看到ZeroWindowProbe及ZeroWindowProbeAck的包。</p><h4 id="Silly-Window-Syndrome"><a href="#Silly-Window-Syndrome" class="headerlink" title="Silly Window Syndrome"></a>Silly Window Syndrome</h4><p>Silly Window Syndrome翻译成中文就是“糊涂窗口综合症”。正如你上面看到的一样，如果我们的接收方太忙了，来不及取走Receive Windows里的数据，那么，就会导致发送方越来越小。到最后，如果接收方腾出几个字节并告诉发送方现在有几个字节的window，而我们的发送方会义无反顾地发送这几个字节。</p><p>要知道，我们的TCP+IP头有40个字节，为了几个字节，要达上这么大的开销，这太不经济了。</p><p>另外，你需要知道网络上有个MTU，对于以太网来说，MTU是1500字节，除去TCP+IP头的40个字节，真正的数据传输可以有1460，这就是所谓的MSS（Max Segment Size）注意，TCP的RFC定义这个MSS的默认值是536，这是因为 <a target="_blank" rel="noopener" href="https://tools.ietf.org/html/rfc791">RFC 791</a>里说了任何一个IP设备都得最少接收576尺寸的大小（实际上来说576是拨号的网络的MTU，而576减去IP头的20个字节就是536）。</p><p><strong>如果你的网络包可以塞满MTU，那么你可以用满整个带宽，如果不能，那么你就会浪费带宽</strong>。（大于MTU的包有两种结局，一种是直接被丢了，另一种是会被重新分块打包发送） 你可以想像成一个MTU就相当于一个飞机的最多可以装的人，如果这飞机里满载的话，带宽最高，如果一个飞机只运一个人的话，无疑成本增加了，也而相当二。</p><p>所以，<strong>Silly Windows Syndrome这个现像就像是你本来可以坐200人的飞机里只做了一两个人</strong>。 要解决这个问题也不难，就是避免对小的window size做出响应，直到有足够大的window size再响应，这个思路可以同时实现在sender和receiver两端。</p><ul><li>如果这个问题是由Receiver端引起的，那么就会使用 David D Clark’s 方案。在receiver端，如果收到的数据导致window size小于某个值，可以直接ack(0)回sender，这样就把window给关闭了，也阻止了sender再发数据过来，等到receiver端处理了一些数据后windows size 大于等于了MSS，或者，receiver buffer有一半为空，就可以把window打开让send 发送数据过来。</li><li>如果这个问题是由Sender端引起的，那么就会使用著名的 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Nagle%27s_algorithm">Nagle’s algorithm</a>。这个算法的思路也是延时处理，他有两个主要的条件：1）要等到 Window Size&gt;=MSS 或是 Data Size &gt;=MSS，2）收到之前发送数据的ack回包，他才会发数据，否则就是在攒数据。</li></ul><p>另外，Nagle算法默认是打开的，所以，对于一些需要小包场景的程序——<strong>比如像telnet或ssh这样的交互性比较强的程序，你需要关闭这个算法</strong>。你可以在Socket设置TCP_NODELAY选项来关闭这个算法（关闭Nagle算法没有全局参数，需要根据每个应用自己的特点来关闭）</p><p>setsockopt(sock_fd, IPPROTO_TCP, TCP_NODELAY, (char *)&amp;value,sizeof(int));</p><p>另外，网上有些文章说TCP_CORK的socket option是也关闭Nagle算法，这不对。<strong>TCP_CORK其实是更新激进的Nagle算汉，完全禁止小包发送，而Nagle算法没有禁止小包发送，只是禁止了大量的小包发送</strong>。最好不要两个选项都设置。</p><h4 id="TCP的拥塞处理-–-Congestion-Handling"><a href="#TCP的拥塞处理-–-Congestion-Handling" class="headerlink" title="TCP的拥塞处理 – Congestion Handling"></a>TCP的拥塞处理 – Congestion Handling</h4><p>上面我们知道了，TCP通过Sliding Window来做流控（Flow Control），但是TCP觉得这还不够，因为Sliding Window需要依赖于连接的发送端和接收端，其并不知道网络中间发生了什么。TCP的设计者觉得，一个伟大而牛逼的协议仅仅做到流控并不够，因为流控只是网络模型4层以上的事，TCP的还应该更聪明地知道整个网络上的事。</p><p>具体一点，我们知道TCP通过一个timer采样了RTT并计算RTO，但是，<strong>如果网络上的延时突然增加，那么，TCP对这个事做出的应对只有重传数据，但是，重传会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，于是，这个情况就会进入恶性循环被不断地放大。试想一下，如果一个网络内有成千上万的TCP连接都这么行事，那么马上就会形成“网络风暴”，TCP这个协议就会拖垮整个网络。</strong>这是一个灾难。</p><p>所以，TCP不能忽略网络上发生的事情，而无脑地一个劲地重发数据，对网络造成更大的伤害。对此TCP的设计理念是：<strong>TCP不是一个自私的协议，当拥塞发生的时候，要做自我牺牲。就像交通阻塞一样，每个车都应该把路让出来，而不要再去抢路了。</strong></p><p>关于拥塞控制的论文请参看《<a target="_blank" rel="noopener" href="http://ee.lbl.gov/papers/congavoid.pdf">Congestion Avoidance and Control</a>》(PDF)</p><p>拥塞控制主要是四个算法：<strong>1）慢启动</strong>，<strong>2）拥塞避免</strong>，<strong>3）拥塞发生</strong>，<strong>4）快速恢复</strong>。这四个算法不是一天都搞出来的，这个四算法的发展经历了很多时间，到今天都还在优化中。 备注:</p><ul><li>1988年，TCP-Tahoe 提出了1）慢启动，2）拥塞避免，3）拥塞发生时的快速重传</li><li>1990年，TCP Reno 在Tahoe的基础上增加了4）快速恢复</li></ul><h4 id="慢热启动算法-–-Slow-Start"><a href="#慢热启动算法-–-Slow-Start" class="headerlink" title="慢热启动算法 – Slow Start"></a>慢热启动算法 – Slow Start</h4><p>首先，我们来看一下TCP的慢热启动。慢启动的意思是，刚刚加入网络的连接，一点一点地提速，不要一上来就像那些特权车一样霸道地把路占满。新同学上高速还是要慢一点，不要把已经在高速上的秩序给搞乱了。</p><p>慢启动的算法如下(cwnd全称Congestion Window)：</p><p>1）连接建好的开始先初始化cwnd = 1，表明可以传一个MSS大小的数据。</p><p>2）每当收到一个ACK，cwnd++; 呈线性上升</p><p>3）每当过了一个RTT，cwnd = cwnd*2; 呈指数让升</p><p>4）还有一个ssthresh（slow start threshold），是一个上限，当cwnd &gt;= ssthresh时，就会进入“拥塞避免算法”（后面会说这个算法）</p><p>所以，我们可以看到，如果网速很快的话，ACK也会返回得快，RTT也会短，那么，这个慢启动就一点也不慢。下图说明了这个过程。</p><p><img src="https://res.craft.do/user/full/d3f184bd-2fc6-ae80-c9ed-d9b26e0cd7ba/doc/A1206DF9-3CED-4694-A792-06A1E444D13B/649B3672-A121-4995-8C47-A93028A1DDFA_2/NEH6powugEU22V2rJlO9Y4TyKclermn0wXJNODn65Poz/Image.png" alt="Image.png"></p><p>这里，我需要提一下的是一篇Google的论文《<a target="_blank" rel="noopener" href="https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/36640.pdf">An Argument for Increasing TCP’s Initial Congestion Window</a>》Linux 3.0后采用了这篇论文的建议——把cwnd 初始化成了 10个MSS。 而Linux 3.0以前，比如2.6，Linux采用了<a target="_blank" rel="noopener" href="https://www.rfc-editor.org/rfc/rfc3390.txt">RFC3390</a>，cwnd是跟MSS的值来变的，如果MSS&lt; 1095，则cwnd = 4；如果MSS&gt;2190，则cwnd=2；其它情况下，则是3。</p><h4 id="拥塞避免算法-–-Congestion-Avoidance"><a href="#拥塞避免算法-–-Congestion-Avoidance" class="headerlink" title="拥塞避免算法 – Congestion Avoidance"></a>拥塞避免算法 – Congestion Avoidance</h4><p>前面说过，还有一个ssthresh（slow start threshold），是一个上限，当cwnd &gt;= ssthresh时，就会进入“拥塞避免算法”。一般来说ssthresh的值是65535，单位是字节，当cwnd达到这个值时后，算法如下：</p><p>1）收到一个ACK时，cwnd = cwnd + 1/cwnd</p><p>2）当每过一个RTT时，cwnd = cwnd + 1</p><p>这样就可以避免增长过快导致网络拥塞，慢慢的增加调整到网络的最佳值。很明显，是一个线性上升的算法。</p><h4 id="拥塞状态时的算法"><a href="#拥塞状态时的算法" class="headerlink" title="拥塞状态时的算法"></a>拥塞状态时的算法</h4><p>前面我们说过，当丢包的时候，会有两种情况：</p><p>1）等到RTO超时，重传数据包。TCP认为这种情况太糟糕，反应也很强烈。</p><ul><li>sshthresh =  cwnd /2</li><li>cwnd 重置为 1</li><li>进入慢启动过程</li></ul><p>2）Fast Retransmit算法，也就是在收到3个duplicate ACK时就开启重传，而不用等到RTO超时。</p><ul><li>TCP Tahoe的实现和RTO超时一样。</li><li>TCP Reno的实现是：<ul><li>cwnd = cwnd /2</li><li>sshthresh = cwnd</li><li>进入快速恢复算法——Fast Recovery</li></ul></li></ul><p>上面我们可以看到RTO超时后，sshthresh会变成cwnd的一半，这意味着，如果cwnd&lt;=sshthresh时出现的丢包，那么TCP的sshthresh就会减了一半，然后等cwnd又很快地以指数级增涨爬到这个地方时，就会成慢慢的线性增涨。我们可以看到，TCP是怎么通过这种强烈地震荡快速而小心得找到网站流量的平衡点的。</p><h4 id="快速恢复算法-–-Fast-Recovery"><a href="#快速恢复算法-–-Fast-Recovery" class="headerlink" title="快速恢复算法 – Fast Recovery"></a>快速恢复算法 – Fast Recovery</h4><p><strong>TCP Reno</strong></p><p>这个算法定义在<a href="%5Bhttps://tools.ietf.org/html/rfc5681%5D(https://tools.ietf.org/html/rfc5681">RFC5681</a> “”TCP Congestion Control””)。快速重传和快速恢复算法一般同时使用。快速恢复算法是认为，你还有3个Duplicated Acks说明网络也不那么糟糕，所以没有必要像RTO超时那么强烈。 注意，正如前面所说，进入Fast Recovery之前，cwnd 和 sshthresh已被更新：</p><ul><li>cwnd = cwnd /2</li><li>sshthresh = cwnd</li></ul><p>然后，真正的Fast Recovery算法如下：</p><ul><li>cwnd = sshthresh  + 3 * MSS （3的意思是确认有3个数据包被收到了）</li><li>重传Duplicated ACKs指定的数据包</li><li>如果再收到 duplicated Acks，那么cwnd = cwnd +1</li><li>如果收到了新的Ack，那么，cwnd = sshthresh ，然后就进入了拥塞避免的算法了。</li></ul><p>如果你仔细思考一下上面的这个算法，你就会知道，<strong>上面这个算法也有问题，那就是——它依赖于3个重复的Acks</strong>。注意，3个重复的Acks并不代表只丢了一个数据包，很有可能是丢了好多包。但这个算法只会重传一个，而剩下的那些包只能等到RTO超时，于是，进入了恶梦模式——超时一个窗口就减半一下，多个超时会超成TCP的传输速度呈级数下降，而且也不会触发Fast Recovery算法了。</p><p>通常来说，正如我们前面所说的，SACK或D-SACK的方法可以让Fast Recovery或Sender在做决定时更聪明一些，但是并不是所有的TCP的实现都支持SACK（SACK需要两端都支持），所以，需要一个没有SACK的解决方案。而通过SACK进行拥塞控制的算法是FACK（后面会讲）</p><p><strong>TCP New Reno</strong></p><p>于是，1995年，TCP New Reno（参见 <a target="_blank" rel="noopener" href="https://tools.ietf.org/html/rfc6582">RFC 6582</a> ）算法提出来，主要就是在没有SACK的支持下改进Fast Recovery算法的——</p><ul><li>当sender这边收到了3个Duplicated Acks，进入Fast Retransimit模式，开发重传重复Acks指示的那个包。如果只有这一个包丢了，那么，重传这个包后回来的Ack会把整个已经被sender传输出去的数据ack回来。如果没有的话，说明有多个包丢了。我们叫这个ACK为Partial ACK。</li><li>一旦Sender这边发现了Partial ACK出现，那么，sender就可以推理出来有多个包被丢了，于是乎继续重传sliding window里未被ack的第一个包。直到再也收不到了Partial Ack，才真正结束Fast Recovery这个过程</li></ul><p>我们可以看到，这个“Fast Recovery的变更”是一个非常激进的玩法，他同时延长了Fast Retransmit和Fast Recovery的过程。</p><h4 id="算法示意图"><a href="#算法示意图" class="headerlink" title="算法示意图"></a>算法示意图</h4><p>下面我们来看一个简单的图示以同时看一下上面的各种算法的样子：</p><p><img src="https://res.craft.do/user/full/d3f184bd-2fc6-ae80-c9ed-d9b26e0cd7ba/doc/A1206DF9-3CED-4694-A792-06A1E444D13B/6F737861-7C75-4313-AF12-0DF11B178C76_2/VHbCg38Fli3hzOBLri2eNuZsoCvxhlTnUpBnSwN4W28z/Image.png" alt="Image.png"></p><h4 id="FACK算法"><a href="#FACK算法" class="headerlink" title="FACK算法"></a>FACK算法</h4><p>FACK全称Forward Acknowledgment 算法，论文地址在这里（PDF）<a target="_blank" rel="noopener" href="http://conferences.sigcomm.org/sigcomm/1996/papers/mathis.pdf">Forward Acknowledgement: Refining TCP Congestion Control</a> 这个算法是其于SACK的，前面我们说过SACK是使用了TCP扩展字段Ack了有哪些数据收到，哪些数据没有收到，他比Fast Retransmit的3 个duplicated acks好处在于，前者只知道有包丢了，不知道是一个还是多个，而SACK可以准确的知道有哪些包丢了。 所以，SACK可以让发送端这边在重传过程中，把那些丢掉的包重传，而不是一个一个的传，但这样的一来，如果重传的包数据比较多的话，又会导致本来就很忙的网络就更忙了。所以，FACK用来做重传过程中的拥塞流控。</p><ul><li>这个算法会把SACK中最大的Sequence Number 保存在<strong>snd.fack</strong>这个变量中，snd.fack的更新由ack带秋，如果网络一切安好则和snd.una一样（snd.una就是还没有收到ack的地方，也就是前面sliding window里的category #2的第一个地方）</li><li>然后定义一个<strong>awnd = snd.nxt – snd.fack</strong>（snd.nxt指向发送端sliding window中正在要被发送的地方——前面sliding windows图示的category#3第一个位置），这样awnd的意思就是在网络上的数据。（所谓awnd意为：actual quantity of data outstanding in the network）</li><li>如果需要重传数据，那么，<strong>awnd = snd.nxt – snd.fack + retran_data</strong>，也就是说，awnd是传出去的数据 + 重传的数据。</li><li>然后触发Fast Recovery 的条件是： ( <strong>( snd.fack – snd.una ) &gt; (3*MSS)</strong> ) || (dupacks == 3) ) 。这样一来，就不需要等到3个duplicated acks才重传，而是只要sack中的最大的一个数据和ack的数据比较长了（3个MSS），那就触发重传。在整个重传过程中cwnd不变。直到当第一次丢包的snd.nxt&lt;=snd.una（也就是重传的数据都被确认了），然后进来拥塞避免机制——cwnd线性上涨。</li></ul><p>我们可以看到如果没有FACK在，那么在丢包比较多的情况下，原来保守的算法会低估了需要使用的window的大小，而需要几个RTT的时间才会完成恢复，而FACK会比较激进地来干这事。 但是，FACK如果在一个网络包会被 reordering的网络里会有很大的问题。</p><h4 id="其它拥塞控制算法简介"><a href="#其它拥塞控制算法简介" class="headerlink" title="其它拥塞控制算法简介"></a>其它拥塞控制算法简介</h4><h4 id="TCP-Vegas-拥塞控制算法"><a href="#TCP-Vegas-拥塞控制算法" class="headerlink" title="TCP Vegas 拥塞控制算法"></a><strong>TCP Vegas 拥塞控制算法</strong></h4><p>这个算法1994年被提出，它主要对TCP Reno 做了些修改。这个算法通过对RTT的非常重的监控来计算一个基准RTT。然后通过这个基准RTT来估计当前的网络实际带宽，如果实际带宽比我们的期望的带宽要小或是要多的活，那么就开始线性地减少或增加cwnd的大小。如果这个计算出来的RTT大于了Timeout后，那么，不等ack超时就直接重传。（Vegas 的核心思想是用RTT的值来影响拥塞窗口，而不是通过丢包） 这个算法的论文是《<a target="_blank" rel="noopener" href="https://www.cs.cmu.edu/~srini/15-744/F02/readings/BP95.pdf">TCP Vegas: End to End Congestion Avoidance on a Global Internet</a>》这篇论文给了Vegas和 New Reno的对比：</p><p><img src="https://res.craft.do/user/full/d3f184bd-2fc6-ae80-c9ed-d9b26e0cd7ba/doc/A1206DF9-3CED-4694-A792-06A1E444D13B/F9B41F4A-495F-4AE3-B00F-C01C4640E9E1_2/JUQTa06DEwbv7eOSCbcdhR5KzezLCPDTyaoswbucOz4z/Image.png" alt="Image.png"></p><p>关于这个算法实现，你可以参看Linux源码：<a target="_blank" rel="noopener" href="http://lxr.free-electrons.com/source/net/ipv4/tcp_vegas.h">/net/ipv4/tcp_vegas.h</a>， <a target="_blank" rel="noopener" href="http://lxr.free-electrons.com/source/net/ipv4/tcp_vegas.c">/net/ipv4/tcp_vegas.c</a></p><h4 id="HSTCP-High-Speed-TCP-算法"><a href="#HSTCP-High-Speed-TCP-算法" class="headerlink" title="HSTCP(High Speed TCP) 算法"></a>HSTCP(High Speed TCP) 算法</h4><p>这个算法来自<a target="_blank" rel="noopener" href="https://tools.ietf.org/html/rfc3649">RFC 3649</a>（<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/HSTCP">Wikipedia词条</a>）。其对最基础的算法进行了更改，他使得Congestion Window涨得快，减得慢。其中：</p><ul><li>拥塞避免时的窗口增长方式： cwnd = cwnd + α(cwnd) / cwnd</li><li>丢包后窗口下降方式：cwnd = (1- β(cwnd))*cwnd</li></ul><p>注：α(cwnd)和β(cwnd)都是函数，如果你要让他们和标准的TCP一样，那么让α(cwnd)=1，β(cwnd)=0.5就可以了。 对于α(cwnd)和β(cwnd)的值是个动态的变换的东西。 关于这个算法的实现，你可以参看Linux源码：<a target="_blank" rel="noopener" href="http://lxr.free-electrons.com/source/net/ipv4/tcp_highspeed.c">/net/ipv4/tcp_highspeed.c</a></p><h4 id="TCP-BIC-算法"><a href="#TCP-BIC-算法" class="headerlink" title="TCP BIC 算法"></a>TCP BIC 算法</h4><p>2004年，产内出BIC算法。现在你还可以查得到相关的新闻《Google：<a target="_blank" rel="noopener" href="https://www.google.com/search?lr=lang_zh-CN%7Clang_zh-TW&newwindow=1&biw=1366&bih=597&tbs=lr:lang_1zh-CN%7Clang_1zh-TW&q=%E7%BE%8E%E7%A7%91%E5%AD%A6%E5%AE%B6%E7%A0%94%E5%8F%91BIC-TCP%E5%8D%8F%E8%AE%AE+%E9%80%9F%E5%BA%A6%E6%98%AFDSL%E5%85%AD%E5%8D%83%E5%80%8D&oq=%E7%BE%8E%E7%A7%91%E5%AD%A6%E5%AE%B6%E7%A0%94%E5%8F%91BIC-TCP%E5%8D%8F%E8%AE%AE+%E9%80%9F%E5%BA%A6%E6%98%AFDSL%E5%85%AD%E5%8D%83%E5%80%8D">美科学家研发BIC-TCP协议 速度是DSL六千倍</a>》 BIC全称<a target="_blank" rel="noopener" href="http://research.csc.ncsu.edu/netsrv/?q=content/bic-and-cubic">Binary Increase Congestion control</a>，在Linux 2.6.8中是默认拥塞控制算法。BIC的发明者发这么多的拥塞控制算法都在努力找一个合适的cwnd – Congestion Window，而且BIC-TCP的提出者们看穿了事情的本质，其实这就是一个搜索的过程，所以BIC这个算法主要用的是Binary Search——二分查找来干这个事。 关于这个算法实现，你可以参看Linux源码：<a target="_blank" rel="noopener" href="http://lxr.free-electrons.com/source/net/ipv4/tcp_bic.c">/net/ipv4/tcp_bic.c</a></p><h4 id="TCP-WestWood算法"><a href="#TCP-WestWood算法" class="headerlink" title="TCP WestWood算法"></a>TCP WestWood算法</h4><p>westwood采用和Reno相同的慢启动算法、拥塞避免算法。westwood的主要改进方面：在发送端做带宽估计，当探测到丢包时，根据带宽值来设置拥塞窗口、慢启动阈值。 那么，这个算法是怎么测量带宽的？每个RTT时间，会测量一次带宽，测量带宽的公式很简单，就是这段RTT内成功被ack了多少字节。因为，这个带宽和用RTT计算RTO一样，也是需要从每个样本来平滑到一个值的——也是用一个加权移平均的公式。 另外，我们知道，如果一个网络的带宽是每秒可以发送X个字节，而RTT是一个数据发出去后确认需要的时候，所以，X * RTT应该是我们缓冲区大小。所以，在这个算法中，ssthresh的值就是est_BD * min-RTT(最小的RTT值)，如果丢包是Duplicated ACKs引起的，那么如果cwnd &gt; ssthresh，则 cwin = ssthresh。如果是RTO引起的，cwnd = 1，进入慢启动。   关于这个算法实现，你可以参看Linux源码： <a target="_blank" rel="noopener" href="http://lxr.free-electrons.com/source/net/ipv4/tcp_westwood.c">/net/ipv4/tcp_westwood.c</a></p><h4 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h4><p>更多的算法，你可以从Wikipedia的 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/TCP_congestion-avoidance_algorithm">TCP Congestion Avoidance Algorithm</a> 词条中找到相关的线索</p><h4 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h4><p>好了，到这里我想可以结束了，TCP发展到今天，里面的东西可以写上好几本书。本文主要目的，还是把你带入这些古典的基础技术和知识中，希望本文能让你了解TCP，更希望本文能让你开始有学习这些基础或底层知识的兴趣和信心。</p><p>当然，TCP东西太多了，不同的人可能有不同的理解，而且本文可能也会有一些荒谬之言甚至错误，还希望得到您的反馈和批评。</p><p>（全文完）</p>]]></content>
      
      
      <categories>
          
          <category> network </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tcp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TCP 的那些事儿（上）</title>
      <link href="2022/12/23/internet-tcp-f/"/>
      <url>2022/12/23/internet-tcp-f/</url>
      
        <content type="html"><![CDATA[<h1 id="TCP-的那些事儿（上）"><a href="#TCP-的那些事儿（上）" class="headerlink" title="TCP 的那些事儿（上）"></a>TCP 的那些事儿（上）</h1><p>TCP是一个巨复杂的协议，因为他要解决很多问题，而这些问题又带出了很多子问题和阴暗面。所以学习TCP本身是个比较痛苦的过程，但对于学习的过程却能让人有很多收获。关于TCP这个协议的细节，我还是推荐你去看<a target="_blank" rel="noopener" href="http://www.kohala.com/start/">W.Richard Stevens</a>的《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/1088054/">TCP/IP 详解 卷1：协议</a>》（当然，你也可以去读一下<a target="_blank" rel="noopener" href="https://tools.ietf.org/html/rfc793">RFC793</a>以及后面N多的RFC）。另外，本文我会使用英文术语，这样方便你通过这些英文关键词来查找相关的技术文档。</p><p>之所以想写这篇文章，目的有三个，</p><ul><li>一个是想锻炼一下自己是否可以用简单的篇幅把这么复杂的TCP协议描清楚的能力。</li><li>另一个是觉得现在的好多程序员基本上不会认认真真地读本书，喜欢快餐文化，所以，希望这篇快餐文章可以让你对TCP这个古典技术有所了解，并能体会到软件设计中的种种难处。并且你可以从中有一些软件设计上的收获。</li><li>最重要的希望这些基础知识可以让你搞清很多以前一些似是而非的东西，并且你能意识到基础的重要。</li></ul><p>所以，本文不会面面俱到，只是对TCP协议、算法和原理的科普。</p><p>我本来只想写一个篇幅的文章的，但是TCP真TMD的复杂，比C++复杂多了，这30多年来，各种优化变种争论和修改。所以，写着写着就发现只有砍成两篇。</p><ul><li>上篇中，主要向你介绍TCP协议的定义和丢包时的重传机制。</li><li>下篇中，重点介绍TCP的流迭、拥塞处理。<span id="more"></span></li></ul><p>废话少说，首先，我们需要知道TCP在网络OSI的七层模型中的第四层——Transport层，IP在第三层——Network层，ARP在第二层——Data Link层，在第二层上的数据，我们叫Frame，在第三层上的数据叫Packet，第四层的数据叫Segment。</p><p>首先，我们需要知道，我们程序的数据首先会打到TCP的Segment中，然后TCP的Segment会打到IP的Packet中，然后再打到以太网Ethernet的Frame中，传到对端后，各个层解析自己的协议，然后把数据交给更高层的协议处理。</p><h4 id="TCP头格式"><a href="#TCP头格式" class="headerlink" title="TCP头格式"></a>TCP头格式</h4><p>接下来，我们来看一下TCP头的格式</p><p><img src="https://res.craft.do/user/full/d3f184bd-2fc6-ae80-c9ed-d9b26e0cd7ba/doc/2ECDCA0E-B498-44FF-BCDA-BCD7B5F57F4F/6CD6A221-6635-4B50-AAB1-32A6F6E49C46_2/Ct8xWuyXZ9y4x5P0TrsThRmIJdJmvj6m7LrfbYRgcnAz/Image.png" alt="Image.png"></p><p>TCP头格式（<a target="_blank" rel="noopener" href="https://nmap.org/book/tcpip-ref.html">图片来源</a>）</p><p>你需要注意这么几点：</p><ul><li>TCP的包是没有IP地址的，那是IP层上的事。但是有源端口和目标端口。</li><li>一个TCP连接需要四个元组来表示是同一个连接（src_ip, src_port, dst_ip, dst_port）准确说是五元组，还有一个是协议。但因为这里只是说TCP协议，所以，这里我只说四元组。</li><li>注意上图中的四个非常重要的东西：<ul><li><strong>Sequence Number</strong>是包的序号，<strong>用来解决网络包乱序（reordering）问题。</strong></li><li><strong>Acknowledgement Number</strong>就是ACK——用于确认收到，<strong>用来解决不丢包的问题</strong>。</li><li><strong>Window又叫Advertised-Window</strong>，也就是著名的滑动窗口（Sliding Window），<strong>用于解决流控的</strong>。</li><li><strong>TCP Flag</strong> ，也就是包的类型，<strong>主要是用于操控TCP的状态机的</strong>。</li></ul></li></ul><p>关于其它的东西，可以参看下面的图示</p><p><img src="https://res.craft.do/user/full/d3f184bd-2fc6-ae80-c9ed-d9b26e0cd7ba/doc/2ECDCA0E-B498-44FF-BCDA-BCD7B5F57F4F/5A4C4434-8C01-4534-9A71-15D1DB9BE5CC_2/gjlf6ENqyHdLXjljUy3YAoMpHgHUhFur1Cz9oyc4bRwz/Image.png" alt="Image.png"></p><p>（<a target="_blank" rel="noopener" href="https://nmap.org/book/tcpip-ref.html">图片来源</a>）</p><h4 id="TCP的状态机"><a href="#TCP的状态机" class="headerlink" title="TCP的状态机"></a>TCP的状态机</h4><p>其实，<strong>网络上的传输是没有连接的，包括TCP也是一样的</strong>。而TCP所谓的“连接”，其实只不过是在通讯的双方维护一个“连接状态”，让它看上去好像有连接一样。所以，TCP的状态变换是非常重要的。</p><p>下面是：“<strong>TCP协议的状态机</strong>”（<a target="_blank" rel="noopener" href="http://www.tcpipguide.com/free/t_TCPOperationalOverviewandtheTCPFiniteStateMachineF-2.htm">图片来源</a>） 和 “<strong>TCP建链接</strong>”、“<strong>TCP断链接</strong>”、“<strong>传数据</strong>” 的对照图，我把两个图并排放在一起，这样方便在你对照着看。另外，下面这两个图非常非常的重要，你一定要记牢。（吐个槽：看到这样复杂的状态机，就知道这个协议有多复杂，复杂的东西总是有很多坑爹的事情，所以TCP协议其实也挺坑爹的）</p><p><img src="https://res.craft.do/user/full/d3f184bd-2fc6-ae80-c9ed-d9b26e0cd7ba/doc/2ECDCA0E-B498-44FF-BCDA-BCD7B5F57F4F/A9DB566E-D742-4649-8F98-EF1F0638EFAD_2/okDKlq2bCx5iKaFbc7dTMnZ0XGTM5xgUFfnlU15yf7Ez/Image.png" alt="Image.png"></p><p>很多人会问，为什么建链接要3次握手，断链接需要4次挥手？</p><ul><li><strong>对于建链接的3次握手，</strong>主要是要初始化Sequence Number 的初始值。通信的双方要互相通知对方自己的初始化的Sequence Number（缩写为ISN：Inital Sequence Number）——所以叫SYN，全称Synchronize Sequence Numbers。也就上图中的 x 和 y。这个号要作为以后的数据通信的序号，以保证应用层接收到的数据不会因为网络上的传输的问题而乱序（TCP会用这个序号来拼接数据）。</li><li><strong>对于4次挥手，</strong>其实你仔细看是2次，因为TCP是全双工的，所以，发送方和接收方都需要Fin和Ack。只不过，有一方是被动的，所以看上去就成了所谓的4次挥手。如果两边同时断连接，那就会就进入到CLOSING状态，然后到达TIME_WAIT状态。下图是双方同时断连接的示意图（你同样可以对照着TCP状态机看）：</li></ul><p><img src="https://res.craft.do/user/full/d3f184bd-2fc6-ae80-c9ed-d9b26e0cd7ba/doc/2ECDCA0E-B498-44FF-BCDA-BCD7B5F57F4F/1323753C-5F53-42ED-B8DD-F2D1104838AB_2/LyUEbQkolv6VHG7lkI2QiEWTSAoSErfQsBmLmRrWDboz/Image.png" alt="Image.png"></p><p>两端同时断连接（<a target="_blank" rel="noopener" href="http://www.tcpipguide.com/free/t_TCPConnectionTermination-4.htm">图片来源</a>）</p><p>另外，有几个事情需要注意一下：</p><ul><li><strong>关于建连接时SYN超时</strong>。试想一下，如果server端接到了clien发的SYN后回了SYN-ACK后client掉线了，server端没有收到client回来的ACK，那么，这个连接处于一个中间状态，即没成功，也没失败。于是，server端如果在一定时间内没有收到的TCP会重发SYN-ACK。在Linux下，默认重试次数为5次，重试的间隔时间从1s开始每次都翻售，5次的重试时间间隔为1s, 2s, 4s, 8s, 16s，总共31s，第5次发出后还要等32s都知道第5次也超时了，所以，总共需要 1s + 2s + 4s+ 8s+ 16s + 32s = 2^6 -1 = 63s，TCP才会把断开这个连接。</li><li><strong>关于SYN Flood攻击</strong>。一些恶意的人就为此制造了SYN Flood攻击——给服务器发了一个SYN后，就下线了，于是服务器需要默认等63s才会断开连接，这样，攻击者就可以把服务器的syn连接的队列耗尽，让正常的连接请求不能处理。于是，Linux下给了一个叫<strong>tcp_syncookies</strong>的参数来应对这个事——当SYN队列满了后，TCP会通过源地址端口、目标地址端口和时间戳打造出一个特别的Sequence Number发回去（又叫cookie），如果是攻击者则不会有响应，如果是正常连接，则会把这个 SYN Cookie发回来，然后服务端可以通过cookie建连接（即使你不在SYN队列中）。请注意，<strong>请先千万别用tcp_syncookies来处理正常的大负载的连接的情况</strong>。因为，synccookies是妥协版的TCP协议，并不严谨。对于正常的请求，你应该调整三个TCP参数可供你选择，第一个是：tcp_synack_retries 可以用他来减少重试次数；第二个是：tcp_max_syn_backlog，可以增大SYN连接数；第三个是：tcp_abort_on_overflow 处理不过来干脆就直接拒绝连接了。</li><li><strong>关于ISN的初始化</strong>。ISN是不能hard code的，不然会出问题的——比如：如果连接建好后始终用1来做ISN，如果client发了30个segment过去，但是网络断了，于是 client重连，又用了1做ISN，但是之前连接的那些包到了，于是就被当成了新连接的包，此时，client的Sequence Number 可能是3，而Server端认为client端的这个号是30了。全乱了。<a target="_blank" rel="noopener" href="https://tools.ietf.org/html/rfc793">RFC793</a>中说，ISN会和一个假的时钟绑在一起，这个时钟会在每4微秒对ISN做加一操作，直到超过2^32，又从0开始。这样，一个ISN的周期大约是4.55个小时。因为，我们假设我们的TCP Segment在网络上的存活时间不会超过Maximum Segment Lifetime（缩写为MSL – <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Maximum_Segment_Lifetime">Wikipedia语条</a>），所以，只要MSL的值小于4.55小时，那么，我们就不会重用到ISN。</li><li><strong>关于 MSL 和 TIME_WAIT</strong>。通过上面的ISN的描述，相信你也知道MSL是怎么来的了。我们注意到，在TCP的状态图中，从TIME_WAIT状态到CLOSED状态，有一个超时设置，这个超时设置是 2*MSL（<a target="_blank" rel="noopener" href="https://tools.ietf.org/html/rfc793">RFC793</a>定义了MSL为2分钟，Linux设置成了30s）为什么要这有TIME_WAIT？为什么不直接给转成CLOSED状态呢？主要有两个原因：1）TIME_WAIT确保有足够的时间让对端收到了ACK，如果被动关闭的那方没有收到Ack，就会触发被动端重发Fin，一来一去正好2个MSL，2）有足够的时间让这个连接不会跟后面的连接混在一起（你要知道，有些自做主张的路由器会缓存IP数据包，如果连接被重用了，那么这些延迟收到的包就有可能会跟新连接混在一起）。你可以看看这篇文章《<a target="_blank" rel="noopener" href="http://www.serverframework.com/asynchronousevents/2011/01/time-wait-and-its-design-implications-for-protocols-and-scalable-servers.html">TIME_WAIT and its design implications for protocols and scalable client server systems</a>》</li><li><strong>关于TIME_WAIT数量太多</strong>。从上面的描述我们可以知道，TIME_WAIT是个很重要的状态，但是如果在大并发的短链接下，TIME_WAIT 就会太多，这也会消耗很多系统资源。只要搜一下，你就会发现，十有八九的处理方式都是教你设置两个参数，一个叫<strong>tcp_tw_reuse</strong>，另一个叫<strong>tcp_tw_recycle</strong>的参数，这两个参数默认值都是被关闭的，后者recyle比前者resue更为激进，resue要温柔一些。另外，如果使用tcp_tw_reuse，必需设置tcp_timestamps=1，否则无效。这里，你一定要注意，<strong>打开这两个参数会有比较大的坑——可能会让TCP连接出一些诡异的问题</strong>（因为如上述一样，如果不等待超时重用连接的话，新的连接可能会建不上。正如<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/Documentation/networking/ip-sysctl.txt">官方文档</a>上说的一样“<strong>It should not be changed without advice/request of technical experts</strong>”）。</li><li><strong>关于tcp_tw_reuse</strong>。官方文档上说tcp_tw_reuse 加上tcp_timestamps（又叫PAWS, for Protection Against Wrapped Sequence Numbers）可以保证协议的角度上的安全，但是你需要tcp_timestamps在两边都被打开（你可以读一下<a target="_blank" rel="noopener" href="http://lxr.free-electrons.com/ident?i=tcp_twsk_unique">tcp_twsk_unique</a>的源码 ）。我个人估计还是有一些场景会有问题。</li><li><strong>关于tcp_tw_recycle</strong>。如果是tcp_tw_recycle被打开了话，会假设对端开启了tcp_timestamps，然后会去比较时间戳，如果时间戳变大了，就可以重用。但是，如果对端是一个NAT网络的话（如：一个公司只用一个IP出公网）或是对端的IP被另一台重用了，这个事就复杂了。建链接的SYN可能就被直接丢掉了（你可能会看到connection time out的错误）（如果你想观摩一下Linux的内核代码，请参看源码 <a target="_blank" rel="noopener" href="http://lxr.free-electrons.com/ident?i=tcp_timewait_state_process">tcp_timewait_state_process</a>）。</li><li><strong>关于tcp_max_tw_buckets</strong>。这个是控制并发的TIME_WAIT的数量，默认值是180000，如果超限，那么，系统会把多的给destory掉，然后在日志里打一个警告（如：time wait bucket table overflow），官网文档说这个参数是用来对抗DDoS攻击的。也说的默认值180000并不小。这个还是需要根据实际情况考虑。</li></ul><p><strong>Again，使用tcp_tw_reuse和tcp_tw_recycle来解决TIME_WAIT的问题是非常非常危险的，因为这两个参数违反了TCP协议（</strong><a target="_blank" rel="noopener" href="https://tools.ietf.org/html/rfc1122"><strong>RFC 1122</strong></a><strong>）</strong></p><p>其实，TIME_WAIT表示的是你主动断连接，所以，这就是所谓的“不作死不会死”。试想，如果让对端断连接，那么这个破问题就是对方的了，呵呵。另外，如果你的服务器是于HTTP服务器，那么设置一个<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/HTTP_persistent_connection">HTTP的KeepAlive</a>有多重要（浏览器会重用一个TCP连接来处理多个HTTP请求），然后让客户端去断链接（你要小心，浏览器可能会非常贪婪，他们不到万不得已不会主动断连接）。</p><h4 id="数据传输中的Sequence-Number"><a href="#数据传输中的Sequence-Number" class="headerlink" title="数据传输中的Sequence Number"></a>数据传输中的Sequence Number</h4><p>下图是我从Wireshark中截了个我在访问coolshell.cn时的有数据传输的图给你看一下，SeqNum是怎么变的。（使用Wireshark菜单中的Statistics -&gt;Flow Graph… ）</p><p><img src="https://res.craft.do/user/full/d3f184bd-2fc6-ae80-c9ed-d9b26e0cd7ba/doc/2ECDCA0E-B498-44FF-BCDA-BCD7B5F57F4F/56C26480-DFD5-41C3-AC17-2346FBC74DC7_2/yifLL4pbPm5hx5M1q6RU7iUOsSmn76ZsytyDQyCZfnwz/Image.png" alt="Image.png"></p><p>你可以看到，<strong>SeqNum的增加是和传输的字节数相关的</strong>。上图中，三次握手后，来了两个Len:1440的包，而第二个包的SeqNum就成了1441。然后第一个ACK回的是1441，表示第一个1440收到了。</p><p><strong>注意</strong>：如果你用Wireshark抓包程序看3次握手，你会发现SeqNum总是为0，不是这样的，Wireshark为了显示更友好，使用了Relative SeqNum——相对序号，你只要在右键菜单中的protocol preference 中取消掉就可以看到“Absolute SeqNum”了</p><h4 id="TCP重传机制"><a href="#TCP重传机制" class="headerlink" title="TCP重传机制"></a>TCP重传机制</h4><p>TCP要保证所有的数据包都可以到达，所以，必需要有重传机制。</p><p>注意，接收端给发送端的Ack确认只会确认最后一个连续的包，比如，发送端发了1,2,3,4,5一共五份数据，接收端收到了1，2，于是回ack 3，然后收到了4（注意此时3没收到），此时的TCP会怎么办？我们要知道，因为正如前面所说的，<strong>SeqNum和Ack是以字节数为单位，所以ack的时候，不能跳着确认，只能确认最大的连续收到的包</strong>，不然，发送端就以为之前的都收到了。</p><h4 id="超时重传机制"><a href="#超时重传机制" class="headerlink" title="超时重传机制"></a>超时重传机制</h4><p>一种是不回ack，死等3，当发送方发现收不到3的ack超时后，会重传3。一旦接收方收到3后，会ack 回 4——意味着3和4都收到了。</p><p>但是，这种方式会有比较严重的问题，那就是因为要死等3，所以会导致4和5即便已经收到了，而发送方也完全不知道发生了什么事，因为没有收到Ack，所以，发送方可能会悲观地认为也丢了，所以有可能也会导致4和5的重传。</p><p>对此有两种选择：</p><ul><li>一种是仅重传timeout的包。也就是第3份数据。</li><li>另一种是重传timeout后所有的数据，也就是第3，4，5这三份数据。</li></ul><p>这两种方式有好也有不好。第一种会节省带宽，但是慢，第二种会快一点，但是会浪费带宽，也可能会有无用功。但总体来说都不好。因为都在等timeout，timeout可能会很长（在下篇会说TCP是怎么动态地计算出timeout的）</p><h4 id="快速重传机制"><a href="#快速重传机制" class="headerlink" title="快速重传机制"></a>快速重传机制</h4><p>于是，TCP引入了一种叫<strong>Fast Retransmit</strong> 的算法，<strong>不以时间驱动，而以数据驱动重传</strong>。也就是说，如果，包没有连续到达，就ack最后那个可能被丢了的包，如果发送方连续收到3次相同的ack，就重传。Fast Retransmit的好处是不用等timeout了再重传。</p><p>比如：如果发送方发出了1，2，3，4，5份数据，第一份先到送了，于是就ack回2，结果2因为某些原因没收到，3到达了，于是还是ack回2，后面的4和5都到了，但是还是ack回2，因为2还是没有收到，于是发送端收到了三个ack=2的确认，知道了2还没有到，于是就马上重转2。然后，接收端收到了2，此时因为3，4，5都收到了，于是ack回6。示意图如下：</p><p><img src="https://res.craft.do/user/full/d3f184bd-2fc6-ae80-c9ed-d9b26e0cd7ba/doc/2ECDCA0E-B498-44FF-BCDA-BCD7B5F57F4F/34913B5D-8199-4D3F-857A-A86A28D43531_2/SiiJn9GdvPrJV5INMogwqxyYenjGXSXRrWFzWrk5OBEz/Image.png" alt="Image.png"></p><p>Fast Retransmit只解决了一个问题，就是timeout的问题，它依然面临一个艰难的选择，就是，是重传之前的一个还是重传所有的问题。对于上面的示例来说，是重传#2呢还是重传#2，#3，#4，#5呢？因为发送端并不清楚这连续的3个ack(2)是谁传回来的？也许发送端发了20份数据，是#6，#10，#20传来的呢。这样，发送端很有可能要重传从2到20的这堆数据（这就是某些TCP的实际的实现）。可见，这是一把双刃剑。</p><h4 id="SACK-方法"><a href="#SACK-方法" class="headerlink" title="SACK 方法"></a>SACK 方法</h4><p>另外一种更好的方式叫：**Selective Acknowledgment (SACK)**（参看<a target="_blank" rel="noopener" href="https://tools.ietf.org/html/rfc2018">RFC 2018</a>），这种方式需要在TCP头里加一个SACK的东西，ACK还是Fast Retransmit的ACK，SACK则是汇报收到的数据碎版。参看下图：</p><p><img src="https://res.craft.do/user/full/d3f184bd-2fc6-ae80-c9ed-d9b26e0cd7ba/doc/2ECDCA0E-B498-44FF-BCDA-BCD7B5F57F4F/17FD241A-881B-4A2C-87F2-B8A50AB1DBA4_2/GyVy6qMvLWzDF09THr7gQATC4TYKtIMiMa3PMm4MMmUz/Image.png" alt="Image.png"></p><p>这样，在发送端就可以根据回传的SACK来知道哪些数据到了，哪些没有到。于是就优化了Fast Retransmit的算法。当然，这个协议需要两边都支持。在 Linux下，可以通过<strong>tcp_sack</strong>参数打开这个功能（Linux 2.4后默认打开）。</p><p>这里还需要注意一个问题——<strong>接收方Reneging，所谓Reneging的意思就是接收方有权把已经报给发送端SACK里的数据给丢了</strong>。这样干是不被鼓励的，因为这个事会把问题复杂化了，但是，接收方这么做可能会有些极端情况，比如要把内存给别的更重要的东西。<strong>所以，发送方也不能完全依赖SACK，还是要依赖ACK，并维护Time-Out，如果后续的ACK没有增长，那么还是要把SACK的东西重传，另外，接收端这边永远不能把SACK的包标记为Ack。</strong></p><p>注意：SACK会消费发送方的资源，试想，如果一个攻击者给数据发送方发一堆SACK的选项，这会导致发送方开始要重传甚至遍历已经发出的数据，这会消耗很多发送端的资源。详细的东西请参看《<a target="_blank" rel="noopener" href="https://www.ibm.com/developerworks/cn/linux/l-tcp-sack/">TCP SACK的性能权衡</a>》</p><h4 id="Duplicate-SACK-–-重复收到数据的问题"><a href="#Duplicate-SACK-–-重复收到数据的问题" class="headerlink" title="Duplicate SACK – 重复收到数据的问题"></a>Duplicate SACK – 重复收到数据的问题</h4><p>Duplicate SACK又称D-SACK，<strong>其主要使用了SACK来告诉发送方有哪些数据被重复接收了</strong>。<a target="_blank" rel="noopener" href="https://www.ietf.org/rfc/rfc2883.txt">RFC-2883</a> 里有详细描述和示例。下面举几个例子（来源于<a target="_blank" rel="noopener" href="https://www.ietf.org/rfc/rfc2883.txt">RFC-2883</a>）</p><p>D-SACK使用了SACK的第一个段来做标志，</p><ul><li>如果SACK的第一个段的范围被ACK所覆盖，那么就是D-SACK</li><li>如果SACK的第一个段的范围被SACK的第二个段覆盖，那么就是D-SACK</li></ul><p><strong>示例一：ACK丢包</strong></p><p>下面的示例中，丢了两个ACK，所以，发送端重传了第一个数据包（3000-3499），于是接收端发现重复收到，于是回了一个SACK=3000-3500，因为ACK都到了4000意味着收到了4000之前的所有数据，所以这个SACK就是D-SACK——旨在告诉发送端我收到了重复的数据，而且我们的发送端还知道，数据包没有丢，丢的是ACK包。</p><p><strong>示例二，网络延误</strong></p><p>下面的示例中，网络包（1000-1499）被网络给延误了，导致发送方没有收到ACK，而后面到达的三个包触发了“Fast Retransmit算法”，所以重传，但重传时，被延误的包又到了，所以，回了一个SACK=1000-1500，因为ACK已到了3000，所以，这个SACK是D-SACK——标识收到了重复的包。</p><p>这个案例下，发送端知道之前因为“Fast Retransmit算法”触发的重传不是因为发出去的包丢了，也不是因为回应的ACK包丢了，而是因为网络延时了。</p><p>可见，引入了D-SACK，有这么几个好处：</p><p>1）可以让发送方知道，是发出去的包丢了，还是回来的ACK包丢了。</p><p>2）是不是自己的timeout太小了，导致重传。</p><p>3）网络上出现了先发的包后到的情况（又称reordering）</p><p>4）网络上是不是把我的数据包给复制了。</p><p><strong>知道这些东西可以很好得帮助TCP了解网络情况，从而可以更好的做网络上的流控</strong>。</p><p>Linux下的tcp_dsack参数用于开启这个功能（Linux 2.4后默认打开）</p><p>好了，上篇就到这里结束了。如果你觉得我写得还比较浅显易懂，那么，欢迎移步看下篇</p>]]></content>
      
      
      <categories>
          
          <category> network </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tcp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统-下</title>
      <link href="2022/11/29/os-%E7%B3%BB%E7%BB%9F%E6%95%B4%E7%90%86-%E4%B8%8B/"/>
      <url>2022/11/29/os-%E7%B3%BB%E7%BB%9F%E6%95%B4%E7%90%86-%E4%B8%8B/</url>
      
        <content type="html"><![CDATA[<h3 id="Linux操作系统概览"><a href="#Linux操作系统概览" class="headerlink" title="Linux操作系统概览"></a>Linux操作系统概览</h3><h3 id="物理内存"><a href="#物理内存" class="headerlink" title="物理内存"></a>物理内存</h3><ul><li>物理内存分 NUMA 节点，分别进行管理；</li><li>每个 NUMA 节点分成多个内存区域；</li><li>每个内存区域分成多个物理页面；</li><li>伙伴系统将多个连续的页面作为一个大的内存块分配给上层；</li><li>kswapd 负责物理页面的换入换出；</li><li>Slub Allocator 将从伙伴系统申请的大内存块切成小块，分配给其他系统</li></ul><span id="more"></span><p><img src="https://res.craft.do/user/full/27f84843-d4d8-568d-3b2d-db22e5d6ce15/doc/ED937B27-BC42-42DC-ABC6-04212DE63155/54F862A0-8386-49BF-8B3F-DEE9C8A646AE_2/gyolywXXfXQonISDGUYFDIkKa9pLydFhUuO59MXYMccz/Image.png" alt="Image.png"></p><h3 id="用户态的内存映射机制"><a href="#用户态的内存映射机制" class="headerlink" title="用户态的内存映射机制"></a>用户态的内存映射机制</h3><ul><li>用户态内存映射函数 mmap，包括用它来做匿名映射和文件映射。</li><li>用户态的页表结构，存储位置在 mm_struct 中。</li><li>在用户态访问没有映射的内存会引发缺页异常，分配物理页表、补齐页表。如果是匿名映射则分配物理内存；如果是 swap，则将 swap 文件读入；如果是文件映射，则将文件读入。</li></ul><p><img src="https://res.craft.do/user/full/27f84843-d4d8-568d-3b2d-db22e5d6ce15/doc/ED937B27-BC42-42DC-ABC6-04212DE63155/C4FFEB6E-626D-4F7C-A07C-B7909051941F_2/YRRQqzrK4RPGRwz3EvB7e76eBrpiJvDfVMEnBe1ePmgz/Image.png" alt="Image.png"></p><h3 id="内存管理体系"><a href="#内存管理体系" class="headerlink" title="内存管理体系"></a>内存管理体系</h3><p>物理内存根据 NUMA 架构分节点。每个节点里面再分区域。每个区域里面再分页。</p><p>物理页面通过伙伴系统进行分配。分配的物理页面要变成虚拟地址让上层可以访问，kswapd 可以根据物理页面的使用情况对页面进行换入换出。</p><p>对于内存的分配需求，可能来自内核态，也可能来自用户态。</p><p>对于内核态，kmalloc 在分配大内存的时候，以及 vmalloc 分配不连续物理页的时候，直接使用伙伴系统，分配后转换为虚拟地址，访问的时候需要通过内核页表进行映射。</p><p>对于 kmem_cache 以及 kmalloc 分配小内存，则使用 slub 分配器，将伙伴系统分配出来的大块内存切成一小块一小块进行分配。</p><p>kmem_cache 和 kmalloc 的部分不会被换出，因为用这两个函数分配的内存多用于保持内核关键的数据结构。内核态中 vmalloc 分配的部分会被换出，因而当访问的时候，发现不在，就会调用 do_page_fault。</p><p>对于用户态的内存分配，或者直接调用 mmap 系统调用分配，或者调用 malloc。调用 malloc 的时候，如果分配小的内存，就用 sys_brk 系统调用；如果分配大的内存，还是用 sys_mmap 系统调用。正常情况下，用户态的内存都是可以换出的，因而一旦发现内存中不存在，就会调用 do_page_fault。</p><p><img src="https://res.craft.do/user/full/27f84843-d4d8-568d-3b2d-db22e5d6ce15/doc/ED937B27-BC42-42DC-ABC6-04212DE63155/AAC4B331-77B6-490B-AD71-D52671D0CD4B_2/ReuYEXAMBNYZdkWFnsIweuNA5bWuXjakI3cOoF17P24z/Image.png" alt="Image.png"></p><h3 id="文件系统"><a href="#文件系统" class="headerlink" title="文件系统"></a>文件系统</h3><p><img src="https://res.craft.do/user/full/27f84843-d4d8-568d-3b2d-db22e5d6ce15/doc/ED937B27-BC42-42DC-ABC6-04212DE63155/3635231F-E1A2-4D50-9AA1-F6180AEE5E32_2/iBnsEdRlLYuPwGGHc7FP7JeimBUgBFKMfQsc8JBJlj8z/Image.png" alt="Image.png"></p><h3 id="进程通信"><a href="#进程通信" class="headerlink" title="进程通信"></a>进程通信</h3><p>进程间通信的各种模式</p><ul><li>类似瀑布开发模式的管道</li><li>类似邮件模式的消息队列</li><li>类似会议室联合开发的共享内存加信号量</li><li>类似应急预案的信号</li></ul><p>当你自己使用的时候，可以根据不同的通信需要，选择不同的模式。</p><ul><li>管道，请你记住这是命令行中常用的模式，面试问到的话，不要忘了。</li><li>消息队列其实很少使用，因为有太多的用户级别的消息队列，功能更强大。</li><li>共享内存加信号量是常用的模式。这个需要牢记，常见到一些知名的以 C 语言开发的开源软件都会用到它。</li><li>信号更加常用，机制也比较复杂。  我们后面会有单独的一节来解析。</li></ul><h3 id="信号处理机制"><a href="#信号处理机制" class="headerlink" title="信号处理机制"></a>信号处理机制</h3><ul><li>在用户程序里面，有两个函数可以调用，一个是 signal，一个是 sigaction，推荐使用 sigaction。</li><li>用户程序调用的是 Glibc 里面的函数，signal 调用的是 __sysv_signal，里面默认设置了一些参数，使得 signal 的功能受到了限制，sigaction 调用的是 __sigaction，参数用户可以任意设定。</li><li>无论是 __sysv_signal 还是 __sigaction，调用的都是统一的一个系统调用 rt_sigaction。</li><li>在内核中，rt_sigaction 调用的是 do_sigaction 设置信号处理函数。在每一个进程的 task_struct 里面，都有一个 sighand 指向 struct sighand_struct，里面是一个数组，下标是信号，里面的内容是信号处理函数</li></ul><p><img src="https://res.craft.do/user/full/27f84843-d4d8-568d-3b2d-db22e5d6ce15/doc/ED937B27-BC42-42DC-ABC6-04212DE63155/2BFFB341-CBA5-415D-B622-4660FA7E21F4_2/KaQpKUuNBQZOs0H0AjSyb429l4rWcPVzPDcRBlRp5e4z/Image.png" alt="Image.png"></p><h3 id="socket"><a href="#socket" class="headerlink" title="socket"></a>socket</h3><p>两种网络协议模型</p><p>TCP/UDP-&gt;IPv4-&gt;ARP</p><p><img src="https://res.craft.do/user/full/27f84843-d4d8-568d-3b2d-db22e5d6ce15/doc/ED937B27-BC42-42DC-ABC6-04212DE63155/C4628019-6678-4EB3-A3B8-4D5690D4B98C_2/r2y0FpjvrnqkwP1Wc4DbyzQcpqT9yLX4yEM3FvHk6kMz/Image.png" alt="Image.png"></p><p><img src="https://res.craft.do/user/full/27f84843-d4d8-568d-3b2d-db22e5d6ce15/doc/ED937B27-BC42-42DC-ABC6-04212DE63155/6E92901F-753E-4B8E-91C3-877D3363C0D5_2/Sf7zAu9vqNfmrx1LSVt31uqOEbz4tc89owaFvFZijPIz/Image.png" alt="Image.png"></p><h3 id="socket-使用"><a href="#socket-使用" class="headerlink" title="socket 使用"></a>socket 使用</h3><p>在传输层有两个主流的协议 TCP 和 UDP，所以我们的 socket 程序设计也是主要操作这两个协议</p><p>当然，无论是用 socket 操作 TCP，还是 UDP，我们首先都要调用 socket 函数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int socket(int domain, int type, int protocol);</span><br></pre></td></tr></table></figure><p>socket 函数用于创建一个 socket 的文件描述符，唯一标识一个 socket。我们把它叫作文件描述符，因为在内核中，我们会创建类似文件系统的数据结构，并且后续的操作都有用到它。</p><p>socket 函数有三个参数。</p><ul><li>domain：表示使用什么 IP 层协议。AF_INET 表示 IPv4，AF_INET6 表示 IPv6。</li><li>type：表示 socket 类型。SOCK_STREAM，顾名思义就是 TCP 面向流的，SOCK_DGRAM 就是 UDP 面向数据报的，SOCK_RAW 可以直接操作 IP 层，或者非 TCP 和 UDP 的协议。例如 ICMP。</li><li>protocol 表示的协议，包括 IPPROTO_TCP、IPPTOTO_UDP。</li></ul><p>通信结束后，我们还要像关闭文件一样，关闭 socket。</p><p><img src="https://res.craft.do/user/full/27f84843-d4d8-568d-3b2d-db22e5d6ce15/doc/ED937B27-BC42-42DC-ABC6-04212DE63155/97946327-C21F-4382-9662-C41528A79BAB_2/EAvPXq6hczBRBQIMLCTnxysVegNqp1yLDhGljpld8ycz/Image.png" alt="Image.png"></p><p><img src="https://res.craft.do/user/full/27f84843-d4d8-568d-3b2d-db22e5d6ce15/doc/ED937B27-BC42-42DC-ABC6-04212DE63155/F64B2722-8919-4559-93F6-0B6CC46A32F5_2/rha3Ow2oy8QOMKG1yDMfRAXHwC1bVsS8a0j0ovvcx5gz/Image.png" alt="Image.png"></p><p><img src="https://res.craft.do/user/full/27f84843-d4d8-568d-3b2d-db22e5d6ce15/doc/ED937B27-BC42-42DC-ABC6-04212DE63155/D6E491A5-7013-421B-8098-F07A09F6D26D_2/UgVyZJPW4RQwvKEdsW0y4syUJUY0R8XEpVfXTyjbG5Mz/Image.png" alt="Image.png"></p><p>TCP 协议的 socket 调用的过程</p><ul><li>服务端和客户端都调用 socket，得到文件描述符；</li><li>服务端调用 listen，进行监听；</li><li>服务端调用 accept，等待客户端连接；</li><li>客户端调用 connect，连接服务端；</li><li>服务端 accept 返回用于传输的 socket 的文件描述符；</li><li>客户端调用 write 写入数据；</li><li>服务端调用 read 读取数据。</li></ul><p><img src="https://res.craft.do/user/full/27f84843-d4d8-568d-3b2d-db22e5d6ce15/doc/ED937B27-BC42-42DC-ABC6-04212DE63155/A19CFA41-22C4-44E4-8658-26EA7A6DAF34_2/2sfEA0VpYPWw3jrxDzNbHuahg9gzndSpiJCtQV0Zp0wz/Image.png" alt="Image.png"></p><p><img src="https://res.craft.do/user/full/27f84843-d4d8-568d-3b2d-db22e5d6ce15/doc/ED937B27-BC42-42DC-ABC6-04212DE63155/4BB3A853-9927-404F-AA28-CF4D698D83EE_2/nx9zzzwm2GMnxBjnX60KCYFeRxDKUIYjXxNkL9OQVxcz/Image.png" alt="Image.png"></p><h3 id="发送网络包"><a href="#发送网络包" class="headerlink" title="发送网络包"></a>发送网络包</h3><ul><li>VFS 层：write 系统调用找到 struct file，根据里面的 file_operations 的定义，调用 sock_write_iter 函数。sock_write_iter 函数调用 sock_sendmsg 函数。</li><li>Socket 层：从 struct file 里面的 private_data 得到 struct socket，根据里面 ops 的定义，调用 inet_sendmsg 函数。</li><li>Sock 层：从 struct socket 里面的 sk 得到 struct sock，根据里面 sk_prot 的定义，调用 tcp_sendmsg 函数。</li><li>TCP 层：tcp_sendmsg 函数会调用 tcp_write_xmit 函数，tcp_write_xmit 函数会调用 tcp_transmit_skb，在这里实现了 TCP 层面向连接的逻辑。</li><li>IP 层：扩展 struct sock，得到 struct inet_connection_sock，根据里面 icsk_af_ops 的定义，调用 ip_queue_xmit 函数。</li><li>IP 层：ip_route_output_ports 函数里面会调用 fib_lookup 查找路由表。FIB 全称是 Forwarding Information Base，转发信息表，也就是路由表。</li><li>在 IP 层里面要做的另一个事情是填写 IP 层的头。</li><li>在 IP 层还要做的一件事情就是通过 iptables 规则。</li><li>MAC 层：IP 层调用 ip_finish_output 进行 MAC 层。</li><li>MAC 层需要 ARP 获得 MAC 地址，因而要调用 ___neigh_lookup_noref 查找属于同一个网段的邻居，他会调用 neigh_probe 发送 ARP。</li><li>有了 MAC 地址，就可以调用 dev_queue_xmit 发送二层网络包了，它会调用 __dev_xmit_skb 会将请求放入队列。</li><li>设备层：网络包的发送回触发一个软中断 NET_TX_SOFTIRQ 来处理队列中的数据。这个软中断的处理函数是 net_tx_action。</li><li>在软中断处理函数中，会将网络包从队列上拿下来，调用网络设备的传输函数 ixgb_xmit_frame，将网络包发的设备的队列上去。</li></ul><p><img src="https://res.craft.do/user/full/27f84843-d4d8-568d-3b2d-db22e5d6ce15/doc/ED937B27-BC42-42DC-ABC6-04212DE63155/270716AA-E236-465E-80A1-292DCF65B298_2/HMTyLROXlkM3o1cfy02cIdPByVX09deaLD45R7cKI98z/Image.png" alt="Image.png"></p><h3 id="接收网络包"><a href="#接收网络包" class="headerlink" title="接收网络包"></a>接收网络包</h3><ul><li>硬件网卡接收到网络包之后，通过 DMA 技术，将网络包放入 Ring Buffer；</li><li>硬件网卡通过中断通知 CPU 新的网络包的到来；</li><li>网卡驱动程序会注册中断处理函数 ixgb_intr；</li><li>中断处理函数处理完需要暂时屏蔽中断的核心流程之后，通过软中断 NET_RX_SOFTIRQ 触发接下来的处理过程；</li><li>NET_RX_SOFTIRQ 软中断处理函数 net_rx_action，net_rx_action 会调用 napi_poll，进而调用 ixgb_clean_rx_irq，从 Ring Buffer 中读取数据到内核 struct sk_buff；</li><li>调用 netif_receive_skb 进入内核网络协议栈，进行一些关于 VLAN 的二层逻辑处理后，调用 ip_rcv 进入三层 IP 层；</li><li>在 IP 层，会处理 iptables 规则，然后调用 ip_local_deliver 交给更上层 TCP 层；</li><li>在 TCP 层调用 tcp_v4_rcv，这里面有三个队列需要处理，如果当前的 Socket 不是正在被读；取，则放入 backlog 队列，如果正在被读取，不需要很实时的话，则放入 prequeue 队列，其他情况调用 tcp_v4_do_rcv；</li><li>在 tcp_v4_do_rcv 中，如果是处于 TCP_ESTABLISHED 状态，调用 tcp_rcv_established，其他的状态，调用 tcp_rcv_state_process；</li><li>在 tcp_rcv_established 中，调用 tcp_data_queue，如果序列号能够接的上，则放入 sk_receive_queue 队列；如果序列号接不上，则暂时放入 out_of_order_queue 队列，等序列号能够接上的时候，再放入 sk_receive_queue 队列。</li></ul><p>至此内核接收网络包的过程到此结束，接下来就是用户态读取网络包的过程，这个过程分成几个层次。</p><ul><li>VFS 层：read 系统调用找到 struct file，根据里面的 file_operations 的定义，调用 sock_read_iter 函数。sock_read_iter 函数调用 sock_recvmsg 函数。</li><li>Socket 层：从 struct file 里面的 private_data 得到 struct socket，根据里面 ops 的定义，调用 inet_recvmsg 函数。</li><li>Sock 层：从 struct socket 里面的 sk 得到 struct sock，根据里面 sk_prot 的定义，调用 tcp_recvmsg 函数。</li><li>TCP 层：tcp_recvmsg 函数会依次读取 receive_queue 队列、prequeue 队列和 backlog 队列。</li></ul><p><img src="https://res.craft.do/user/full/27f84843-d4d8-568d-3b2d-db22e5d6ce15/doc/ED937B27-BC42-42DC-ABC6-04212DE63155/0C89A4BD-8DAA-4F0B-B89D-53F0E8CA786B_2/bvnNjlSpIY0yAwtpnKqgzZqPyypszsw79x3ii9IXPa0z/Image.png" alt="Image.png"></p>]]></content>
      
      
      <categories>
          
          <category> OS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> OS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统-上</title>
      <link href="2022/11/28/os-%E7%B3%BB%E7%BB%9F%E6%95%B4%E7%90%86/"/>
      <url>2022/11/28/os-%E7%B3%BB%E7%BB%9F%E6%95%B4%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h3 id="Linux操作系统概览"><a href="#Linux操作系统概览" class="headerlink" title="Linux操作系统概览"></a>Linux操作系统概览</h3><h3 id="内核初始化"><a href="#内核初始化" class="headerlink" title="内核初始化"></a>内核初始化</h3><p>用户态 - 系统调用 - 保存寄存器 - 内核态执行系统调用 - 恢复寄存器 - 返回用户态</p><p><img src="https://res.craft.do/user/full/27f84843-d4d8-568d-3b2d-db22e5d6ce15/doc/ED937B27-BC42-42DC-ABC6-04212DE63155/6C97FED1-4457-463A-BB9F-129E0522EFC1_2/w6pwUQCiKUXyUFfECuUj53pGxyxlHwBMM0mT6ky8jmQz/Image.png" alt="Image.png"></p><span id="more"></span><p><img src="https://res.craft.do/user/full/27f84843-d4d8-568d-3b2d-db22e5d6ce15/doc/ED937B27-BC42-42DC-ABC6-04212DE63155/392EA7C3-802C-4D65-A9CC-8FEB117635BC_2/ifMx6XfepiWStQxnATEWxjaF2EH1t0DRLPTQmuNgoBkz/Image.png" alt="Image.png"></p><h3 id="内核初始化-1"><a href="#内核初始化-1" class="headerlink" title="内核初始化"></a>内核初始化</h3><p>用户态 - 系统调用 - 保存寄存器 - 内核态执行系统调用 - 恢复寄存器 - 返回用户态</p><p>do_execve-&gt;do_execveat_common-&gt;exec_binprm-&gt;search_binary_handler</p><p><img src="https://res.craft.do/user/full/27f84843-d4d8-568d-3b2d-db22e5d6ce15/doc/ED937B27-BC42-42DC-ABC6-04212DE63155/8C0B8233-7698-4735-983B-DCA5476B4827_2/ntxnj3T9WNpUiswKlq0hzHi6KeBvKpLyygeYM53KBRcz/Image.png" alt="Image.png"></p><p><img src="https://res.craft.do/user/full/27f84843-d4d8-568d-3b2d-db22e5d6ce15/doc/ED937B27-BC42-42DC-ABC6-04212DE63155/721E1E53-41CE-4DA9-BACA-0A68E2ADBF17_2/qNlEQyxFiV5as40yQuGord3RZPkmiB1hrv7SPj0cAsMz/Image.png" alt="Image.png"></p><p><img src="https://res.craft.do/user/full/27f84843-d4d8-568d-3b2d-db22e5d6ce15/doc/ED937B27-BC42-42DC-ABC6-04212DE63155/5A829BA1-FA33-4101-B84F-E8069AD1EFAB_2/19f0pAliUCw9ft44zNHvz7IFw5lINP573slQmyC6Iw8z/Image.png" alt="Image.png"></p><p><img src="https://res.craft.do/user/full/27f84843-d4d8-568d-3b2d-db22e5d6ce15/doc/ED937B27-BC42-42DC-ABC6-04212DE63155/2B6A58A2-8FEC-4FDA-B0C4-5D4CA8A971A3_2/j7yivE32hoQX2EubcOy6a2l2CTs74B4HPuDL72feOyYz/Image.png" alt="Image.png"></p><h3 id="系统调用的过程"><a href="#系统调用的过程" class="headerlink" title="系统调用的过程"></a>系统调用的过程</h3><p><img src="https://res.craft.do/user/full/27f84843-d4d8-568d-3b2d-db22e5d6ce15/doc/ED937B27-BC42-42DC-ABC6-04212DE63155/0DDD62AD-0D19-43BF-AD55-A235DD08F56E_2/r4HVzwJt9D9PxiCCPNsbDHxzykazwdhg6mvKRU0GFi0z/Image.png" alt="Image.png"></p><h3 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h3><p>进程从代码到二进制到运行时的过程</p><p><img src="https://res.craft.do/user/full/27f84843-d4d8-568d-3b2d-db22e5d6ce15/doc/ED937B27-BC42-42DC-ABC6-04212DE63155/83C26296-53BB-4CF2-9CCC-E0B32AD17B4E_2/dTncQCCyjMofAX3mvYPcVytn3yYMcF6FaDrUr1stS8Ez/Image.png" alt="Image.png"></p><p><strong>进程相当于一个项目，而线程就是为了完成项目需求，而建立的一个个开发任务</strong></p><p><img src="https://res.craft.do/user/full/27f84843-d4d8-568d-3b2d-db22e5d6ce15/doc/ED937B27-BC42-42DC-ABC6-04212DE63155/AE54E495-E4F5-4B9C-8E03-6E2404114B09_2/0st7LYGrhqK203dy0pF42f9hwcypDhRmpVUnBixYn5Az/Image.png" alt="Image.png"></p><p>在程序执行过程中，一旦调用到系统调用，就需要进入内核继续执行。那如何将用户态的执行和内核态的执行串起来呢？</p><p><img src="https://res.craft.do/user/full/27f84843-d4d8-568d-3b2d-db22e5d6ce15/doc/ED937B27-BC42-42DC-ABC6-04212DE63155/864FAF36-4E49-4C6C-BBC8-71989BA8C622_2/dlxgGJ42HolHy9XVGfST1BVW84jwGjAf3sQkd8FNJ6Iz/Image.png" alt="Image.png"></p><h3 id="调度"><a href="#调度" class="headerlink" title="调度"></a>调度</h3><p>一个 CPU 上有一个队列，CFS 的队列是一棵红黑树，树的每一个节点都是一个 sched_entity，每个 sched_entity 都属于一个 task_struct，task_struct 里面有指针指向这个进程属于哪个调度类, 在调度的时候，依次调用调度类的函数，从 CPU 的队列中取出下一个进程</p><p><img src="https://res.craft.do/user/full/27f84843-d4d8-568d-3b2d-db22e5d6ce15/doc/ED937B27-BC42-42DC-ABC6-04212DE63155/E10D30AB-2AC7-40DA-AE9B-6917192F7560_2/tzkiy5maOcJ81T3exx6kisPDro8km6F8USEqMqUyMs0z/Image.png" alt="Image.png"></p><p><img src="https://res.craft.do/user/full/27f84843-d4d8-568d-3b2d-db22e5d6ce15/doc/ED937B27-BC42-42DC-ABC6-04212DE63155/5A746A48-918A-4C3C-A2ED-29DD2B01842C_2/EOgwSuwPTg7nN1yB0OJps1dTdOYJ0ZcKo2hilJvzBesz/Image.png" alt="Image.png"></p><h3 id="主动调度"><a href="#主动调度" class="headerlink" title="主动调度"></a>主动调度</h3><p>主动调度的过程，也即一个运行中的进程主动调用 __schedule 让出 CPU。在 __schedule 里面会做两件事情，第一是选取下一个进程，第二是进行上下文切换。而上下文切换又分用户态进程空间的切换和内核态的切换</p><h3 id="抢占式调度"><a href="#抢占式调度" class="headerlink" title="抢占式调度"></a>抢占式调度</h3><p><img src="https://res.craft.do/user/full/27f84843-d4d8-568d-3b2d-db22e5d6ce15/doc/ED937B27-BC42-42DC-ABC6-04212DE63155/C7BAE4F0-C716-45D2-A357-144B01BEEC0A_2/HuO73nvDo8bhM0YHq6u93dezjxnnrAvTqnCqEjUF7sYz/Image.png" alt="Image.png"></p><h3 id="进程Fork创建的过程"><a href="#进程Fork创建的过程" class="headerlink" title="进程Fork创建的过程"></a>进程Fork创建的过程</h3><p><img src="https://res.craft.do/user/full/27f84843-d4d8-568d-3b2d-db22e5d6ce15/doc/ED937B27-BC42-42DC-ABC6-04212DE63155/FB7EC04C-FB5E-41BE-81CB-773F97093A7C_2/KElztMcWw4pPlSUkLP6CLeRjsnLZxj4eiD5J8WdB9Aoz/download.jpeg" alt="download.jpeg"></p><h3 id="创建线程"><a href="#创建线程" class="headerlink" title="创建线程"></a>创建线程</h3><p>创建进程的话，调用的系统调用是 fork，在 copy_process 函数里面，会将五大结构 files_struct、fs_struct、sighand_struct、signal_struct、mm_struct 都复制一遍，从此父进程和子进程各用各的数据结构。而创建线程的话，调用的是系统调用 clone，在 copy_process 函数里面， 五大结构仅仅是引用计数加一，也即线程共享进程的数据结构。</p><p><img src="https://res.craft.do/user/full/27f84843-d4d8-568d-3b2d-db22e5d6ce15/doc/ED937B27-BC42-42DC-ABC6-04212DE63155/66A8A068-5535-43C4-A2AE-78AE022856F7_2/6XpCOaTI7wC0oF3OpcpYjyCRxpsabAaeIHH2AwT5pZoz/Image.png" alt="Image.png"></p><h3 id="一个进程运行需要的内存结构"><a href="#一个进程运行需要的内存结构" class="headerlink" title="一个进程运行需要的内存结构"></a>一个进程运行需要的内存结构</h3><p>用户态：</p><ul><li>代码段、全局变量、BSS</li><li>函数栈</li><li>堆</li><li>内存映射区</li></ul><p>内核态：</p><ul><li>内核的代码、全局变量、BSS</li><li>内核数据结构例如 task_struct</li><li>内核栈</li><li>内核中动态分配的内存</li></ul><p><img src="https://res.craft.do/user/full/27f84843-d4d8-568d-3b2d-db22e5d6ce15/doc/ED937B27-BC42-42DC-ABC6-04212DE63155/7966A56D-2424-4582-B71A-030F9507492F_2/CAI6OWeaBX0A0rZNg7ghsdMKmxbQxrbGlBy9kphqZU0z/Image.png" alt="Image.png"></p>]]></content>
      
      
      <categories>
          
          <category> OS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> OS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>官方翻墙服务，多条线路，IP不怕被墙</title>
      <link href="2022/08/15/vpn-vpn/"/>
      <url>2022/08/15/vpn-vpn/</url>
      
        <content type="html"><![CDATA[<h1>Just My Socks：搬瓦工官方翻墙服务，多条线路，IP不怕被墙</h1><h2>力荐！Just My Socks - 非常靠谱稳定的shadowsocks/V2ray代理服务！</h2><h2>文章目录</h2><ol id="user-content-content-index-contents">     <li><a href="#user-content-just1">Just My Socks介绍</a></li>     <li><a href="#user-content-just2">Just My Socks购买</a></li>     <li><a href="#user-content-just3">Just My Socks优惠码</a></li>     <li><a href="#user-content-just4">Just My Socks注册</a></li>     <li><a href="#user-content-just5">Just My Socks信息查看</a></li>     <li><a href="#user-content-just6">Just My Socks怎么用</a></li></ol><p class="keepp">Just My Socks是目前非常火热的一个Shadowsocks/V2ray服务商（机场），由搬瓦工官方推出，每个服务提供5条线路，包括最快的CN2 GIA线路。Just My Socks最大的优势是保证IP不被墙，如果IP被墙，会自动更换新的可用IP给用户。对于只是需要翻墙看看YouTube、ins或者谷歌以及谷歌学术的朋友，Just My Socks是一个非常合适的选择。</p><span id="more"></span><h2 id="user-content-just1"><span id="just_my_socks">一、Just My Socks介绍</span></h2><p class="keepp">Just My Socks是<strong>搬瓦工官方</strong>出品的Shadowsocks/V2ray代理服务，支持支付宝付款，提供ss账号，每个账号有5条线路，包括<strong>搬瓦工CN2 GIA线路</strong>，性价比很高且非常稳定，比买VPS灵活划算且省得折腾，<strong>保证IP可用，被封自动切换</strong>。</p><p class="keepp"><strong>Just My Socks靠谱吗？</strong>不同于其他机场，Just My Socks是搬瓦工官方推出的，已经稳定运行了近1年了（2018年10月推出的），可以说非常靠谱。</p><p class="keepp"><strong>Just My Socks怎么样？</strong>每个ss账号有5个线路，包括最快的搬瓦工CN2 GIA线路，速度很快。</p><p class="keepp"><strong>哪些人适合用Just My Socks？</strong>如果你只是为了翻墙看看YouTube、刷刷ins，或者谷歌，那么你完全不需要折腾VPS，自建ss，Just My Socks可以非常方便的达到这些需求。<strong>Just My Socks缺点</strong>：无法看Netflix。</p><p class="keepp"><strong>支持的协议：TCP或UDP？</strong>Just My Socks 100仅支持TCP协议，该协议足以用于浏览网络以及使用YouTube等大多数流媒体服务。从Just My Socks 500开始的所有套餐均支持TCP和UDP协议（请参阅下面的注释）。语音协议（如WhatsApp和某些VOIP实现）可能需要UDP协议。如果您的套餐是Just My Socks 100，并且您想使用UDP协议，那么您将需要升级到Just My Socks 500套餐。</p><h2 id="user-content-just2"><span id="just_my_socks-2">二、Just My Socks购买</span></h2><p class="keepp">目前，Just My Socks一共有4种方案：</p><table id="tablepress-1"><thead><tr><th>方案名称</th><th>带宽</th><th>流量</th><th>价格</th><th>设备限制</th><th>购买链接</th></tr></thead><tbody><tr><td>Just My Socks 100</td><td>1 GB</td><td>100 GB /月</td><td>$2.88 / 月</td><td>最多3个设备同时在线(当前断货)</td><td><a rel="nofollow noopener" target="_blank" href="https://justmysocks3.net/members/aff.php?aff=17752">立即购买</a></td></tr><tr><td>Just My Socks 500</td><td>2.5 GB</td><td>500 GB / 月</td><td>$5.88 / 月</td><td>最多5个设备同时在线</td><td><a rel="nofollow noopener" target="_blank" href="https://justmysocks3.net/members/aff.php?aff=17752">立即购买</a></td></tr><tr><td>Just My Socks 1000</td><td>5 GB</td><td>1TB / 月</td><td>$9.88 / 月</td><td>不限制设备数量</td><td><a rel="nofollow noopener" target="_blank" href="https://justmysocks3.net/members/aff.php?aff=17752">立即购买</a></td></tr><tr><td>Just My Socks 5000</td><td>5 GB</td><td>5TB / 月</td><td>$48.99 / 月</td><td>不限制设备数量</td><td><a rel="nofollow noopener" target="_blank" href="https://justmysocks3.net/members/aff.php?aff=17752">立即购买</a></td></tr></tbody></table><p class="keepp"><strong>我该选择哪一款Just My Socks？</strong>一般来说，如果只是谷歌查资料，直接选择最便宜的方案就行，如果你爱看视频，并且非常频繁，那么就选择500或者1000的，需要注意的是<span style="color: #ff0000;">便宜方案都有设备限制</span>，如果你想多个人一起用，那么建议选择1000的，不限制设备数量。</p><p class="keepp">选择合适的Just My Socks方案后，点击“立即购买”进入购买页，确认配置无误后，建议年付（Annually），只需要付10个月的价格，点击Continue继续：<br class="keepp">Just My Socks 官网：<a rel="nofollow noopener" target="_blank" href="https://justmysocks3.net/members/aff.php?aff=17752">Just My Socks 官网</a></p><a href="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/20210617105821.png" target="_blank" rel="noopener noreferrer"><img style="max-width:100%" src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/20210617105821.png" alt="Just My Socks 购买教程，若图片无法显示请点击查看" /></a><h2 id="user-content-just3"><span id="just_my_socks-3">三、Just My Socks优惠码</span></h2><p class="keepp">在购买Just My Socks时，我们可以使用Just My Socks优惠码：<strong>JMS9272283</strong>获取5.2%循环优惠，输入优惠码后点击Validate Code即可使用优惠码，点击Checkout付款：<br class="keepp"><a href="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/20210617110034.png" target="_blank" rel="noopener noreferrer"><img style="max-width:100%" src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/20210617110034.png" alt="Just My Socks优惠码，若图片无法显示请点击查看" /></a></p><h2 id="user-content-just4"><span id="just_my_socks-4">四、Just My Socks注册</span></h2><p class="keepp">这里需要填写你Just My Socks账号的信息：<strong>不要挂代理注册，如实填写</strong>，否则可能被认为欺诈，其中省份直接写拼音即可（例如Shandong），选择支付方式为Paypal（Paypal更安全）或 Alipay（支付宝），勾选同意服务条款后，点击Complete Order完成订单：<br class="keepp"><a href="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/20210617110207.png" target="_blank" rel="noopener noreferrer"><img style="max-width:100%" src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/20210617110207.png" alt="Just My Socks 注册信息，若图片无法显示请点击查看" /></a><br class="keepp">用支付宝付款完成后，你的Just My Socks服务就购买完成了。</p><h2 id="user-content-just5"><span id="just_my_socks-5">五、Just My Socks信息查看</span></h2><p class="keepp">完成Just My Socks购买后，登陆<a rel="nofollow noopener" target="_blank" href="https://justmysocks3.net/members/aff.php?aff=17752">Just My Socks 官网</a>，选择Services->My Services，就可以看到你刚才买的服务了，点击这个服务查看详情：<br class="keepp"><a href="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/20210617110310.png" target="_blank" rel="noopener noreferrer"><img style="max-width:100%" src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/20210617110310.png" alt="Just My Socks 我的服务，若图片无法显示请点击查看" /></a></p><p class="keepp">这里就可以看到Shadowsocks/V2ray详情了，包括加密方式，端口，密码和IP（有5个节点，域名形式发放）等等：<br class="keepp"><a href="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/20210617110404.png" target="_blank" rel="noopener noreferrer"><img style="max-width:100%" src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/20210617110404.png" alt="Just My Socks shadowsocks详情，若图片无法显示请点击查看" /></a></p><h2 id="user-content-just6"><span id="just_my_socks-6">六、Just My Socks怎么用</span></h2><p>有了Shadowsocks/V2ray账号后，接下来怎么用？剩下的只需要下载安装Shadowsocks/V2ray客户端（<em><strong>注意：Just My Socks不支持SSR，不要使用SSR客户端，请使用下图中的<a rel="nofollow noopener" target="_blank" href="https://justmysocks3.net/members/aff.php?aff=17752">Just My Socks 官网</a>的下载链接下载客户端</strong></em>），然后将购买的服务器导入客户端即可使用啦。</p><p><b>第1～5条线路介绍</b></p><p>cXs1，cXs2和cXs5通过CN2 GT网络与其他中国联通和中国移动直接连接进行路由。</p><p>服务器cXs3通过中国电信提供的CN2 GIA网络进行路由（仅中国电信路由）。</p><p>服务器cXs4通过高级中国移动混合路由（在返回路径上具有CN2 GIA）（仅中国移动路由）。</p><p>注意2020-08-11作为实验，某些cXs4服务器在返回路径上对所有3个运营商（CU / CM / CT）使用具有GIA支持的荷兰POP</p><p><b>第6条线路：什么是Freedom服务器（s801）？</b></p><p>Freedom服务器可以提供更多的数据传输，具体取决于当前的乘数。该服务器提供了较便宜的路由，并且不提供任何形式的保证。用它来节省您的每月数据传输津贴。</p><p>例如，如果当前数据传输倍数= 10，那么您下载的所有内容中只有1/10会计入每月数据配额。</p><p>实际示例：假设您下载20GB的文件。如果您使用s1..s5范围内的服务器进行下载，则系统将计入所有20GB的数据传输（加上任何TCP开销）。 但是，如果您使用服务器s801进行此传输，并且当前乘数为10，则系统将仅占该传输的1/10（20 GB / 10 = 2 GB）</p><p>注意：数据传输乘数可以随时更改。官方不提供有关服务器s801的任何质量或正常运行时间保证。它是出于礼貌提供的，可以随时脱机使用。</p><p>备注：上面是官方解释，简单点就是最后一条线路没有前面5条线路好，所以使用它时流量消耗会进行打折，相当于可以节省流量，但速度要慢点，主要取决于自己的需求。</p><h3>在just_my_socks网站，参考下图下载对应操作系统的客户端</h3><img style="max-width:100%" src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/20210617110554.png" alt="SS客户端下载，若图片无法显示请点击查看" /><img style="max-width:100%" src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/20210617110636.png" alt="SS client download，若图片无法显示请点击查看" /><p class="keepp"><strong>反馈交流：</strong><a target="_blank" href="https://github.com/ChengKeJ/JustMySocks/issues"  rel="nofollow noopener">如果有任何问题，欢迎大家交流！</a></p><p class="keepp"><strong>免责声明：</strong>我们推荐的任何产品和服务已努力确保可靠持久，但我们不为此承担任何责任。本库一切资源仅用作交流学习，请勿用作商业或违法行为！如造成任何后果，本库概不负责！</p>]]></content>
      
      
      <categories>
          
          <category> vpn </category>
          
      </categories>
      
      
        <tags>
            
            <tag> vpn </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>查询一行数据怎么很慢？</title>
      <link href="2021/11/02/mysql-%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9F%A5%E8%AF%A2%E4%B8%80%E8%A1%8C%E6%95%B0%E6%8D%AE%E4%B9%9F%E5%BE%88%E6%85%A2/"/>
      <url>2021/11/02/mysql-%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9F%A5%E8%AF%A2%E4%B8%80%E8%A1%8C%E6%95%B0%E6%8D%AE%E4%B9%9F%E5%BE%88%E6%85%A2/</url>
      
        <content type="html"><![CDATA[<h5 id="为什么查询一行数据也很慢"><a href="#为什么查询一行数据也很慢" class="headerlink" title="为什么查询一行数据也很慢?"></a>为什么查询一行数据也很慢?</h5><p>1.MySQL数据库本身被堵住了，比如：系统或网络资源不够</p><p>2.SQL语句被堵住了，比如：表锁，行锁等，导致存储引擎不执行对应的SQL语句</p><p>3.确实是索引使用不当，没有走索引</p><p>4.表中数据的特点导致的，走了索引，但回表次数庞大</p><p>SQL语句被堵住的原因</p><ul><li>表锁</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from t where id&#x3D;1;</span><br></pre></td></tr></table></figure><p>长时间不返回,一般碰到这种情况的话，大概率是表 t 被锁住了。接下来分析原因的时候，一般都是首先执行一下 </p><p>show processlist 命令，看看当前语句处于什么状态。然后我们再针对每种状态，去分析它们产生的原因、如何复</p><p>现，以及如何处理。</p><span id="more"></span><p><img src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/image-20211022091452158.png" alt="image-20211022091452158"></p><p>(performance_schema=on，相比于设置为 off 会有 10% 左右的性能损失)通过查sys.schema_table_lock_waits </p><p>这张表，我们就可以直接找出造成阻塞的 process id，把这个连接用 kill 命令断开即可。</p><p><img src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/image-20211022093053390.png" alt="image-20211022093053390"></p><p> <strong>Waiting for table flush</strong></p><p>另外一种查询堵住的情况是: 表t 等待被flush,正常flush是很快的</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">flush tables t with read lock;</span><br><span class="line"></span><br><span class="line">flush tables with read lock;</span><br></pre></td></tr></table></figure><p>Waiting for table flush 状态的可能情况是：有一个 flush tables 命令被别的语句堵住了，然后它又堵住了我们的 </p><p>select 语句。</p><p><strong>等行锁</strong></p><p><img src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/image-20211022094227519.png" alt="image-20211022094227519"></p><p>session A 启动了事务，占有写锁，还不提交，是导致 session B 被堵住的原因</p><p>查出是谁占着这个写锁?</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; select * from t sys.innodb_lock_waits where locked_table&#x3D;&#39;&#96;test&#96;.&#96;t&#96;&#39;\G</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/image-20211022094422669.png" alt="image-20211022094422669"></p><p><strong>undo log</strong></p><p>mysql在事物开始操作数据之前，会先将原始数据备份到一个undo log的地方，这样做的目的有两个。第一是为了</p><p>保证事物的原子性，如果事物在执行的过程中出现了某些错误，或者是用户执行了rollback的操作，mysql可以利</p><p>用undo log中的备份将数据恢复到事物开始之前的状态。第二是为了实现多版本的并发控制，事物在提交之前，</p><p>undo log中保存了未提交之前的数据版本，undo log可以作为旧版数据的快照供其他并发访问的事物实现快照</p><p>读。</p><p><strong>快照读</strong>:SQL读取的数据是快照版本，也就是历史版本，普通的select查询的就是快照。innodb存储引擎的快照</p><p>读，读取的数据将由cache(原始数据)+undo(事物修改过的数据)两部分组成。</p><p><strong>当前读</strong>:SQL读取的数据是最新版本，可以通过锁的机制来保证读取的数据无法被其它的事物修改。update，</p><p>delete，insert，select … lock in share mode，select … for update都是当前读。</p><p>除了undo log，Mysql数据库还有一个<strong>redo log</strong>的概念，mysql在事物开始之后，事物中操作的任何数据，会将最</p><p>新的数据备份到一个地方（redo log）,就是在事物执行的过程中，开始将数据写入redo buffer中，最后写入redo </p><p>log中，具体的落盘策略可以自行配置。这样做的目的是:为了实现事物的持久性，防止在发生故障的时间点，尚有</p><p>脏页未写入磁盘，在mysql重启的时候，根据redo log重做，从而使事物未入磁盘的数据达到持久化这一特定。</p><p><img src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/image-20211022100827871.png" alt="image-20211022100827871"></p><p>session A 先用 start transaction with consistent snapshot 命令启动了一个事务，之后 session B 才开始执行 </p><p>update 语句。</p><p><img src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/image-20211022100857409.png" alt="image-20211022100857409"></p><p>session B 更新完 100 万次，生成了 100 万个回滚日志 (undo log)。带 lock in share mode 的 SQL 语句，是当前</p><p>读，因此会直接读到 1000001 这个结果，所以速度很快；而 select * from t where id=1 这个语句，是一致性</p><p>读，因此需要从 1000001 开始，依次执行 undo log，执行了 100 万次以后 找到seesionA 一致性视图那个版本 </p><p>才将 1 这个结果返回.</p>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>删除是不是只能跑路？</title>
      <link href="2021/11/01/mysql-redolog-binlog/"/>
      <url>2021/11/01/mysql-redolog-binlog/</url>
      
        <content type="html"><![CDATA[<h5 id="数据恢复过程"><a href="#数据恢复过程" class="headerlink" title="数据恢复过程"></a>数据恢复过程</h5><p>1.最近的一次全量备份 -&gt; 2. 从备份的时间点开始,将备份的binlog 依次取出来重放到误删表之前的那个时刻</p><p>这样你的临时库就跟误删之前的线上库一样了,按需要恢复到线上库去。</p><h5 id="日志模块"><a href="#日志模块" class="headerlink" title="日志模块"></a>日志模块</h5><p>与查询流程不一样的是，更新流程还涉及两个重要的日志模块</p><p>redo log 是 InnoDB 引擎特有的日志，而 Server 层也有自己的日志，称为 binlog（归档日志）</p><span id="more"></span><h6 id="redo-log"><a href="#redo-log" class="headerlink" title="redo log"></a>redo log</h6><p>WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘，也就是先写粉板，等不忙的时候再</p><p>写账本。</p><p>具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log（粉板）里面，并更新内存，</p><p>这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往</p><p>往是在系统比较空闲的时候做，这就像打烊以后掌柜做的事</p><p>有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为 crash-safe。</p><h6 id="binlog"><a href="#binlog" class="headerlink" title="binlog"></a>binlog</h6><p>redo log 是 InnoDB 引擎特有的日志，而 Server 层也有自己的日志，称为 binlog（归档日志）</p><h6 id="redo-log-vs-binlog"><a href="#redo-log-vs-binlog" class="headerlink" title="redo log vs binlog"></a>redo log vs binlog</h6><ul><li><p>redolog 是InnoDB特有,binlog 是mysql server 层独有</p></li><li><p>redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原</p><p>始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。</p></li><li><p>redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小</p><p>后会切换到下一个，并不会覆盖以前的日志</p></li></ul><h5 id="两阶段提交"><a href="#两阶段提交" class="headerlink" title="两阶段提交"></a>两阶段提交</h5><p>什么是”两阶段提交“?</p><p>先看数据update的mysql执行过程如图, 浅色 InnoDB 内部执行的，深色 执行器中执行的</p><img src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/2e5bff4910ec189fe1ee6e2ecc7b4bbe.png" alt="img" style="zoom:50%;" /><p>Innodb更新完内存然后写入redo log -&gt; prepare状态 -&gt; 告知执行器执行完成了，随时可以提交事务。执行器生成</p><p>这个操作的 binlog，并把 binlog 写入磁盘 -&gt;更新redo log状态为commit的</p><p>为什么必须有“两阶段提交”呢？</p><p>这是为了让两份日志之间的逻辑一致.</p><p>比如在更新的时候, 如果redo log 完好,意味中数据库重启 crash了 当时数据库数据可以恢复正常,但是归档的数据</p><p>会少一条更新的语句.如果后续误删数据利用备份库+binlog进行数据恢复的时候,会少一条更新语句.</p><p>反之亦然,binlog完好,但是redo log异常,恢复之后的数据认识更新前的值,后续binlog 恢复出来的值与原值不同.</p><p>redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致.</p>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何优化查询</title>
      <link href="2021/10/30/mysql-mysql-%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/"/>
      <url>2021/10/30/mysql-mysql-%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<p><strong>查询优化</strong></p><p><strong>why?</strong></p><h4 id="优化的思路"><a href="#优化的思路" class="headerlink" title="优化的思路"></a><strong>优化的思路</strong></h4><p><strong>客户端到服务器 其中包括 检验连接 查询缓存 解析 以及存储引擎涉及的调用 都会带来 cpu 内存 io等开销我们要</strong></p><p><strong>做的就是减少这些…</strong></p><h5 id="措施"><a href="#措施" class="headerlink" title="措施"></a><strong>措施</strong></h5><p>​    <strong>一个是检查是不是返回了 程序不需要的大量数据,大量数据会带来大量cpu以及io等损耗…</strong></p><p>​    <strong>一个是检查是不是扫了额外的行记录最简单的衡量查询开销的三个指标：1.响应时间2.扫描的行数3.返回的行</strong></p><p><strong>数, 关注数据的访问类型全表扫描 索引扫描 范围扫描 唯一索引扫描等…</strong></p><span id="more"></span><h5 id="using-where？"><a href="#using-where？" class="headerlink" title="using where？"></a><strong>using where？</strong></h5><h5 id="扫描大量数据-返回却很少数的行"><a href="#扫描大量数据-返回却很少数的行" class="headerlink" title=" 扫描大量数据, 返回却很少数的行?"></a><strong><img src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/cFNOQmbetv8RBaxL6EWXV0kf1_JS53PbHcNtpCbod-FXk3T8PPqnkWpoYjCyjP-yQeMb16IXJHEI683HYXjO9nFNeO3vA7YvVuB_1wT1oEWKXfRSy9YIPovUvkAWArlW1jSLrNbH=s0.png" alt="img"></strong> 扫描大量数据, 返回却很少数的行?</h5><h5 id=""><a href="#" class="headerlink" title=""></a><strong><img src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/CloQyJONtRGw9ovj3Qx3on2_pEMMq2rs7ShENqfQDO-G0SY6lAcQ6l7mBZCDr9_7HmkeFN5J1aqR0I3uAxIcze75RRYvNfLsXIL0ffBtpm26tMbgbzDIybE3xkYabP7IpnQo4feY=s0.png" alt="img"></strong></h5><h4 id="why-这样优化"><a href="#why-这样优化" class="headerlink" title="why 这样优化 ?"></a><strong>why 这样优化 ?</strong></h4><h5 id="查询执行基础"><a href="#查询执行基础" class="headerlink" title="查询执行基础"></a><strong>查询执行基础</strong></h5><p><strong><img src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/image-20211013132735291.png" alt="image-20211013132735291"></strong></p><h6 id="Mysql-客户端-服务器的通信协议"><a href="#Mysql-客户端-服务器的通信协议" class="headerlink" title="Mysql 客户端/服务器的通信协议"></a><strong>Mysql 客户端/服务器的通信协议</strong></h6><p><strong>”半双工“协议,单方面一方进行推送,服务器推送数据给客户端,客户端推送查询给服务器,两个动作不能同时发生.</strong></p><p><strong>虽然这种通信比较简单快速,但是有一个缺点就是一方必须接收完全部信息才能响应. 这就是为什么客户端进行查询</strong></p><p><strong>数据包传送的时候需要进行大小限制“max_allowed_package”  以及这也是为什么在查询返回时加”limit“ 限制.</strong></p><h6 id="查询缓存"><a href="#查询缓存" class="headerlink" title="查询缓存"></a><strong>查询缓存</strong></h6><p><strong>查询会和缓存中的查询进行匹配(一个区分大小写的Hash查找实现),如果完全匹配且权限没有问题则会直接返回数</strong></p><p><strong>据,反之如果有一个字节不匹配则不会命中缓存</strong></p><h6 id="查询优化以及处理-查询优化器"><a href="#查询优化以及处理-查询优化器" class="headerlink" title="查询优化以及处理(查询优化器)"></a><strong>查询优化以及处理</strong>(查询优化器)</h6><p><strong>这个阶段主要将 sql  (转换成 ) —&gt; 执行计划 -&gt; mysql 依据这个执行计划去和存储引擎进行交互.</strong></p><p><strong>转换执行计划过程包括 解析sql, 预处理,优化sql 执行计划</strong></p><p><strong>查询优化包括静态优化以及动态优化,静态优化主要则是将where 层面的条件以代数的形式去比较选择,通常只做一</strong></p><p><strong>次,但是动态优化则是每次都会评估. 常见的mysql能够处理的优化类型:</strong></p><p><strong><img src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/image-20211013155103802.png" alt="image-20211013155103802"></strong></p><h6 id="查询执行引擎"><a href="#查询执行引擎" class="headerlink" title="查询执行引擎"></a><strong>查询执行引擎</strong></h6><p><strong>Mysql 根据优化后的执行计划调用存储引擎的”handler API“,在解析运行时就为每张表生成handler</strong> </p><p><strong>实列.</strong></p><h6 id="查询结果返回"><a href="#查询结果返回" class="headerlink" title="查询结果返回"></a><strong>查询结果返回</strong></h6><p><strong>服务器会将返回的结果集的每行数据以客户端/服务器通信协议进行封包处理,通过TCP协议进行传输,传输过程可能</strong></p><p><strong>会将封包数据进行缓存,进行批量传输.</strong></p><p><strong>其次如果查询是可以缓存,那么mysql 也会在这个阶段缓存对应的结果集</strong></p>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何创建高性能索引</title>
      <link href="2021/10/29/mysql-mysql-%E5%A6%82%E4%BD%95%E5%88%9B%E5%BB%BA%E9%AB%98%E6%80%A7%E8%83%BD%E7%B4%A2%E5%BC%95/"/>
      <url>2021/10/29/mysql-mysql-%E5%A6%82%E4%BD%95%E5%88%9B%E5%BB%BA%E9%AB%98%E6%80%A7%E8%83%BD%E7%B4%A2%E5%BC%95/</url>
      
        <content type="html"><![CDATA[<h5 id="为什么需要索引"><a href="#为什么需要索引" class="headerlink" title="为什么需要索引?"></a><strong>为什么需要索引?</strong></h5><p><strong>避免去扫全表,存储引擎先走索引找到对应值,然后根据索引记录找到对应的数据行.</strong></p><p><strong>优点的话,因为索引使用B+树结构 使得查询数据不再是随机IO,且避免去扫描全表</strong></p><p><strong>索引的策略(使用)</strong></p><h5 id="单列"><a href="#单列" class="headerlink" title="单列"></a><strong>单列</strong></h5><p><strong>不要在where 后面针对索引列计算,因为无法自动解析计算,所以需要避免索引列的一些计算</strong></p><p><strong><img src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/image-20211013193141024.png" alt="image-20211013193141024"></strong></p><span id="more"></span><h5 id="前缀索引"><a href="#前缀索引" class="headerlink" title="前缀索引"></a><strong>前缀索引</strong></h5><p><strong>使列的前缀区分度趋近于这个列的完整列的区分度,这个时候可以考虑使用前缀索引,避免了索引过大,但同时区分度</strong></p><p><strong>差不多的情况.</strong></p><p><strong><img src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/image-20211013193656198.png" alt="image-20211013193656198" style="zoom:60%;" /></strong></p><p><strong><img src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/image-20211013193530306.png" alt="image-20211013193530306"></strong></p><h5 id="索引合并的优化"><a href="#索引合并的优化" class="headerlink" title="索引合并的优化?"></a><strong>索引合并的优化?</strong></h5><p><strong><img src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/image-20211013194453445.png" alt="image-20211013194453445"></strong></p><p><strong>当服务器对多个索引进行联合操作时候,通常会消耗大量的CPU,内存等,有的时候or的索引列区分度不高,查询优</strong></p><p><strong>化器评估可能还不如扫全表来的成本低,可能就会放弃走索引. 所以遇到extra using union 合并索引优化的时候</strong> </p><p><strong>需要看看自己的索引建立的是否合理?</strong></p><h5 id="如何选择合适的索引顺序"><a href="#如何选择合适的索引顺序" class="headerlink" title="如何选择合适的索引顺序?"></a><strong>如何选择合适的索引顺序?</strong></h5><p><strong>如果没有排序或者分组的情况下,将区分度最高的列放在最前面是合理的,但如果涉及排序或者分组的时候,还是应该像前缀索引那样针对查询的结果集的区分度来做判断</strong></p><p><strong><img src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/image-20211013200842505.png" alt="image-20211013200842505" style="zoom:50%;" /></strong></p><h5 id="聚簇索引"><a href="#聚簇索引" class="headerlink" title="聚簇索引"></a><strong>聚簇索引</strong></h5><p><strong>索引和数据行聚合在一起的,通常数据行不可能放在两个地方,所以聚簇索引的索引一般都是主键</strong></p><p><strong>聚簇索引默认是主键，如果表中没有定义主键，InnoDB 会选择一个唯一的非空索引代替</strong></p><p><strong><img src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/image-20211014153327555.png" alt="image-20211014153327555" style="zoom:50%;" /></strong></p><ul><li><p><strong>缺点:  当主键发生变化的时候,要插入一个已经满的数据行内时,会发生“页分裂”的问题, 导致数据行不连续,导致</strong></p><p><strong>全表扫描变慢,其次产生的”页分裂“ 也会占有额外的内存.</strong></p></li><li><p><strong>优点: 在B+树中查询会更快些,且使用覆盖索引扫描的查询可以直接用叶子结点上的主键</strong></p></li></ul><h5 id="覆盖索引"><a href="#覆盖索引" class="headerlink" title="覆盖索引"></a><strong>覆盖索引</strong></h5><p><strong>索引包含了要查询的列,那么就没有必要回表查询(数据行).</strong></p><p><strong>优点: 如果走覆盖索引,返回的行数明显会少很多, 对服务器的缓存 IO 负载也会好很多</strong></p><h5 id="什么是“延迟关联“？"><a href="#什么是“延迟关联“？" class="headerlink" title="什么是“延迟关联“？"></a><strong>什么是“延迟关联“？</strong></h5><h5 id="超多分页的问题"><a href="#超多分页的问题" class="headerlink" title="超多分页的问题"></a><strong>超多分页的问题</strong></h5><p><strong>随着偏移量 <code>offset</code> 的增加，MySQL 需要花费大量的时间来扫描需要丢弃的数据。本质上就是 <code>offset</code> 过大导致</strong></p><p><strong>的大量回表 I/O 查询。</strong></p><p><strong>通过使用覆盖索引查询返回需要的主键，再根据主键关联原表获得需要的数据。</strong> </p><p><strong><img src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/image-20211014162823668.png" alt="image-20211014162823668"></strong></p><h5 id="使用索引来排序"><a href="#使用索引来排序" class="headerlink" title="使用索引来排序"></a><strong>使用索引来排序</strong></h5><p><strong><img src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/image-20211014165259909.png" alt="image-20211014165259909"></strong></p><p><strong><img src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/image-20211014165042661.png" alt="image-20211014165042661"></strong></p><p><strong>当第一列是范围查询的时候也不能使用索引作排序查询</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">....</span><br><span class="line">where retal_date&gt;&quot;2005-05-25&quot; order by inventory_id,customer_id</span><br><span class="line">....</span><br></pre></td></tr></table></figure><p><strong>注意避免 冗余 &amp; 重复&amp;  未使用索引</strong></p><h5 id="索引和锁"><a href="#索引和锁" class="headerlink" title="索引和锁"></a><strong>索引和锁</strong></h5><p><strong>在返回给服务器之前的,能够通过索引过滤无效行的形式去避免无效行的锁,返回到服务器数据可以通过where 过滤</strong></p><p><strong>之后释放锁.</strong></p><p><strong><img src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/image-20211016095647397.png" alt="image-20211016095647397"></strong></p><p><strong><code>use index</code> 索引返回过滤 1-5 行的数据 , <code>use where</code> 索引返回行给服务器,应用 <code>where</code> 过滤</strong></p><p><strong><img src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/image-20211016100036309.png" alt="image-20211016100036309" style="zoom:50%;" /></strong></p><p><strong>虽然查询只返回了2<del>4行的数据,但实际获取的是1</del>4行之间的排他锁,InnoDB 会锁住第一行,因为<code>查询优化器</code> 选择</strong></p><p><strong>的执行计划是<code>索引范围扫描</code></strong></p><h5 id="索引案例学习"><a href="#索引案例学习" class="headerlink" title="索引案例学习"></a>索引案例学习</h5><p><code>IN</code> or <code>&gt;</code> ?  </p><img src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/image-20211016103048834.png" alt="image-20211016103048834" style="zoom:50%;" /><p>explain 结果来看无法区分 这二者的区别,但是 可以从值的范围和多个等于条件来得出不同,第二个就是等值查询</p><p>那二者在查询效率上有什么区别吗?</p><p>简单的来说第二种等值查询后续列可以继续使用索引,但是第一种范围查询后续列不可以使用索引,因为查询只能使</p><p>用索引的最左匹配.所以应该尽可能将范围查询放在索引列的后面.以便优化器可以使用尽可能多的索引列.</p><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><ul><li><p>服务器从存储中读取的块尽可能多的包含所需要的行</p></li><li><p>顺序IO 比随机IO快,特别是对机械硬盘,如果服务器能够顺序获取数据,那服务器则无需额外的排序</p></li><li><p>覆盖索引是很快的,如果索引列能返回所有的查询数据,则存储引擎无需回表查询数据行</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统里的内存管理</title>
      <link href="2021/09/28/os-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"/>
      <url>2021/09/28/os-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p><img src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/%E5%9B%BE%E6%80%AA%E5%85%BD_f2433484b95076e61f00e5b8b98a68f0_68721.jpg" alt="图怪兽_f2433484b95076e61f00e5b8b98a68f0_68721"></p><h5 id="存储器结构"><a href="#存储器结构" class="headerlink" title="存储器结构"></a>存储器结构</h5><p>cpu -&gt; 寄存器 -&gt; 高速缓存 -&gt; 主存 -&gt; 磁盘</p><h5 id="一种存储器抽象：地址空间"><a href="#一种存储器抽象：地址空间" class="headerlink" title="一种存储器抽象：地址空间"></a>一种存储器抽象：地址空间</h5><p>定义: 存储位置列表,存放可执行程序,程序的数据以及堆栈</p><p>地址空间是进程可以用来寻址内存的地址集。每个进程都有它自己的地址空间，独立于其他进程的地址空间，但是</p><p>某些进程会希望可以共享地址空间 </p><span id="more"></span><h5 id="映射内存-基址寄存器和变址寄存器"><a href="#映射内存-基址寄存器和变址寄存器" class="headerlink" title="映射内存? 基址寄存器和变址寄存器"></a>映射内存? 基址寄存器和变址寄存器</h5><p>每个 CPU 配置两个特殊硬件寄存器，通常叫做<code>基址寄存器(basic register)</code>和<code>变址寄存器(limit register)</code>。当</p><p>使用基址寄存器和变址寄存器时，程序会装载到内存中的连续位置并且在装载期间无需重定位。当一个进程运行</p><p>时，程序的起始物理地址装载到基址寄存器中，程序的长度则装载到变址寄存器中.</p><ul><li>基址寄存器：存储数据内存的起始位置</li><li>变址寄存器：存储应用程序的长度</li></ul><img src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/image-20210928135552448.png" alt="image-20210927200421691" style="zoom:50%;" /><h5 id="程序运行所需内存超过物理内存"><a href="#程序运行所需内存超过物理内存" class="headerlink" title="程序运行所需内存超过物理内存?"></a>程序运行所需内存超过物理内存?</h5><p>最简单的一种方式就是<code>交换(swapping)</code>技术，即把一个进程完整的调入内存，然后再内存中运行一段时间，再把</p><p>它放回磁盘。空闲进程会存储在磁盘中，所以这些进程在没有运行时不会占用太多内存。另外一种策略叫做<code>虚拟</code></p><p><code>内存(virtual memory)</code>，虚拟内存技术能够允许应用程序部分的运行在内存中.</p><ul><li><p><strong>交换</strong></p><p>交换在内存创建了多个 <code>空闲区(hole)</code>，内存会把所有的空闲区尽可能向下移动合并成为一个大的空闲区。这</p><p>项技术称为<code>内存紧缩(memory compaction)</code>,但这项技术会消耗很多CPU的时间,通常不使用</p></li><li><p><strong>虚拟内存</strong></p><p>虚拟内存的基本思想是, <strong>每个程序都有自己的地址空间，这个地址空间被划分为多个称为<code>页面(page)</code>的块</strong>。</p><p>每一页都是连续的地址范围。这些页被映射到物理内存，但并不是所有的页都必须在内存中才能运行程序。当</p><p>程序引用到一部分在物理内存中的地址空间时，硬件会立刻执行必要的映射。当程序引用到一部分不在物理内</p><p>存中的地址空间时，由操作系统负责将缺失的部分装入物理内存并重新执行失败的指令.</p></li></ul><h5 id="虚拟内存中的分页"><a href="#虚拟内存中的分页" class="headerlink" title="虚拟内存中的分页"></a>虚拟内存中的分页</h5><p>在使用虚拟内存时，虚拟地址不会直接发送到内存总线上。相反，会使用 <code>MMU(Memory Management Unit)</code> 内存</p><p>管理单元把虚拟地址映射为物理内存地址</p><p>  <img src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/image-20210928152422814.png" alt="image-20210928152422814"></p><p><img src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/image-20210928152951607.png" alt="image-20210928152951607"></p><h5 id="大体流程"><a href="#大体流程" class="headerlink" title="大体流程"></a>大体流程</h5><p>CPU -&gt; 虚拟内存地址空间(被分成<code>页面</code>块) -&gt; MMU (内存单元管理) -&gt; 物理内存-&gt; 总线 -&gt; 操作设备</p><h5 id="虚拟地址到物理地址的映射"><a href="#虚拟地址到物理地址的映射" class="headerlink" title="虚拟地址到物理地址的映射?"></a>虚拟地址到物理地址的映射?</h5><ul><li><p>转换检测缓冲区 TLB (硬件层面)</p><p>从硬件方面来解决这个问题，为计算机设置一个小型的硬件设备，能够将虚拟地址直接映射到物理地址，而不</p><p>必再访问页表。这种设备被称为<code>转换检测缓冲区(Translation Lookaside Buffer, TLB)</code></p></li></ul><p><img src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/image-20210928154218704.png" alt="image-20210928154218704"></p><h5 id="页面置换算法"><a href="#页面置换算法" class="headerlink" title="页面置换算法"></a>页面置换算法</h5><table><thead><tr><th align="left">算法</th><th align="left">注释</th></tr></thead><tbody><tr><td align="left">最优算法</td><td align="left">不可实现，但可以用作基准</td></tr><tr><td align="left">NRU(最近未使用) 算法</td><td align="left">和 LRU 算法很相似</td></tr><tr><td align="left">FIFO(先进先出) 算法</td><td align="left">有可能会抛弃重要的页面</td></tr><tr><td align="left">第二次机会算法</td><td align="left">比 FIFO 有较大的改善</td></tr><tr><td align="left">时钟算法</td><td align="left">实际使用</td></tr><tr><td align="left">LRU(最近最少)算法</td><td align="left">比较优秀，但是很难实现</td></tr><tr><td align="left">NFU(最不经常食用)算法</td><td align="left">和 LRU 很类似</td></tr><tr><td align="left">老化算法</td><td align="left">近似 LRU 的高效算法</td></tr><tr><td align="left">工作集算法</td><td align="left">实施起来开销很大</td></tr><tr><td align="left">工作集时钟算法</td><td align="left">比较有效的算法</td></tr></tbody></table><h4 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h4><img src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/image-20210927200421691.png" alt="image-20210927200421691" style="zoom:50%;" />]]></content>
      
      
      <categories>
          
          <category> OS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> OS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统里的进程和线程</title>
      <link href="2021/09/28/os-%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/"/>
      <url>2021/09/28/os-%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<p><img src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/%E5%9B%BE%E6%80%AA%E5%85%BD_81f15acdf27c9e27dd3e2e54d3360863_79599.png" alt="图怪兽_81f15acdf27c9e27dd3e2e54d3360863_79599"></p><h5 id="什么是进程"><a href="#什么是进程" class="headerlink" title="什么是进程?"></a>什么是进程?</h5><p>一个进程就是一个正在执行的程序的实例，进程也包括程序计数器、寄存器和变量的当前值。从概念上来说，每个</p><p>进程都有各自的虚拟 CPU，但是实际情况是 CPU 会在各个进程之间进行来回切换。</p><h5 id="进程模型"><a href="#进程模型" class="headerlink" title="进程模型?"></a>进程模型?</h5><p>一个进程就是一个正在执行的程序的实例，进程也包括<code>程序计数器</code>、<code>寄存器</code>和<code>变量的当前值</code>。从概念上来说，每个</p><p>进程都有各自的<code>虚拟 CPU</code>，但是实际情况是 CPU 会在各个进程之间进行来回切换。</p><span id="more"></span><p><strong>举例</strong></p><p>4 道程序被抽象为 4 个拥有各自控制流程（即每个自己的程序计数器）的进程，并且每个程序都独立的运行。当</p><p>然，实际上只有一个物理程序计数器，每个程序要运行时，其逻辑程序计数器会装载到物理程序计数器中。当程序</p><p>运行结束后，其物理程序计数器就会是真正的程序计数器，然后再把它放回进程的逻辑计数器中。</p><p><strong>概述</strong></p><p>进程是某一类特定活动的总和，它有程序、输入输出以及状态。单个处理器可以被若干进程共享，它使用某</p><p>种调度算法决定何时停止一个进程的工作，并转而为另外一个进程提供服务</p><h5 id="进程状态"><a href="#进程状态" class="headerlink" title="进程状态"></a>进程状态</h5><p>每个进程是一个独立的实体，有其自己的程序计数器和内部状态，但是，进程之间存在关联关系</p><ol><li><code>运行态</code>，运行态指的就是进程实际占用 CPU 时间片运行时 (获得CPU 时间片)</li><li><code>就绪态</code>，就绪态指的是可运行，但因为其他进程正在运行而处于就绪状态 (还没有获得CPU 时间片)</li><li><code>阻塞态</code>，除非某种外部事件发生，否则进程不能运行</li></ol><p><strong>程序调度</strong> 指的是，决定哪个进程优先被运行和运行多久</p><p><strong>操作系统最底层的就是调度程序</strong>，在它上面有许多进程。所有关于中断处理、启动进程和停止进程的具体细节都隐</p><p>藏在调度程序中。事实上，调度程序只是一段非常小的程序</p><h5 id="进程的实现"><a href="#进程的实现" class="headerlink" title="进程的实现"></a>进程的实现</h5><p>操作系统为了执行进程间的切换，会维护着一张表格，这张表就是 <code>进程表(process table)</code>。每个进程占用一个</p><p>进程表项。该表项包含了进程状态的重要信息，包括程序计数器、堆栈指针、内存分配状况、所打开文件的状态、</p><p>账号和调度信息，以及其他在进程由运行态转换到就绪态或阻塞态时所必须保存的信息，从而保证该进程随后能再</p><p>次启动，就像从未被中断过一样。</p><img src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/image-20210927135216802.png" alt="image-20210927135216802" style="zoom:50%;" /><h5 id="为什么要用线程"><a href="#为什么要用线程" class="headerlink" title="为什么要用线程?"></a>为什么要用线程?</h5><ul><li>多线程之间会共享同一块地址空间和所有可用数据的能力，这是进程所不具备的</li><li>线程要比进程<code>更轻量级</code>，由于线程更轻，所以它比进程更容易创建，也更容易撤销。在许多系统中，创建一个线程要比创建一个进程快 10 - 100 倍。</li><li>第三个原因可能是性能方面的探讨，如果多个线程都是 CPU 密集型的，那么并不能获得性能上的增强，但是如果存在着大量的计算和大量的 I/O 处理，拥有多个线程能在这些活动中彼此重叠进行，从而会加快应用程序的执行速度</li></ul><h5 id="线程模型"><a href="#线程模型" class="headerlink" title="线程模型?"></a>线程模型?</h5><p>进程中拥有一个执行的线程，通常简写为 <code>线程(thread)</code>。线程会有程序计数器，用来记录接着要执行哪一条指</p><p>令；线程还拥有寄存器，用来保存线程当前正在使用的变量；线程还会有堆栈，用来记录程序的执行路径。尽管线</p><p>程必须在某个进程中执行，但是进程和线程完完全全是两个不同的概念，并且他们可以分开处理。进程用于把资源</p><p>集中在一起，而<strong>线程则是 CPU 上调度执行的实体</strong>。</p><p>在多个线程中，各个线程共享同一地址空间和其他资源。在多个进程中，进程共享物理内存、磁盘、打印机和其他</p><p>资源。</p><img src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/image-20210927141721690.png" alt="image-20210927141721690" style="zoom:50%;" /><h5 id="线程状态"><a href="#线程状态" class="headerlink" title="线程状态"></a>线程状态</h5><p>和进程一样，线程可以处于下面这几种状态：<strong>运行中、阻塞、就绪和终止</strong></p><h5 id="线程的实现"><a href="#线程的实现" class="headerlink" title="线程的实现"></a>线程的实现</h5><ul><li>在用户空间中实现线程</li><li>在内核空间中实现线程</li><li>在用户和内核空间中混合实现线程</li></ul><p>用户态VS内核态线程</p><ol><li><p>当一个线程阻塞时，内核可以进行选择，是运行在同一个进程中的另一个线程（如果有就绪线程的话）还是运</p><p>行一个另一个进程中的线程。但是在用户实现中，运行时系统始终运行自己的线程，直到内核剥夺它的 CPU </p><p>时间片（或者没有可运行的线程存在了）为止。</p></li><li><p>在内核中创建或者销毁线程的开销比较大</p></li><li><p>用户级线程和内核级线程之间的主要差别在于<code>性能</code>。用户级线程的切换需要少量的机器指令（想象一下Java程</p><p>序的线程切换），而内核线程需要完整的上下文切换，修改内存映像，使高速缓存失效，这会导致了若干数量</p><p>级的延迟。另一方面，在使用内核级线程时，一旦线程阻塞在 I/O 上就不需要在用户级线程中那样将整个进程</p><p>挂起</p></li></ol><h5 id="进程通信"><a href="#进程通信" class="headerlink" title="进程通信"></a>进程通信</h5><ul><li><code>竞态条件</code>  <code>临界区</code> <code>忙等互斥</code> <code> 睡眠与唤醒</code> <code>信号量</code> <code>互斥量</code>  <code>管程</code> <code> 消息传递</code> <code>屏障</code> <code>避免锁</code></li></ul><h5 id="调度"><a href="#调度" class="headerlink" title="调度"></a>调度</h5><p>如果只有一个 CPU 可用，那么必须选择接下来哪个进程/线程可以运行。操作系统中有一个叫做 <code>调度程序</code></p><p><code>(scheduler)</code> 的角色存在，它就是做这件事儿的，该程序使用的算法叫做 <code>调度算法(scheduling algorithm)</code></p><ul><li><p><strong>批处理系统中的调度:</strong> <code>先来先服务</code>, <code>最短作业优先</code>, <code>最短剩余优先</code></p></li><li><p><strong>实时系统中的调度:</strong> </p><p>实时系统可以分为两类，<code>硬实时(hard real time)</code> 和 <code>软实时(soft real time)</code> 系统，前者意味着必须要满</p><p>足绝对的截止时间；后者的含义是虽然不希望偶尔错失截止时间，但是可以容忍。</p></li><li><p><strong>交互式系统中的调度:</strong> </p><p><code>轮询调度</code> 一种最古老、最简单、最公平并且最广泛使用的算法就是 <code>轮询算法(round-robin)</code>。每个进程都会被</p><p>分配一个时间段，称为<code>时间片(quantum)</code>，在这个时间片内允许进程运行</p><p><code>优先级调度</code>轮询调度假设了所有的进程是同等重要的。但事实情况可能不是这样。例如，在一所大学中的等</p><p>级制度，首先是院长，然后是教授、秘书、后勤人员，最后是学生。这种将外部情况考虑在内就实现了<code>优先</code></p><p><code>级调度(priority scheduling)</code></p></li></ul><h5 id="概览图"><a href="#概览图" class="headerlink" title="概览图"></a>概览图</h5><img src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/image-20210927092731492.png" alt="image-20210927092731492" style="zoom:80%;" /><h4 id="文章参考："><a href="#文章参考：" class="headerlink" title="文章参考："></a>文章参考：</h4><p>《现代操作系统》第四版</p><p>《Modern Operation System》fourth</p><p> <a target="_blank" rel="noopener" href="https://baike.baidu.com/item/SATA%E7%A1%AC%E7%9B%98/3947233?fr=aladdin">https://baike.baidu.com/item/SATA硬盘/3947233?fr=aladdin</a></p><p> <a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E8%99%9A%E6%8B%9F%E5%9C%B0%E5%9D%80/1329947?fr=aladdin">https://baike.baidu.com/item/虚拟地址/1329947?fr=aladdin</a></p><p> <a target="_blank" rel="noopener" href="https://www.cnblogs.com/cxuanBlog/p/12448298.html">https://www.cnblogs.com/cxuanBlog/p/12448298.html</a></p>]]></content>
      
      
      <categories>
          
          <category> OS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> OS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Optional 的使用会导致性能下降吗？</title>
      <link href="2021/07/26/service-%E4%BD%A0%E9%9C%80%E8%A6%81%E6%8B%85%E5%BF%83Optional%E7%9B%B8%E5%85%B3%E7%9A%84%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E5%90%97/"/>
      <url>2021/07/26/service-%E4%BD%A0%E9%9C%80%E8%A6%81%E6%8B%85%E5%BF%83Optional%E7%9B%B8%E5%85%B3%E7%9A%84%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E5%90%97/</url>
      
        <content type="html"><![CDATA[<p><img src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/%E5%9B%BE%E6%80%AA%E5%85%BD_bb2845fd7f5a4c03fb9adb66715a5e02_14370.png" alt="图怪兽_bb2845fd7f5a4c03fb9adb66715a5e02_14370"></p><p>几天前，我在论坛上发了一篇关于<code>Optional</code> 的文章。其中一条评论是一个非常好的问题:</p><blockquote><p>Optional 的使用会导致性能下降吗？</p></blockquote><p>答案是: 是的，它会的。但是你应该担心吗？</p><span id="more"></span><h2 id="使用Optional的好处"><a href="#使用Optional的好处" class="headerlink" title="使用Optional的好处"></a>使用Optional的好处</h2><p>Optional 类使我们这些开发人员的生活更轻松</p><ul><li>增加代码的可读性</li><li>减少代码中的条件数</li><li>更不容易出错</li></ul><p>让我们来看看 Optional 类的一些主要方法是如何实现的。</p><!--more--><h2 id="Optional-如何实现的？"><a href="#Optional-如何实现的？" class="headerlink" title="Optional 如何实现的？"></a>Optional 如何实现的？</h2><p>这里有一些 <code>Optional</code> 类的主要方法:</p><p>基本上，它将值包装到一个新的 <code>Optional</code>对象中，并检查包装的值是否为<code>null</code>。</p><p>即使没有使用 Optional，也必须检查值是否为 null。它可能比您做的检查多一些，但我认为您不必担心这一点。</p><p>但是您必须知道，将值包装到新对象中将增加 GC 要收集的对象数量。这意味着堆使用量将增加得更快，CPU 使用量将更高(更多 GC 事件)。</p><p>好吧，但是有多高呢？同样，这取决于您正在创建的可选对象的数量、堆的大小以及您的应用程序在不使用可选对象的情况下使用的 CPU 数量。</p><p>例如，假设您对应用程序进行了基准测试，并得出结论，使用 Optional 将提高 CPU 使用率1个百分点。如果您的应用程序平均使用50% 的 CPU，那么使用51% 的可选 CPU 并不是一个很大的开销，对吧？</p><p>但是，如果您的应用程序平均消耗5% 的 CPU，使用6% 意味着20% 的开销，这是相当重要的。</p><h2 id="过早优化是万恶之源"><a href="#过早优化是万恶之源" class="headerlink" title="过早优化是万恶之源"></a>过早优化是万恶之源</h2><p>Joshua Bloch 在<a target="_blank" rel="noopener" href="https://www.amazon.com/gp/product/0134685997/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=0134685997&linkCode=as2&tag=hbelmiro0f-20&linkId=213790c63c0d57baac2e45b3183a35b2">Effective Java</a> 一书中有整整一章(第67项: Optimize judiciously)谈到了优化。</p><p>他在这一章的开头写道:</p><blockquote><p>关于最优化，有三个关注点是每个人都应该知道的:</p><blockquote><p>与其他任何单一原因(包括盲目的愚蠢)相比，更多的计算原罪是以效率的名义犯下的(不一定能实现)。</p></blockquote><p>William A. Wulf</p><blockquote><p>我们应该忘记小的副作用，比如说97% 的时间: 过早的优化是一切罪恶的根源。</p></blockquote><p>Donald E. Knuth</p><blockquote><p>在优化问题上，我们遵循两个规则:</p><ul><li>规则1. 不要这样做</li><li>规则 2（仅适用于专家）。 暂时不要这样做——也就是说，除非你有一个非常清晰且未经优化的解决方案。</li></ul></blockquote><p>M. A. Jackson</p></blockquote><p>因此，除非您需要一个快速的应用程序并且资源有限，否则不要过早担心性能问题。专注于编写好的代码，这样当你需要它的时候，它就很容易优化。此外，使用分析器查找对性能影响更大的位置。</p><h2 id="谁会使用你的-API？"><a href="#谁会使用你的-API？" class="headerlink" title="谁会使用你的 API？"></a>谁会使用你的 API？</h2><p>这也是一个你需要问自己的好问题。如果您正在编写一个内部 API，您可以更自由地决定是否使用它。</p><p>但是如果你正在编写一个公共 API，比如一个框架或者库，而你不知道什么样的应用程序在调用它，你可能需要更加灵活，给客户端选择是否使用可选的选项。</p><p>您可以提供两个方法，一个返回  <code>Optional</code> ，另一个返回 <code>null</code>。但是，当创建一个可以返回 <code>null</code> 的方法时，尽量让它显式。使用注释  <code>javax.annotation.Nullable</code>。方法的可空性。 (<a target="_blank" rel="noopener" href="https://jcp.org/en/jsr/detail?id=305">JSR 305</a>)</p><h2 id="最终，这取决于你"><a href="#最终，这取决于你" class="headerlink" title="最终，这取决于你"></a>最终，这取决于你</h2><p>你可以决定是否使用 Optional。没有一个简单的答案适用于所有情况。软件工程中的大多数事情都是这样的。这一切都是权衡取舍。</p><p>所以，要意识到它是如何工作的，并评估替代方案。任何事情都有代价，你是那个可以决定是否承担的人。</p><p>您认为为了提高性能而付出不可读且更容易出错的代码的代价是值得的吗？你知道这种进步有多重要吗？</p><p>在大多数情况下，使用 <code>Optional</code>  并保持开心！<code>Optional</code>  是不错的!</p>]]></content>
      
      
      <categories>
          
          <category> 微服务 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 微服务治理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何做好监控微服务调⽤?</title>
      <link href="2021/06/16/service-06-16-%E5%A6%82%E4%BD%95%E5%81%9A%E5%A5%BD%E7%9B%91%E6%8E%A7%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%B0%83%E2%BD%A4/"/>
      <url>2021/06/16/service-06-16-%E5%A6%82%E4%BD%95%E5%81%9A%E5%A5%BD%E7%9B%91%E6%8E%A7%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%B0%83%E2%BD%A4/</url>
      
        <content type="html"><![CDATA[<img src="https://cdn.jsdelivr.net/gh/ChengKeJ/pic@master/img/%E5%9B%BE%E6%80%AA%E5%85%BD_17f35bc65eed401b374b1b5fcf552d44_83179.png" style="zoom:90%;" /><h6 id="监控对象"><a href="#监控对象" class="headerlink" title="监控对象"></a>监控对象</h6><ul><li><p>⽤户端监控。通常是指业务直接对⽤户提供的功能的监控</p></li><li><p>接口监控。通常是指业务提供的功能所依赖的接口的监控</p></li></ul><span id="more"></span><ul><li><p>资源监控。通常是指某个接⼝依赖的资源的监控。比如该接口使用的redis 缓存，对redis 的监控就是资源的</p><p>监控</p></li><li><p>基础监控。通常是指对服务器本身的健康状况的监控。主要包括CPU利⽤率、内存使⽤量、I/O读写量、⽹卡</p><p>带宽等</p></li></ul><h6 id="监控指标"><a href="#监控指标" class="headerlink" title="监控指标"></a>监控指标</h6><ul><li><p>请求量。请求量监控分为两个维度，⼀个是实时请求量QPS，⼀个是统计请求量PV。QPS（Queries Per</p><p>Second） 即每秒查询次数来衡量，它反映了服务调⽤的实时变化情况。统计请求量⼀般⽤PV（Page View）</p><p>即⼀段时间内⽤户的访 问量来衡量，⽐如⼀天的PV代表了服务⼀天的请求量，通常⽤来统计报表。</p></li><li><p>响应时间。⼤多数情况下，可以⽤⼀段时间内所有调⽤的平均耗时来反映请求的响应时间。可以把响应时间划</p><p>分为多个区间，⽐如0～10ms、10ms～50ms、50ms～ 100ms、100ms～500ms、500ms以上这五个区</p><p>间。除此之外，还可以从P90、P95、P99、P999⻆度来监控请求的响应时间，⽐如P99 = 500ms，意思是</p><p>99%的请求响 应时间在500ms以内，它代表了请求的服务质量，即SLA。</p></li><li><p>错误率。错误率的监控通常⽤⼀段时间内调⽤失败的次数占调⽤总次数的⽐率来衡量，⽐如对于接⼝的错误率</p><p>⼀般⽤接⼝ 返回错误码为503的⽐率来表示。</p></li></ul><h6 id="监控维度"><a href="#监控维度" class="headerlink" title="监控维度"></a>监控维度</h6><ul><li><p>全局维度。从整体⻆度监控对象的的请求量、平均耗时以及错误率，全局维度的监控⼀般是为了让你对监控对象的调⽤情 况有个整体了解。</p></li><li><p> 分机房维度。</p></li><li><p> 时间维度。同⼀个监控对象，在每天的同⼀时刻各种指标通常也不会⼀样</p></li><li><p>核⼼维度。业务上⼀般会依据重要性程度对监控对象进⾏分级，最简单的是分成核⼼业务和⾮核⼼业务。</p><p>核⼼业务和⾮核⼼业务在部署上必须隔离，分开监控，这样才能对核⼼业务做重点保障。</p></li></ul><h6 id="监控系统"><a href="#监控系统" class="headerlink" title="监控系统"></a>监控系统</h6><blockquote><p>主要包括四个环节：数据采集、数据传输、数据处理和数据展示</p></blockquote><ul><li><p>数据采集</p><p>通常有两种数据收集⽅式：</p><ul><li><p><strong>服务主动上报</strong>，这种处理⽅式通过在业务代码或者服务框架⾥加⼊数据收集代码逻辑，在每⼀次服务</p><p>调⽤完成后，主动上报服务的调⽤信息。</p></li><li><p><strong>代理收集</strong>，这种处理⽅式通过服务调⽤后把调⽤的详细信息记录到本地⽇志⽂件中，然后再通过代理去解</p><p>析本地⽇志⽂ 件，然后再上报服务的调⽤信息。</p></li></ul></li><li><p>数据传输</p><ul><li><p><strong>UDP传输</strong>，这种处理⽅式是数据处理单元提供服务器的请求地址，数据采集后通过UDP协议与服务器建⽴</p><p>连接，然后把数 据发送过去。</p></li><li><p><strong>Kafka传输</strong>，这种处理⽅式是数据采集后发送到指定的Topic，然后数据处理单元再订阅对应的Topic，就</p><p>可以从Kafka消息队列中读取到对应的数据。</p><img src="https://cdn.smalltechnologyjun.com//image-20210615200330740.png" alt="image-20210615200330740" style="zoom: 80%;" /></li></ul></li><li><p>数据处理</p><p>数据聚合两个维度：接口维度和机器维度</p><p>聚合后的数据持久化： 索引数据库(es) 或者 时序数据库influxDB</p></li><li><p>数据展示</p><p>数据展示有多种⽅式，⽐如曲线图、饼状图、格⼦图展示</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 微服务 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 微服务治理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络基本概念</title>
      <link href="2020/11/12/internet-2020-11-12-%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/"/>
      <url>2020/11/12/internet-2020-11-12-%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</url>
      
        <content type="html"><![CDATA[<p>本篇文章简单梳理网络通信的基础概念</p><p>在学习Java网络编程之前，我们先来了解什么是计算机网络。</p><p>计算机网络是指两台或更多的计算机组成的网络，在同一个网络中，任意两台计算机都可以直接通信，因为所有计算机都需要遵循同一种网络协议。</p><p>那什么是互联网呢？互联网是网络的网络（internet），即把很多计算机网络连接起来，形成一个全球统一的互联网。</p><p>对某个特定的计算机网络来说，它可能使用网络协议ABC，而另一个计算机网络可能使用网络协议XYZ。如果计算机网络各自的通讯协议不统一，就没法把不同的网络连接起来形成互联网。因此，为了把计算机网络接入互联网，就必须使用<strong>TCP/IP协议</strong>。</p><p>TCP/IP协议泛指互联网协议，其中最重要的两个协议是TCP协议和IP协议。只有使用TCP/IP协议的计算机才能够联入互联网，使用其他网络协议（例如NetBIOS、AppleTalk协议等）是无法联入互联网的。</p><span id="more"></span><h3 id="IP地址"><a href="#IP地址" class="headerlink" title="IP地址"></a>IP地址</h3><p>在互联网中，一个IP地址用于唯一标识一个网络接口（Network Interface）。一台联入互联网的计算机肯定有一个IP地址，但也可能有多个IP地址。</p><p>IP地址分为IPv4和IPv6两种。IPv4采用32位地址，类似101.202.99.12，而IPv6采用128位地址，类似2001:0DA8:100A:0000:0000:1020:F2F3:1428。IPv4地址总共有232个（大约42亿），而IPv6地址则总共有2128个（大约340万亿亿亿亿），IPv4的地址目前已耗尽，而IPv6的地址是根本用不完的。</p><p>IP地址又分为公网IP地址和内网IP地址。公网IP地址可以直接被访问，内网IP地址只能在内网访问。内网IP地址类似于：</p><ul><li>192.168.x.x</li><li>10.x.x.x</li></ul><p>有一个特殊的IP地址，称之为本机地址，它总是<strong>127.0.0.1</strong>。</p><p>IPv4地址实际上是一个32位整数。例如：</p><p>106717964 = 0x65ca630c<br>          = 65  ca  63 0c<br>          = 101.202.99.12<br>如果一台计算机只有一个网卡，并且接入了网络，那么，它有一个本机地址<strong>127.0.0.1</strong>，还有一个IP地址，例如<strong>101.202.99.12</strong>，可以通过这个IP地址接入网络。</p><p>如果一台计算机有两块网卡，那么除了本机地址，它可以有两个IP地址，可以分别接入两个网络。通常连接两个网络的设备是路由器或者交换机，它至少有两个IP地址，分别接入不同的网络，让网络之间连接起来。</p><p>如果两台计算机位于同一个网络，那么他们之间可以直接通信，因为他们的IP地址前段是相同的，也就是网络号是相同的。网络号是IP地址通过子网掩码过滤后得到的。例如：</p><p>某台计算机的IP是<strong>101.202.99.2</strong>，子网掩码是<strong>255.255.255.0</strong>，那么计算该计算机的网络号是：</p><ul><li>IP = 101.202.99.2</li><li>Mask = 255.255.255.0</li><li>Network = IP &amp; Mask = 101.202.99.0</li></ul><p>每台计算机都需要正确配置IP地址和子网掩码，根据这两个就可以计算网络号，如果两台计算机计算出的网络号相同，说明两台计算机在同一个网络，可以直接通信。如果两台计算机计算出的网络号不同，那么两台计算机不在同一个网络，不能直接通信，它们之间必须通过路由器或者交换机这样的网络设备间接通信，我们把这种设备称为<strong>网关</strong>。</p><p>网关的作用就是连接多个网络，负责把来自一个网络的数据包发到另一个网络，这个过程叫<strong>路由</strong>。</p><p>所以，一台计算机的一个网卡会有3个关键配置：</p><p>network</p><ul><li>IP地址，例如：10.0.2.15</li><li>子网掩码，例如：255.255.255.0</li><li>网关的IP地址，例如：10.0.2.2<h3 id="域名"><a href="#域名" class="headerlink" title="域名"></a>域名</h3>因为直接记忆IP地址非常困难，所以我们通常使用域名访问某个特定的服务。域名解析服务器DNS负责把域名翻译成对应的IP，客户端再根据IP地址访问服务器。</li></ul><p>用nslookup可以查看域名对应的IP地址：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ nslookup  https:&#x2F;&#x2F;smalltechnologyjun.com</span><br><span class="line">Server:  xxx.xxx.xxx.xxx</span><br><span class="line">Address: xxx.xxx.xxx.xxx#53</span><br></pre></td></tr></table></figure><p>有一个特殊的本机域名<strong>localhost</strong>，它对应的IP地址总是本机地址<strong>127.0.0.1</strong>。</p><h3 id="网络模型"><a href="#网络模型" class="headerlink" title="网络模型"></a>网络模型</h3><p>由于计算机网络从底层的传输到高层的软件设计十分复杂，要合理地设计计算机网络模型，必须采用<strong>分层模型</strong>，每一层负责处理自己的操作。<strong>OSI（Open System Interconnect）网络模型</strong>是ISO组织定义的一个计算机互联的标准模型，注意它只是一个定义，目的是为了简化网络各层的操作，提供标准接口便于实现和维护。这个模型从上到下依次是：</p><ul><li>应用层，提供应用程序之间的通信；</li><li>表示层：处理数据格式，加解密等等；</li><li>会话层：负责建立和维护会话；</li><li>传输层：负责提供端到端的可靠传输；</li><li>网络层：负责根据目标地址选择路由来传输数据；</li><li>链路层和物理层负责把数据进行分片并且真正通过物理网络传输，例如，无线网、光纤等。</li></ul><h4 id="互联网实际使用的TCP-IP模型并不是对应到OSI的7层模型，而是大致对应OSI的5层模型："><a href="#互联网实际使用的TCP-IP模型并不是对应到OSI的7层模型，而是大致对应OSI的5层模型：" class="headerlink" title="互联网实际使用的TCP/IP模型并不是对应到OSI的7层模型，而是大致对应OSI的5层模型："></a>互联网实际使用的TCP/IP模型并不是对应到OSI的7层模型，而是大致对应OSI的5层模型：</h4><pre><code>OSI         TCP/IP 应用层      应用层 表示层会话层传输层      传输层网络层      IP层链路层      网络接口层物理层</code></pre><h3 id="常用协议"><a href="#常用协议" class="headerlink" title="常用协议"></a>常用协议</h3><p>IP协议是一个分组交换，它不保证可靠传输。而TCP协议是传输控制协议，它是面向连接的协议，支持可靠传输和双向通信。TCP协议是建立在IP协议之上的，简单地说，IP协议只负责发数据包，不保证顺序和正确性，而TCP协议负责控制数据包传输，它在传输数据之前需要先建立连接，建立连接后才能传输数据，传输完后还需要断开连接。TCP协议之所以能保证数据的可靠传输，是通过接收确认、超时重传这些机制实现的。并且，TCP协议允许双向通信，即通信双方可以同时发送和接收数据。</p><ul><li><p>TCP协议也是应用最广泛的协议，许多高级协议都是建立在TCP协议之上的，例如HTTP、SMTP等。</p></li><li><p>UDP协议（User Datagram Protocol）是一种数据报文协议，它是无连接协议，不保证可靠传输。因为UDP协议在通信前不需要建立连接，因此它的传输效率比TCP高，而且UDP协议比TCP协议要简单得多。</p></li></ul><p>选择UDP协议时，传输的数据通常是能容忍丢失的，例如，一些语音视频通信的应用会选择UDP协议。</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>计算机网络的基本概念主要有：</p><ul><li>计算机网络：由两台或更多计算机组成的网络；</li><li>互联网：连接网络的网络；</li><li>IP地址：计算机的网络接口（通常是网卡）在网络中的唯一标识；</li><li>网关：负责连接多个网络，并在多个网络之间转发数据的计算机，通常是路由器或交换机；</li><li>网络协议：互联网使用TCP/IP协议，它泛指互联网协议簇；</li><li>IP协议：一种分组交换传输协议；</li><li>TCP协议：一种面向连接，可靠传输的协议；</li><li>UDP协议：一种无连接，不可靠传输的协议。</li></ul>]]></content>
      
      
      <categories>
          
          <category> network </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 网络基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计算机网络思维导图</title>
      <link href="2020/11/12/internet-2020-11-26-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE/"/>
      <url>2020/11/12/internet-2020-11-26-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE/</url>
      
        <content type="html"><![CDATA[<p>分享计算机网络思维导图，持续更新ing</p><span id="more"></span><p><img src="https://raw.githubusercontent.com/ChengKeJ/ChengKeJ.github.io/master/img/internet.png"></p>]]></content>
      
      
      <categories>
          
          <category> network </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 网络基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>设计模式-代理模式</title>
      <link href="2020/10/30/designPattern-2020-10-30-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F/"/>
      <url>2020/10/30/designPattern-2020-10-30-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<p>在有些情况下，一个客户不能或者不想直接访问另一个对象，这时需要找一个中介帮忙完成某项任务，这个中介就是代理对象。例如，购买火车票不一定要去火车站买，可以通过 12306 网站或者去火车票代售点买。又如找女朋友、找保姆、找工作等都可以通过找中介完成。</p><p>在软件设计中，使用代理模式的例子也很多，例如，要访问的远程对象比较大（如视频或大图像等），其下载要花很多时间。还有因为安全原因需要屏蔽客户端直接访问真实对象，如某单位的内部数据库等。</p><span id="more"></span><h3 id="代理模式的定义与特点"><a href="#代理模式的定义与特点" class="headerlink" title="代理模式的定义与特点"></a>代理模式的定义与特点</h3><p>代理模式的定义：由于某些原因需要给某对象提供一个代理以控制对该对象的访问。这时，访问对象不适合或者不能直接引用目标对象，代理对象作为访问对象和目标对象之间的中介。</p><h3 id="代理模式的主要优点有："><a href="#代理模式的主要优点有：" class="headerlink" title="代理模式的主要优点有："></a>代理模式的主要优点有：</h3><ul><li>代理模式在客户端与目标对象之间起到一个中介作用和保护目标对象的作用；</li><li>代理对象可以扩展目标对象的功能；</li><li>代理模式能将客户端与目标对象分离，在一定程度上降低了系统的耦合度，增加了程序的可扩展性</li></ul><h3 id="其主要缺点是："><a href="#其主要缺点是：" class="headerlink" title="其主要缺点是："></a>其主要缺点是：</h3><ul><li>代理模式会造成系统设计中类的数量增加</li><li>在客户端和目标对象之间增加一个代理对象，会造成请求处理速度变慢；</li><li>增加了系统的复杂度；</li><li>那么如何解决以上提到的缺点呢？答案是可以使用动态代理方式</li></ul><h3 id="代理模式的结构与实现"><a href="#代理模式的结构与实现" class="headerlink" title="代理模式的结构与实现"></a>代理模式的结构与实现</h3><p>代理模式的结构比较简单，主要是通过定义一个继承抽象主题的代理来包含真实主题，从而实现对真实主题的访问，下面来分析其基本结构和实现方法。</p><h4 id="1-模式的结构"><a href="#1-模式的结构" class="headerlink" title="1. 模式的结构"></a>1. 模式的结构</h4><p>代理模式的主要角色如下。</p><ul><li>抽象主题（Subject）类：通过接口或抽象类声明真实主题和代理对象实现的业务方法。</li><li>真实主题（Real Subject）类：实现了抽象主题中的具体业务，是代理对象所代表的真实对象，是最终要引用的对象。</li><li>代理（Proxy）类：提供了与真实主题相同的接口，其内部含有对真实主题的引用，它可以访问、控制或扩展真实主题的功能。</li></ul><p>其结构图如图 1 所示<br><img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gk7fvl8ky9g30i209mmxh.gif"></p><p>在代码中，一般代理会被理解为代码增强，实际上就是在原代码逻辑前后增加一些代码逻辑，而使调用者无感知。</p><p>根据代理的创建时期，代理模式分为静态代理和动态代理。</p><ul><li>静态：由程序员创建代理类或特定工具自动生成源代码再对其编译，在程序运行前代理类的 .class 文件就已经存在了。</li><li>动态：在程序运行时，运用反射机制动态创建而成</li></ul><h4 id="2-模式的实现"><a href="#2-模式的实现" class="headerlink" title="2. 模式的实现"></a>2. 模式的实现</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line">1.三个抽象主题</span><br><span class="line">&#x2F;**</span><br><span class="line"> * process check gamer ticket</span><br><span class="line"> *&#x2F;</span><br><span class="line">public interface CheckProcess &#123;</span><br><span class="line">    void check();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public interface DietProcess &#123;</span><br><span class="line">    void diet();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * process game</span><br><span class="line"> *&#x2F;</span><br><span class="line">public interface GameProcess &#123;</span><br><span class="line">    void play();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">2. 三个真实主题</span><br><span class="line">public class BigGamePayer extends GamePayer &#123;</span><br><span class="line">    @Override</span><br><span class="line">    public void play() &#123;</span><br><span class="line">        log.info(&quot;&#x3D;&#x3D;&#x3D; big player start play ...&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public class BigChecker implements CheckProcess &#123;</span><br><span class="line">    @Override</span><br><span class="line">    public void check() &#123;</span><br><span class="line">        log.info(&quot;&#x3D;&#x3D;&#x3D; start check ticket&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public class Dieter implements DietProcess &#123;</span><br><span class="line">    @Override</span><br><span class="line">    public void diet() &#123;</span><br><span class="line">      log.info(&quot;&#x3D;&#x3D; start make diet : ice &quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">3. 代理类</span><br><span class="line">public class ProxyProcess implements GameProcess, CheckProcess, DietProcess &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 代理检票</span><br><span class="line">    private CheckProcess checkProcess;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 代理游戏</span><br><span class="line">    private GameProcess  gameProcess;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 代理饮食</span><br><span class="line">    private DietProcess  dietProcess;</span><br><span class="line"></span><br><span class="line">    public &lt;T&gt; ProxyProcess(T t) &#123;</span><br><span class="line">        if (t instanceof GameProcess) &#123;</span><br><span class="line">            this.gameProcess &#x3D; (GameProcess) t;</span><br><span class="line">        &#125; else if (t instanceof CheckProcess) &#123;</span><br><span class="line">            this.checkProcess &#x3D; (CheckProcess) t;</span><br><span class="line">        &#125; else if (t instanceof DietProcess) &#123;</span><br><span class="line">            this.dietProcess &#x3D; (DietProcess) t;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void play() &#123;</span><br><span class="line">        before();</span><br><span class="line">        this.gameProcess.play();</span><br><span class="line">        after();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void check() &#123;</span><br><span class="line">        this.checkProcess.check();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void diet() &#123;</span><br><span class="line">        this.dietProcess.diet();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    public void before() &#123;</span><br><span class="line">        log.info(&quot;&#x3D;&#x3D;&#x3D; proxy: start before play game&quot;);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void after() &#123;</span><br><span class="line">        log.info(&quot;&#x3D;&#x3D;&#x3D; proxy:  start after play game&quot;);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>游戏屋:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">public class GameHome &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        proxyCheck();</span><br><span class="line">        proxyPlay();</span><br><span class="line">        proxyDiete();</span><br><span class="line">    &#125;</span><br><span class="line">    public static void proxyPlay() &#123;</span><br><span class="line">        &#x2F;&#x2F; 代理玩游戏</span><br><span class="line">        BigGamePayer bigGamePayer &#x3D; new BigGamePayer();</span><br><span class="line">        ProxyProcess proxyPayer &#x3D; new ProxyProcess(bigGamePayer);</span><br><span class="line">        proxyPayer.play();</span><br><span class="line">    &#125;</span><br><span class="line">    public static void proxyCheck() &#123;</span><br><span class="line">        &#x2F;&#x2F; 代理检票</span><br><span class="line">        BigChecker bigChecker &#x3D; new BigChecker();</span><br><span class="line">        ProxyProcess proxyProcess &#x3D; new ProxyProcess(bigChecker);</span><br><span class="line">        proxyProcess.check();</span><br><span class="line">    &#125;</span><br><span class="line">    public static void proxyDiete() &#123;</span><br><span class="line">        &#x2F;&#x2F; 代理美食</span><br><span class="line">        Dieter dieter &#x3D; new Dieter();</span><br><span class="line">        ProxyProcess proxyProcess &#x3D; new ProxyProcess(dieter);</span><br><span class="line">        proxyProcess.diet();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>运行结果:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">16:29:18.572 [main] INFO com.ckj.base.designPatternes.proxy.extend.BigChecker - &#x3D;&#x3D;&#x3D; start check ticket</span><br><span class="line">16:29:18.575 [main] INFO com.ckj.base.designPatternes.proxy.proxy.ProxyProcess - &#x3D;&#x3D;&#x3D; proxy: start before play game</span><br><span class="line">16:29:18.575 [main] INFO com.ckj.base.designPatternes.proxy.extend.BigGamePayer - &#x3D;&#x3D;&#x3D; big player start play ...</span><br><span class="line">16:29:18.575 [main] INFO com.ckj.base.designPatternes.proxy.proxy.ProxyProcess - &#x3D;&#x3D;&#x3D; proxy:  start after play game</span><br><span class="line">16:29:18.576 [main] INFO com.ckj.base.designPatternes.proxy.extend.Dieter - &#x3D;&#x3D; start make diet : ice </span><br></pre></td></tr></table></figure><h4 id="3-动态代理"><a href="#3-动态代理" class="headerlink" title="3. 动态代理"></a>3. 动态代理</h4><p>在前面介绍的代理模式中，代理类中包含了对真实主题的引用，这种方式存在两个缺点。</p><ul><li>真实主题与代理主题一一对应，增加真实主题也要增加代理。</li><li>设计代理以前真实主题必须事先存在，不太灵活。采用动态代理模式可以解决以上问题，如 SpringAOP，其结构图如图 4 所示。</li></ul><p><img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gk7jnux1oeg30hi0g6js3.gif"></p><p>改造如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; dynamic proxy</span><br><span class="line">    GameProcess proxy &#x3D; (GameProcess) Proxy.newProxyInstance(GameProcess.class.getClassLoader(), new Class[]&#123;GameProcess.class&#125;,</span><br><span class="line">            new InvocationHandler() &#123;</span><br><span class="line">        @Override</span><br><span class="line">        public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123;</span><br><span class="line">            log.info(&quot;start dynamic process...&quot;);</span><br><span class="line">            return method.invoke(new BigGamePayer(), args);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">    proxy.play();</span><br></pre></td></tr></table></figure><p>运行结果:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">18:17:11.681 [main] INFO com.ckj.base.designPatternes.proxy.GameHome - start dynamic process...</span><br><span class="line">18:17:11.681 [main] INFO com.ckj.base.designPatternes.proxy.extend.BigGamePayer - &#x3D;&#x3D;&#x3D; big player start play ...</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis 的事物</title>
      <link href="2020/10/27/redis-2020-10-27-redis-%E7%9A%84%E4%BA%8B%E7%89%A9/"/>
      <url>2020/10/27/redis-2020-10-27-redis-%E7%9A%84%E4%BA%8B%E7%89%A9/</url>
      
        <content type="html"><![CDATA[<p>MULTI 、 EXEC 、 DISCARD 和 WATCH 是 Redis 事务的基础。</p><span id="more"></span><p>事务可以一次执行多个命令， 并且带有以下两个重要的保证：</p><ul><li>事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。</li><li>事务是一个原子操作：事务中的命令要么全部被执行，要么全部都不执行。</li></ul><!--more--><p>EXEC 命令负责触发并执行事务中的所有命令：<br>当使用 AOF 方式做持久化的时候， Redis 会使用单个 write(2) 命令将事务写入到磁盘中。<br>然而，如果 Redis 服务器因为某些原因被管理员杀死，或者遇上某种硬件故障，那么可能只有部分事务命令会被成功写入到磁盘中。<br>如果 Redis 在重新启动时发现 AOF 文件出了这样的问题，那么它会退出，并汇报一个错误。<br>使用 redis-check-aof 程序可以修复这一问题：它会移除 AOF 文件中不完整事务的信息，确保服务器可以顺利启动。</p><ul><li>如果客户端在使用 MULTI 开启了一个事务之后，却因为断线而没有成功执行 EXEC ，那么事务中的所有命令都不会被执行。</li><li>另一方面，如果客户端成功在开启事务之后执行 EXEC ，那么事务中的所有命令都会被执行。<br>从 2.2 版本开始，Redis 还可以通过乐观锁（optimistic lock）实现 CAS （check-and-set）操作，具体信息请参考文档的后半部分。</li></ul><h3 id="用法"><a href="#用法" class="headerlink" title="用法"></a>用法</h3><p>MULTI 命令用于开启一个事务，它总是返回 OK 。</p><p>MULTI 执行之后， 客户端可以继续向服务器发送任意多条命令， 这些命令不会立即被执行， 而是被放到一个队列中， 当 EXEC 命令被调用时， 所有队列中的命令才会被执行。</p><p>另一方面， 通过调用 DISCARD ， 客户端可以清空事务队列， 并放弃执行事务。</p><p>以下是一个事务例子， 它原子地增加了 foo 和 bar 两个键的值：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&gt; MULTI</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">&gt; INCR foo</span><br><span class="line">QUEUED</span><br><span class="line"></span><br><span class="line">&gt; INCR bar</span><br><span class="line">QUEUED</span><br><span class="line"></span><br><span class="line">&gt; EXEC</span><br><span class="line">1) (integer) 1</span><br><span class="line">2) (integer) 1</span><br></pre></td></tr></table></figure><p>EXEC 命令的回复是一个数组， 数组中的每个元素都是执行事务中的命令所产生的回复。 其中， 回复元素的先后顺序和命令发送的先后顺序一致。</p><p>当客户端处于事务状态时， 所有传入的命令都会返回一个内容为 QUEUED 的状态回复（status reply）， 这些被入队的命令将在 EXEC 命令被调用时执行。</p><h3 id="事务中的错误"><a href="#事务中的错误" class="headerlink" title="事务中的错误"></a>事务中的错误</h3><p>使用事务时可能会遇上以下两种错误：</p><ul><li>事务在执行 EXEC 之前，入队的命令可能会出错。比如说，命令可能会产生语法错误（参数数量错误，参数名错误，等等），或者其他更严重的错误，比如内存不足（如果服务器使用 maxmemory 设置了最大内存限制的话）。</li><li>命令可能在 EXEC 调用之后失败。举个例子，事务中的命令可能处理了错误类型的键，比如将列表命令用在了字符串键上面，诸如此类。<br>对于发生在 EXEC 执行之前的错误，客户端以前的做法是检查命令入队所得的返回值：如果命令入队时返回 QUEUED ，那么入队成功；否则，就是入队失败。如果有命令在入队时失败，那么大部分客户端都会停止并取消这个事务。</li></ul><p>不过，从 Redis 2.6.5 开始，服务器会对命令入队失败的情况进行记录，并在客户端调用 EXEC 命令时，拒绝执行并自动放弃这个事务。</p><p>在 Redis 2.6.5 以前， Redis 只执行事务中那些入队成功的命令，而忽略那些入队失败的命令。 而新的处理方式则使得在流水线（pipeline）中包含事务变得简单，因为发送事务和读取事务的回复都只需要和服务器进行一次通讯。</p><p>至于那些在 EXEC 命令执行之后所产生的错误， 并没有对它们进行特别处理： 即使事务中有某个/某些命令在执行时产生了错误， 事务中的其他命令仍然会继续执行。</p><p>从协议的角度来看这个问题，会更容易理解一些。 以下例子中， LPOP 命令的执行将出错， 尽管调用它的语法是正确的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Trying 127.0.0.1...</span><br><span class="line">Connected to localhost.</span><br><span class="line">Escape character is &#39;^]&#39;.</span><br><span class="line"></span><br><span class="line">MULTI</span><br><span class="line">+OK</span><br><span class="line"></span><br><span class="line">SET a 3</span><br><span class="line">abc</span><br><span class="line"></span><br><span class="line">+QUEUED</span><br><span class="line">LPOP a</span><br><span class="line"></span><br><span class="line">+QUEUED</span><br><span class="line">EXEC</span><br><span class="line"></span><br><span class="line">*2</span><br><span class="line">+OK</span><br><span class="line">-ERR Operation against a key holding the wrong kind of value</span><br></pre></td></tr></table></figure><p>EXEC 返回两条批量回复（bulk reply）： 第一条是 OK ，而第二条是 -ERR 。 至于怎样用合适的方法来表示事务中的错误， 则是由客户端自己决定的。</p><p>最重要的是记住这样一条， 即使事务中有某条/某些命令执行失败了， 事务队列中的其他命令仍然会继续执行 —— Redis 不会停止执行事务中的命令。</p><p>以下例子展示的是另一种情况， 当命令在入队时产生错误， 错误会立即被返回给客户端：</p><p>MULTI<br>+OK</p><p>INCR a b c<br>-ERR wrong number of arguments for ‘incr’ command<br>因为调用 INCR 命令的参数格式不正确， 所以这个 INCR 命令入队失败。</p><h3 id="为什么-Redis-不支持回滚（roll-back）"><a href="#为什么-Redis-不支持回滚（roll-back）" class="headerlink" title="为什么 Redis 不支持回滚（roll back）"></a>为什么 Redis 不支持回滚（roll back）</h3><p>如果你有使用关系式数据库的经验， 那么 “Redis 在事务失败时不进行回滚，而是继续执行余下的命令”这种做法可能会让你觉得有点奇怪。</p><p>以下是这种做法的优点：</p><ul><li>Redis 命令只会因为错误的语法而失败（并且这些问题不能在入队时发现），或是命令用在了错误类型的键上面：这也就是说，从实用性的角度来说，失败的命令是由编程错误造成的，而这些错误应该在开发的过程中被发现，而不应该出现在生产环境中。</li><li>因为不需要对回滚进行支持，所以 Redis 的内部可以保持简单且快速。<br>有种观点认为 Redis 处理事务的做法会产生 bug ， 然而需要注意的是， 在通常情况下， 回滚并不能解决编程错误带来的问题。 举个例子， 如果你本来想通过 INCR 命令将键的值加上 1 ， 却不小心加上了 2 ， 又或者对错误类型的键执行了 INCR ， 回滚是没有办法处理这些情况的。</li></ul><p>鉴于没有任何机制能避免程序员自己造成的错误， 并且这类错误通常不会在生产环境中出现， 所以 Redis 选择了更简单、更快速的无回滚方式来处理事务。</p><h3 id="放弃事务"><a href="#放弃事务" class="headerlink" title="放弃事务"></a>放弃事务</h3><p>当执行 DISCARD 命令时， 事务会被放弃， 事务队列会被清空， 并且客户端会从事务状态中退出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">redis&gt; SET foo 1</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">redis&gt; MULTI</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">redis&gt; INCR foo</span><br><span class="line">QUEUED</span><br><span class="line"></span><br><span class="line">redis&gt; DISCARD</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">redis&gt; GET foo</span><br><span class="line">&quot;1&quot;</span><br></pre></td></tr></table></figure><h3 id="使用-check-and-set-操作实现乐观锁"><a href="#使用-check-and-set-操作实现乐观锁" class="headerlink" title="使用 check-and-set 操作实现乐观锁"></a>使用 check-and-set 操作实现乐观锁</h3><p>WATCH 命令可以为 Redis 事务提供 check-and-set （CAS）行为。</p><p>被 WATCH 的键会被监视，并会发觉这些键是否被改动过了。 如果有至少一个被监视的键在 EXEC 执行之前被修改了， 那么整个事务都会被取消， EXEC 返回空多条批量回复（null multi-bulk reply）来表示事务已经失败。</p><p>举个例子， 假设我们需要原子性地为某个值进行增 1 操作（假设 INCR 不存在）。</p><p>首先我们可能会这样做：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">val &#x3D; GET mykey</span><br><span class="line">val &#x3D; val + 1</span><br><span class="line">SET mykey $val</span><br></pre></td></tr></table></figure><p>上面的这个实现在只有一个客户端的时候可以执行得很好。 但是， 当多个客户端同时对同一个键进行这样的操作时， 就会产生竞争条件。</p><p>举个例子， 如果客户端 A 和 B 都读取了键原来的值， 比如 10 ， 那么两个客户端都会将键的值设为 11 ， 但正确的结果应该是 12 才对。</p><p>有了 WATCH ， 我们就可以轻松地解决这类问题了：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">WATCH mykey</span><br><span class="line"></span><br><span class="line">val &#x3D; GET mykey</span><br><span class="line">val &#x3D; val + 1</span><br><span class="line"></span><br><span class="line">MULTI</span><br><span class="line">SET mykey $val</span><br><span class="line">EXEC</span><br></pre></td></tr></table></figure><p>使用上面的代码， 如果在 WATCH 执行之后， EXEC 执行之前， 有其他客户端修改了 mykey 的值， 那么当前客户端的事务就会失败。 程序需要做的， 就是不断重试这个操作， 直到没有发生碰撞为止。</p><p>这种形式的锁被称作乐观锁， 它是一种非常强大的锁机制。 并且因为大多数情况下， 不同的客户端会访问不同的键， 碰撞的情况一般都很少， 所以通常并不需要进行重试。</p><h3 id="了解-WATCH"><a href="#了解-WATCH" class="headerlink" title="了解 WATCH"></a>了解 WATCH</h3><p>WATCH 使得 EXEC 命令需要有条件地执行： 事务只能在所有被监视键都没有被修改的前提下执行， 如果这个前提不能满足的话，事务就不会被执行。</p><p>如果你使用 WATCH 监视了一个带过期时间的键， 那么即使这个键过期了， 事务仍然可以正常执行， 关于这方面的详细情况，请看这个帖子： <a target="_blank" rel="noopener" href="http://code.google.com/p/redis/issues/detail?id=270">http://code.google.com/p/redis/issues/detail?id=270</a></p><p>WATCH 命令可以被调用多次。 对键的监视从 WATCH 执行之后开始生效， 直到调用 EXEC 为止。</p><p>用户还可以在单个 WATCH 命令中监视任意多个键， 就像这样：</p><p>redis&gt; WATCH key1 key2 key3<br>OK<br>当 EXEC 被调用时， 不管事务是否成功执行， 对所有键的监视都会被取消。</p><p>另外， 当客户端断开连接时， 该客户端对键的监视也会被取消。</p><p>使用无参数的 UNWATCH 命令可以手动取消对所有键的监视。 对于一些需要改动多个键的事务， 有时候程序需要同时对多个键进行加锁， 然后检查这些键的当前值是否符合程序的要求。 当值达不到要求时， 就可以使用 UNWATCH 命令来取消目前对键的监视， 中途放弃这个事务， 并等待事务的下次尝试。</p><h3 id="使用-WATCH-实现-ZPOP"><a href="#使用-WATCH-实现-ZPOP" class="headerlink" title="使用 WATCH 实现 ZPOP"></a>使用 WATCH 实现 ZPOP</h3><p>WATCH 可以用于创建 Redis 没有内置的原子操作。</p><p>举个例子， 以下代码实现了原创的 ZPOP 命令， 它可以原子地弹出有序集合中分值（score）最小的元素：</p><p>WATCH zset<br>element = ZRANGE zset 0 0<br>MULTI<br>    ZREM zset element<br>EXEC<br>程序只要重复执行这段代码， 直到 EXEC 的返回值不是空多条回复（null multi-bulk reply）即可。</p><h3 id="Redis-脚本和事务"><a href="#Redis-脚本和事务" class="headerlink" title="Redis 脚本和事务"></a>Redis 脚本和事务</h3><p>从定义上来说， Redis 中的脚本本身就是一种事务， 所以任何在事务里可以完成的事， 在脚本里面也能完成。 并且一般来说， 使用脚本要来得更简单，并且速度更快。</p><p>因为脚本功能是 Redis 2.6 才引入的， 而事务功能则更早之前就存在了， 所以 Redis 才会同时存在两种处理事务的方法。</p><p>不过我们并不打算在短时间内就移除事务功能， 因为事务提供了一种即使不使用脚本， 也可以避免竞争条件的方法， 而且事务本身的实现并不复杂。</p><p>不过在不远的将来， 可能所有用户都会只使用脚本来实现事务也说不定。 如果真的发生这种情况的话， 那么我们将废弃并最终移除事务功能。</p><blockquote><p>译者：黄健宏<br>原文：<a target="_blank" rel="noopener" href="http://redisdoc.com/topic/transaction.html">http://redisdoc.com/topic/transaction.html</a><br>本文档翻译自： <a target="_blank" rel="noopener" href="http://redis.io/topics/transactions">http://redis.io/topics/transactions</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis 事物 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis 的线程模型</title>
      <link href="2020/10/26/redis-2020-10-26-redis-%E7%9A%84%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B/"/>
      <url>2020/10/26/redis-2020-10-26-redis-%E7%9A%84%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h3 id="Redis-的线程模型"><a href="#Redis-的线程模型" class="headerlink" title="Redis 的线程模型"></a>Redis 的线程模型</h3><p>Redis 内部使用文件事件处理器 file event handler ，这个文件事件处理器是单线程的，所以 Redis 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 socket，将产生事件的 socket 压入内存队列中，事件分派器根据 socket 上的事件类型来选择对应的事件处理器进行处理。</p><span id="more"></span><p>文件事件处理器的结构包含 4 个部分：</p><ul><li>多个 socket</li><li>IO 多路复用程序</li><li>文件事件分派器</li><li>事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）</li></ul><p>多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 socket，会将产生事件的 socket 放入队列中排队，事件分派器每次从队列中取出一个 socket，根据 socket 的事件类型交给对应的事件处理器进行处理。</p><p>来看客户端与 Redis 的一次通信过程：</p><p>Redis-single-thread-model</p><p><img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gk2qyo3nu4j31c80r8n45.jpg"></p><p>要明白，通信是通过 socket 来完成的，不懂的同学可以先去看一看 socket 网络编程。</p><p>首先，Redis 服务端进程初始化的时候，会将 server socket 的 AE_READABLE 事件与连接应答处理器关联。</p><p>客户端 socket01 向 Redis 进程的 server socket 请求建立连接，此时 server socket 会产生一个 AE_READABLE 事件，IO 多路复用程序监听到 server socket 产生的事件后，将该 socket 压入队列中。文件事件分派器从队列中获取 socket，交给连接应答处理器。连接应答处理器会创建一个能与客户端通信的 socket01，并将该 socket01 的 AE_READABLE 事件与命令请求处理器关联。</p><p>假设此时客户端发送了一个 set key value 请求，此时 Redis 中的 socket01 会产生 AE_READABLE 事件，IO 多路复用程序将 socket01 压入队列，此时事件分派器从队列中获取到 socket01 产生的 AE_READABLE 事件，由于前面 socket01 的 AE_READABLE 事件已经与命令请求处理器关联，因此事件分派器将事件交给命令请求处理器来处理。命令请求处理器读取 socket01 的 key value 并在自己内存中完成 key value 的设置。操作完成后，它会将 socket01 的 AE_WRITABLE 事件与命令回复处理器关联。</p><p>如果此时客户端准备好接收返回结果了，那么 Redis 中的 socket01 会产生一个 AE_WRITABLE 事件，同样压入队列中，事件分派器找到相关联的命令回复处理器，由命令回复处理器对 socket01 输入本次操作的一个结果，比如 ok ，之后解除 socket01 的 AE_WRITABLE 事件与命令回复处理器的关联。</p><p>这样便完成了一次通信。</p><h3 id="为啥-Redis-单线程模型也能效率这么高？"><a href="#为啥-Redis-单线程模型也能效率这么高？" class="headerlink" title="为啥 Redis 单线程模型也能效率这么高？"></a>为啥 Redis 单线程模型也能效率这么高？</h3><ul><li>纯内存操作。</li><li>核心是基于非阻塞的 IO 多路复用机制。</li><li> C 语言实现，一般来说，C 语言实现的程序“距离”操作系统更近，执行速度相对会更快。</li><li> 单线程反而避免了多线程的频繁上下文切换问题，预防了多线程可能产生的竞争问题。</li></ul><h3 id="Redis-6-0-开始引入多线程"><a href="#Redis-6-0-开始引入多线程" class="headerlink" title="Redis 6.0 开始引入多线程"></a>Redis 6.0 开始引入多线程</h3><p>注意！ Redis 6.0 之后的版本抛弃了单线程模型这一设计，原本使用单线程运行的 Redis 也开始选择性地使用多线程模型。</p><p>前面还在强调 Redis 单线程模型的高效性，现在为什么又要引入多线程？这其实说明 Redis 在有些方面，单线程已经不具有优势了。因为读写网络的 Read/Write 系统调用在 Redis 执行期间占用了大部分 CPU 时间，如果把网络读写做成多线程的方式对性能会有很大提升。</p><p>Redis 的多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程。 之所以这么设计是不想 Redis 因为多线程而变得复杂，需要去控制 key、lua、事务、LPUSH/LPOP 等等的并发问题。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>Redis 选择使用单线程模型处理客户端的请求主要还是因为 CPU 不是 Redis 服务器的瓶颈，所以使用多线程模型带来的性能提升并不能抵消它带来的开发成本和维护成本，系统的性能瓶颈也主要在网络 I/O 操作上；而 Redis 引入多线程操作也是出于性能上的考虑，对于一些大键值对的删除操作，通过多线程非阻塞地释放内存空间也能减少对 Redis 主线程阻塞的时间，提高执行的效率。</p>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis 线程模型 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JVM内存结构</title>
      <link href="2020/10/12/jvm-2020-10-09-jvm%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84/"/>
      <url>2020/10/12/jvm-2020-10-09-jvm%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<p>1.7和1.8之间JVM内存结构以及它们的差异</p><span id="more"></span><h4 id="JVM-内存分配"><a href="#JVM-内存分配" class="headerlink" title="JVM 内存分配"></a>JVM 内存分配</h4><p>根据 <a target="_blank" rel="noopener" href="https://docs.oracle.com/javase/specs/jvms/se8/html/index.html">JVM 规范</a>，JVM 内存分为虚拟机栈、堆、方法区、程序计数器、本地方法 stack5个部分。</p><blockquote><p><a target="_blank" rel="noopener" href="https://www.programmersought.com/article/74164482693/">https://www.programmersought.com/article/74164482693/</a></p></blockquote><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjk8684wiqj30w70lh47l.jpg"></p><table><thead><tr><th>名称</th><th>特征</th><th>作用</th><th>配置参数</th><th>异常</th></tr></thead><tbody><tr><td>程序计数器</td><td>占用内存小，线程私有，生命周期与线程相同</td><td>字节码行号指示器</td><td>无</td><td>无</td></tr><tr><td>虚拟机栈</td><td>线程私有，生命周期与线程相同，使用连续的内存空间</td><td>Java方法执行的内存模型，存储局部变量表、操作栈、动态链接、方法出口等信息</td><td>-Xss</td><td>StackOverflowError/OutOfMemoryError</td></tr><tr><td>堆</td><td>线程共享，生命周期与虚拟机相同，可以不使用连续的内存地址</td><td>保存对象实例，所有对象实例（包括数组）都要在堆上分配</td><td>-Xms -Xsx -Xmn</td><td>OutOfMemoryError</td></tr><tr><td>方法区</td><td>线程共享，生命周期与虚拟机相同，可以不使用连续的内存地址</td><td>存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据</td><td>-XX:PermSize:16M -XX:MaxPermSize64M / -XX:MetaspaceSize=16M -XX:MaxMetaspaceSize=64M</td><td>OutOfMemoryError</td></tr><tr><td>本地方法栈</td><td>线程私有</td><td>为虚拟机使用到的 Native 方法服务</td><td>无</td><td>StackOverflowError/OutOfMemoryError</td></tr></tbody></table><h4 id="1-7和1-8之间JVM内存结构以及它们的差异"><a href="#1-7和1-8之间JVM内存结构以及它们的差异" class="headerlink" title="1.7和1.8之间JVM内存结构以及它们的差异"></a>1.7和1.8之间JVM内存结构以及它们的差异</h4><p>事实上，移除永久代的工作是从 JDK 1.7开始的。在 JDK 1.7中，存储在永久生成中的部分数据已经转移到 Java 堆或本机堆。</p><p>然而，JDK 1.7中的永久代仍然存在，并且没有被完全删除。</p><p>例如，将符号引用转移到本机堆; 将类的文本变量(内嵌字符串)和静态变量转移到 Java 堆。</p><p>JDK 1.8 同 JDK 1.7 比，最大的差别就是：元数据区取代了永久代。元空间的本质和永久代类似，都是对 JVM 规范中方法区的实现。</p><p>不过元空间与永久代之间最大的区别在于：元数据区并不在虚拟机中，而是使用本地内存。</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjk6ksulhlj31920mctca.jpg"></p><blockquote><p>方法区是java虚拟机规范中定义的一种概念上的区域，不同的厂商可以对虚拟机进行不同的实现。我们通常使用的Java SE都是由Sun JDK和OpenJDK所提供，这也是应用最广泛的版本。而该版本使用的VM就是HotSpot VM。通常情况下，我们所讲的java虚拟机指的就是HotSpot的版本</p></blockquote><ul><li><p>PermGen(永久代)</p><p>Java7及以前版本的Hotspot中方法区位于永久代中。同时，永久代和堆是相互隔离的，但它们使用的物理内存是连续的，永久代的垃圾收集是和老年代捆绑在一起的，因此无论谁满了，都会触发永久代和老年代的垃圾收集。</p><p>Java7中永久代中存储的部分数据已经开始转移到Java Heap或Native Memory中了。比如，符号引用(Symbols)转移到了Native Memory；字符串常量池(interned strings)转移到了Java Heap；类的静态变量(class statics)转移到了Java Heap。</p><p>绝大部分Java程序员应该都见过java.lang.OutOfMemoryError: PremGen space异常。这里的PermGen space其实指的就是方法区。不过方法区和PermGen space又有着本质的区别。前者是JVM的规范，而后者则是JVM规范的一种实现，并且只有HotSpot才有PermGen space，而对于其他类型的虚拟机，如JRockit(Oracle)、J9(IBM)并没有PermGen space。由于方法区主要存储类的相关信息，所以对于动态生成类的情况比较容易出现永久代的内存溢出。并且JDK 1.8中永久代的参数PermSize和MaxPermSize已经失效。</p></li><li><p>Metaspace(元空间)</p><p>对于Java8，HotSpot取消了永久代，那么是不是就没有方法区了呢？当然不是，方法区只是一个规范，只不过它的实现变了。</p><p>在Java8中，元空间(Metaspace)登上舞台，方法区存在于元空间(Metaspace)。同时，元空间不再与堆连续，而且是存在于本地内存（Native memory）。</p><p>JDK1.7后对JVM架构进行了改造，将类元数据放到本地内存中，另外，将字符串常量池和静态变量放到Java堆里。HotSpot VM将会为类的元数据明确分配和释放本地内存。在这种架构下，类元信息就突破了原来 -XX:MaxPermSize的限制，现在可以使用更多的本地内存。这样就从一定程度上解决了原来在运行时生成大量类造成经常Full GC问题，如运行时使用反射、代理等。所以升级以后Java堆空间可能会增加。</p><p>元空间的本质和永久代类似，都是对JVM规范中方法区的实现。不过元空间与永久代之间的最大区别在于：元空间并不在虚拟机中，而是使用本地内存。本地内存（Native memory），也称为C-Heap，是供JVM自身进程使用的。当Java Heap空间不足时会触发GC，但Native memory空间不够却不会触发GC。默认情况下元空间是可以无限使用本地内存的，但为了不让它如此膨胀，JVM同样提供了参数来限制它使用的使用。</p><p>-XX:MetaspaceSize，class metadata的初始空间配额，以bytes为单位，达到该值就会触发垃圾收集进行类型卸载，同时GC会对该值进行调整：如果释放了大量的空间，就适当的降低该值；如果释放了很少的空间，那么在不超过MaxMetaspaceSize（如果设置了的话），适当的提高该值。</p><p>-XX：MaxMetaspaceSize，可以为class metadata分配的最大空间。默认是没有限制的。</p><p>-XX：MinMetaspaceFreeRatio,在GC之后，最小的Metaspace剩余空间容量的百分比，减少为class metadata分配空间导致的垃圾收集。</p><p>-XX:MaxMetaspaceFreeRatio,在GC之后，最大的Metaspace剩余空间容量的百分比，减少为class metadata释放空间导致的垃圾收集。</p></li><li><p>对于方法区，Java8之后的变化</p><p>移除了永久代（PermGen），替换为元空间（Metaspace）</p><p>永久代中的class metadata（类元信息）转移到了native memory（本地内存，而不是虚拟机）</p><p>永久代中的interned Strings（字符串常量池） 和 class static variables（类静态变量）转移到了Java heap</p><p>永久代参数（PermSize MaxPermSize）-&gt; 元空间参数（MetaspaceSize MaxMetaspaceSize</p></li><li><p>Java8为什么要将永久代替换成Metaspace？</p><p>字符串存在永久代中，容易出现性能问题和内存溢出。</p><p>类及方法的信息等比较难确定其大小，因此对于永久代的大小指定比较困 难，太小容易出现永久代溢出，太大则容易导致老年代溢出。</p><p>永久代会为 GC 带来不必要的复杂度，并且回收效率偏低。</p></li></ul><h4 id=""><a href="#" class="headerlink" title=""></a></h4>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> jvm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis 基础-数据结构-字典</title>
      <link href="2020/07/29/redis-2020-07-29-redis-%E5%9F%BA%E7%A1%80-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%AD%97%E5%85%B8/"/>
      <url>2020/07/29/redis-2020-07-29-redis-%E5%9F%BA%E7%A1%80-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%AD%97%E5%85%B8/</url>
      
        <content type="html"><![CDATA[<h4 id="字典定义"><a href="#字典定义" class="headerlink" title="字典定义:"></a>字典定义:</h4><p>字典（dictionary）， 又名映射（map）或关联数组（associative array）， 是一种抽象数据结构， 由一集键值对（key-value pairs）组成， 各个键值对的键各不相同， 程序可以添加新的键值对到字典中， 或者基于键进行查找、更新或删除等操作。</p><span id="more"></span><p>字典的主要用途有以下两个： 1.实现数据库键空间（key space）2.用作 Hash 类型键的底层实现之一,具体可以看redis 5大对象那篇文章。</p><h4 id="字典的实现"><a href="#字典的实现" class="headerlink" title="字典的实现"></a>字典的实现</h4><p>Redis的字典使用哈希表作为底层实现，一个哈希表里面可以有多个哈希表节点，而每个哈希表节点就保存了字典中的一个键值对。</p><ul><li>哈希表</li></ul><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh6x5esz0sj317w0h4dim.jpg"></p><p>table属性是一个数组，数组中的每个元素都是一个指向dict.h/dictEntry结构的指针，每个dictEntry结构保存着一个键值对。size属性记录了哈希表的大小，也即是table数组的大小，而used属性则记录了哈希表目前已有节点（键值对）的数量。sizemask属性的值总是等于size-1，这个属性和哈希值一起决定一个键应该被放到table数组的哪个索引上面</p><p>一个大小为4的空哈希表:</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh6x8e3dn2j30xa0eeq62.jpg"></p><ul><li>哈希表节点</li></ul><p>哈希表节点使用dictEntry结构表示，每个dictEntry结构都保存着一个键值对。</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh7nrf2momj317o0icdhx.jpg"></p><p>next属性是指向另一个哈希表节点的指针，这个指针可以将多个哈希值相同的键值对连接在一次，以此来解决键冲突（collision）的问题</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh7nu7hg4qj312w08m0un.jpg"></p><h4 id="字典"><a href="#字典" class="headerlink" title="字典"></a>字典</h4><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh7nx14aclj317s0hc413.jpg"></p><p>type属性和privdata属性是针对不同类型的键值对，为创建多态字典而设置的：</p><ul><li><p>type属性是一个指向dictType结构的指针，每个dictType结构保存了一簇用于操作特定类型键值对的函数，Redis会为用途不同的字典设置不同的类型特定函数。</p></li><li><p>而privdata属性则保存了需要传给那些类型特定函数的可选参数。</p></li></ul><p>ht属性是一个包含两个项的数组，数组中的每个项都是一个dictht哈希表，一般情况下，字典只使用ht[0]哈希表，ht[1]哈希表只会在对ht[0]哈希表进行rehash时使用</p><p>除了ht[1]之外，另一个和rehash有关的属性就是rehashidx，它记录了rehash目前的进度，如果目前没有在进行rehash，那么它的值为-1</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh7o1vruinj316c0fygot.jpg"></p><h4 id="哈希算法"><a href="#哈希算法" class="headerlink" title="哈希算法"></a>哈希算法</h4><p>当有新的键值对添加到字典中，需要根据key 算出对应的哈希值和索引值，然后再根据索引值，将包含新键值对的哈希表节点放到哈希表数组的指定索引上面</p><p>Redis计算哈希值和索引值的方法如下:</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh7o7ofn6gj318208odhy.jpg"></p><ul><li>举列：</li></ul><p>  我们要将一个键值对k0和v0添加到字典，先利用上面语句获取hash值，然后获取对应的索引值。</p><p>  <img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh7oaramw2j31560caacn.jpg"></p><h4 id="解决键冲突"><a href="#解决键冲突" class="headerlink" title="解决键冲突"></a>解决键冲突</h4><p>当有两个或以上数量的键被分配到了哈希表数组的同一个索引上面时，我们称这些键发生了冲突（collision）.</p><p>Redis的哈希表使用链地址法（separate chaining）来解决键冲突，每个哈希表节点都有一个next指针，多个哈希表节点可以用next指针构成一个单向链表，被分配到同一个索引上的多个节点可以用这个单向链表连接起来，这就解决了键冲突的问题。  </p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh7t7jdv02j30z40bgacf.jpg"></p><h4 id="rehash"><a href="#rehash" class="headerlink" title="rehash"></a>rehash</h4><p>扩展和收缩哈希表的工作可以通过执行rehash（重新散列）操作来完成，Redis对字典的哈希表执行rehash的步骤如下：</p><p>1）为字典的ht[1]哈希表分配空间，这个哈希表的空间大小取决于要执行的操作，以及ht[0]当前包含的键值对数量（也即是ht[0].used属性的值）：</p><ul><li>如果执行的是扩展操作，那么ht[1]的大小为第一个大于等于ht[0].used*2的2 n（2的n次方幂）；</li><li>如果执行的是收缩操作，那么ht[1]的大小为第一个大于等于ht[0].used的2 n。</li></ul><p>2）将保存在ht[0]中的所有键值对rehash到ht[1]上面：rehash指的是重新计算键的哈希值和索引值，然后将键值对放置到ht[1]哈希表的指定位置上。</p><p>3）当ht[0]包含的所有键值对都迁移到了ht[1]之后（ht[0]变为空表），释放ht[0]，将ht[1]设置为ht[0]，并在ht[1]新创建一个空白哈希表，为下一次rehash做准备。</p><blockquote><p>执行rehash之前的字典</p></blockquote><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh7tfuiudnj310a0hi0wp.jpg"></p><blockquote><p>为字典的ht[1]哈希表分配空间</p></blockquote><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh7tfuiudnj310a0hi0wp.jpg"></p><blockquote><p>将ht[0]包含的四个键值对都rehash到ht[1]</p></blockquote><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh7ticpjpwj314c0i8434.jpg"></p><blockquote><p>释放ht[0]，并将ht[1]设置为ht[0]，然后为ht[1]分配一个空白哈希表</p></blockquote><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh7tiy9y4vj310k0huwik.jpg"></p><p>另一方面，当哈希表的负载因子小于0.1时，程序自动开始对哈希表执行收缩操作</p><h4 id="渐进式rehash"><a href="#渐进式rehash" class="headerlink" title="渐进式rehash"></a>渐进式rehash</h4><p>背景：如果哈希表里保存的键值对数量不是四个，而是四百万、四千万甚至四亿个键值对，那么要一次性将这些键值对全部rehash到ht[1]的话，庞大的计算量可能会导致服务器在一段时间内停止服务。</p><p>为了避免rehash对服务器性能造成影响，服务器不是一次性将ht[0]里面的所有键值对全部rehash到ht[1]，而是分多次、渐进式地将ht[0]里面的键值对慢慢地rehash到ht[1]。</p><p>以下是哈希表渐进式rehash的详细步骤：</p><ul><li><p>1）为ht[1]分配空间，让字典同时持有ht[0]和ht[1]两个哈希表。</p></li><li><p>2）在字典中维持一个索引计数器变量rehashidx，并将它的值设置为0，表示rehash工作正式开始。</p></li><li><p>3）在rehash进行期间，每次对字典执行添加、删除、查找或者更新操作时，程序除了执行指定的操作以外，还会顺带将ht[0]哈希表在rehashidx索引上的所有键值对rehash到ht[1]，当rehash工作完成之后，程序将rehashidx属性的值增一。</p></li><li><p>4）随着字典操作的不断执行，最终在某个时间点上，ht[0]的所有键值对都会被rehash至ht[1]，这时程序将rehashidx属性的值设为-1，表示rehash操作已完成。渐进式rehash的好处在于它采取分而治之的方式，将rehash键值对所需的计算工作均摊到对字典的每个添加、删除、查找和更新操作上，从而避免了集中式rehash而带来的庞大计算量</p></li></ul><p>在渐进式rehash执行期间，新添加到字典的键值对一律会被保存到ht[1]里面，而ht[0]则不再进行任何添加操作，这一措施保证了ht[0]包含的键值对数量会只减不增，并随着rehash操作的执行而最终变成空表。</p><h4 id="字典API"><a href="#字典API" class="headerlink" title="字典API"></a>字典API</h4><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh7w8rgux8j31080bk0x6.jpg"></p>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis 基础-数据结构-简单动态字符串</title>
      <link href="2020/07/28/redis-2020-07-28-redis-%E5%9F%BA%E7%A1%80-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AE%80%E5%8D%95%E5%8A%A8%E6%80%81%E5%AD%97%E7%AC%A6%E4%B8%B2/"/>
      <url>2020/07/28/redis-2020-07-28-redis-%E5%9F%BA%E7%A1%80-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AE%80%E5%8D%95%E5%8A%A8%E6%80%81%E5%AD%97%E7%AC%A6%E4%B8%B2/</url>
      
        <content type="html"><![CDATA[<h4 id="简单动态字符串定义"><a href="#简单动态字符串定义" class="headerlink" title="简单动态字符串定义:"></a>简单动态字符串定义:</h4><p>每个sds.h/sdshdr结构表示一个SDS值</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh6v5tmf5jj31840eq0ur.jpg"></p><span id="more"></span><p>SDS示例:</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh6v6tnl68j30xy0d4wge.jpg"></p><p>SDS和C字符一样保留空字符结尾，但是不会计算在len属性里，自动分配1字节空间和末尾添加空字符都是sds函数自动完成的。</p><h4 id="SDS与C字符串的区别"><a href="#SDS与C字符串的区别" class="headerlink" title="SDS与C字符串的区别:"></a>SDS与C字符串的区别:</h4><ul><li>常数复杂度获取字符串长度</li></ul><p>C字符串本身的长度不记录，所以获取对应的长度是O(n)复杂度。</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh6vg9k270j313w0u0gv5.jpg"></p><p>因为SDS在len属性中记录了SDS本身的长度，所以获取一个SDS长度的复杂度仅为O（1）.</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh6vh7vqaxj31180bqdhg.jpg"></p><p>这个结构确保了获取字符串长度的工作不会成为Redis的性能瓶颈。</p><ul><li>杜绝缓冲区溢出</li></ul><p>C字符串除了O(n)复杂度之外，还会存在缓冲区溢出（buffer overflow）</p><p>使用sds api对 sds修改的时候，会先检查其对应空间是否满足，不满足会自动拓展，在执行修改。</p><p>举个例子，SDS的API里面也有一个用于执行拼接操作的sdscat函数，它可以将一个C字符串拼接到给定SDS所保存的字符串的后面，</p><p>但是在执行拼接操作之前，sdscat会先检查给定SDS的空间是否足够，如果不够的话，sdscat就会先扩展SDS的空间，然后才执行拼接操作</p><p>拼接操作之前:</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh6vni0q9ij30yk0aw0uf.jpg"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sdscat(s,&quot; Cluster&quot;);</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>拼接操作之后:</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh6vnxuvqtj30vk060dgr.jpg"></p><ul><li>减少修改字符串时带来的内存重分配次数</li></ul><p>每次增长或者缩短一个C字符串，程序都总要对保存这个C字符串的数组进行一次内存重分配操作:</p><p>比如拼接操作（append），截断操作（trim）。</p><p>因为内存重分配涉及复杂的算法，并且可能需要执行系统调用，所以它通常是一个比较耗时的操作。</p><p>为了避免C字符串的这种缺陷，SDS通过未使用空间解除了字符串长度和底层数组长度之间的关联：在SDS中，buf数组的长度不一定就是字符数量加一，数组里面可以包含未使用的字节，而这些字节的数量就由SDS的free属性记录</p><p>SDS实现了空间预分配和惰性空间释放两种优化策略：</p><ul><li>1.空间预分配<ul><li>如果对SDS进行修改之后，SDS的长度（也即是len属性的值）将小于1MB，那么程序分配和len属性同样大小的未使用空间，这时SDS len属性的值将和free属性的值相同</li><li>如果对SDS进行修改之后，SDS的长度将大于等于1MB，那么程序会分配1MB的未使用空间</li></ul></li></ul><blockquote><p>执行sdscat之前：</p></blockquote><p>  <img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh6vv4w7sdj30yg0bqq4v.jpg"></p><blockquote><p>执行sdscat之后：</p></blockquote><p>  <img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh6vyesgypj30zk066q3v.jpg"></p><blockquote><p>再次执行sdscat：</p></blockquote><p>  <img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh6vzveb5xj315k06e0tm.jpg"></p><blockquote><p>过这种预分配策略，SDS将连续增长N次字符串所需的内存重分配次数从必定N次降低为最多N次</p></blockquote><ul><li>2.惰性空间释放</li></ul><p>  惰性空间释放用于优化SDS的字符串缩短操作：当SDS的API需要缩短SDS保存的字符串时，程序并不立即使用内存重分配来回收缩短后多出来的字节，而是使用free属性将这些字节的数量记录起来，并等待将来使用。</p><blockquote><p>执行sdstrim之前:</p></blockquote><p>  <img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh6welfjn7j30u807it9m.jpg"></p><blockquote><p>执行sdstrim之后:</p></blockquote><p>  <img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh6wg7f5aqj3140090jsd.jpg"></p><blockquote><p>再次执行sdscat之后：</p></blockquote><p>  <img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh6wh8yuupj317k08yt9r.jpg"></p><p>  当然SDS也提供了相应的API，让我们可以在有需要时，真正地释放SDS的未使用空间，所以不用担心惰性空间释放策略会造成内存浪费。</p><ul><li>二进制安全</li></ul><p>C字符串中的字符必须符合某种编码（比如ASCII），并且除了字符串的末尾之外，字符串里面不能包含空字符，否则最先被程序读入的空字符将被误认为是字符串结尾，这些限制使得C字符串只能保存文本数据，而不能保存像图片、音频、视频、压缩文件这样的二进制数据  </p><p>为了确保Redis可以适用于各种不同的使用场景，SDS的API都是二进制安全的（binary-safe），所有SDSAPI都会以处理二进制的方式来处理SDS存放在buf数组里的数据也是我们将SDS的buf属性称为字节数组的原因。</p><p>通过使用二进制安全的SDS，而不是C字符串，使得Redis不仅可以保存文本数据，还可以保存任意格式的二进制数据</p><ul><li>C字符串和SDS之间的区别</li></ul><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh6wndju9hj30xg08k77q.jpg"></p><h4 id="SDS-API"><a href="#SDS-API" class="headerlink" title="SDS API"></a>SDS API</h4><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh6wom8r58j30w80msds9.jpg"></p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>1）常数复杂度获取字符串长度。</p><p>2）杜绝缓冲区溢出。</p><p>3）减少修改字符串长度时所需的内存重分配次数。</p><p>4）二进制安全。</p><p>5）兼容部分C字符串函数。</p>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis 基础-数据结构-整数集合</title>
      <link href="2020/07/22/redis-2020-07-22-redis-%E5%9F%BA%E7%A1%80-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%95%B4%E6%95%B0%E9%9B%86%E5%90%88/"/>
      <url>2020/07/22/redis-2020-07-22-redis-%E5%9F%BA%E7%A1%80-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%95%B4%E6%95%B0%E9%9B%86%E5%90%88/</url>
      
        <content type="html"><![CDATA[<h4 id="整数集合定义"><a href="#整数集合定义" class="headerlink" title="整数集合定义:"></a>整数集合定义:</h4><p>整数集合（intset）是Redis用于保存整数值的集合抽象数据结构，它可以保存类型为int16_t、int32_t或者int64_t的整数值，并且保证集合中不会出现重复元素。</p><h4 id="整数集合使用场景"><a href="#整数集合使用场景" class="headerlink" title="整数集合使用场景:"></a>整数集合使用场景:</h4><p>整数集合（intset）是集合键的底层实现之一，当一个集合只包含整数值元素，并且这个集合的元素数量不多时，Redis就会使用整数集合作为集合键的底层实现</p>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis 基础-数据结构-跳跃表</title>
      <link href="2020/07/22/redis-2020-07-22-redis-%E5%9F%BA%E7%A1%80-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E8%B7%B3%E8%B7%83%E8%A1%A8/"/>
      <url>2020/07/22/redis-2020-07-22-redis-%E5%9F%BA%E7%A1%80-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E8%B7%B3%E8%B7%83%E8%A1%A8/</url>
      
        <content type="html"><![CDATA[<h4 id="跳跃表定义"><a href="#跳跃表定义" class="headerlink" title="跳跃表定义:"></a>跳跃表定义:</h4><p>跳跃表（skiplist）是一种有序数据结构，它通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。</p><p>跳跃表支持平均O（logN）、最坏O（N）复杂度的节点查找，还可以通过顺序性操作来批量处理节点。</p><span id="more"></span><h4 id="跳跃表使用场景"><a href="#跳跃表使用场景" class="headerlink" title="跳跃表使用场景:"></a>跳跃表使用场景:</h4><p>Redis使用跳跃表作为有序集合键的底层实现之一，如果一个有序集合包含的元素数量比较多，又或者有序集合中元素的成员（member）是比较长的字符串时，Redis就会使用跳跃表来作为有序集合键的底层实现,<br>和链表、字典等数据结构被广泛地应用在Redis内部不同，Redis只在两个地方用到了跳跃表，一个是实现有序集合键，另一个是在集群节点中用作内部数据结构，除此之外，跳跃表在Redis里面没有其他用途。</p><h4 id="跳跃表构成"><a href="#跳跃表构成" class="headerlink" title="跳跃表构成:"></a>跳跃表构成:</h4><p>Redis的跳跃表由redis.h/zskiplistNode和redis.h/zskiplist两个结构定义。</p><p> zskiplistNode结构用于表示跳跃表节点:</p><ul><li>层（level）：节点中用L1、L2、L3等字样标记节点的各个层，L1代表第一层，L2代表第二层，以此类推。</li></ul><p>  每个层都带有两个属性：前进指针和跨度。前进指针用于访问位于表尾方向的其他节点，而跨度则记录了前进指针所指向节点和当前节点的距离。在上面的图片中，连线上带有数字的箭头就代表前进指针，而那个数字就是跨度。当程序从表头向表尾进行遍历时，访问会沿着层的前进指针进行。</p><ul><li><p>后退（backward）指针：节点中用BW字样标记节点的后退指针，它指向位于当前节点的前一个节点。后退指针在程序从表尾向表头遍历时使用。</p></li><li><p> 分值（score）：各个节点中的1.0、2.0和3.0是节点所保存的分值。在跳跃表中，节点按各自所保存的分值从小到大排列。</p></li><li><p> 成员对象（obj）：各个节点中的o1、o2和o3是节点所保存的成员对象。</p></li></ul><p>zskiplist结构:用于保存跳跃表节点的相关信息，比如节点的数量，以及指向表头节点和表尾节点的指针等等。</p><ul><li><p>header：指向跳跃表的表头节点。</p></li><li><p>tail：指向跳跃表的表尾节点</p></li><li><p>level：记录目前跳跃表内，层数最大的那个节点的层数（表头节点的层数不计算在内）</p></li><li><p>length：记录跳跃表的长度，也即是，跳跃表目前包含节点的数量（表头节点不计算在内</p></li></ul><h4 id="跳跃表展示图"><a href="#跳跃表展示图" class="headerlink" title="跳跃表展示图:"></a>跳跃表展示图:</h4><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh0013kywqj30w40c442f.jpg"></p><h4 id="zskiplistNod-结构详细介绍："><a href="#zskiplistNod-结构详细介绍：" class="headerlink" title="zskiplistNod 结构详细介绍："></a>zskiplistNod 结构详细介绍：</h4><ul><li>结构定义：</li></ul><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh00aw82t7j317s0l041b.jpg"></p><p>跳跃表节点的level数组可以包含多个元素，每个元素都包含一个指向其他节点的指针，程序可以通过这些层来加快访问其他节点的速度，一般来说，层的数量越多，访问其他节点的速度就越快</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh01aoczwpj30yc0c2tcy.jpg">  </p><p>查询遍历过程：</p><ul><li><p>1）迭代程序首先访问跳跃表的第一个节点（表头），然后从第四层的前进指针移动到表中的第二个节点。</p></li><li><p>2）在第二个节点时，程序沿着第二层的前进指针移动到表中的第三个节点。</p></li><li><p>3）在第三个节点时，程序同样沿着第二层的前进指针移动到表中的第四个节点。</p></li><li><p>4）当程序再次沿着第四个节点的前进指针移动时，它碰到一个NULL，程序知道这时已经到达了跳跃表的表尾，于是结束这次遍历。</p></li></ul><p>举个查询例子：</p><p>假如要查询 数值为3.0的位置，从头节点出发遍历到3.0, 沿途经历的层：查找的过程只经过了一个层，并且层的跨度为3，所以目标节点在跳跃表中的位置为3。是不是很快！</p><h4 id="zskiplist-结构详细介绍："><a href="#zskiplist-结构详细介绍：" class="headerlink" title="zskiplist 结构详细介绍："></a>zskiplist 结构详细介绍：</h4><ul><li>结构定义：</li></ul><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh00w61phgj316q0bumyv.jpg"></p><p>通过使用一个zskiplist结构来持有这些节点，程序可以更方便地对整个跳跃表进行处理，比如快速访问跳跃表的表头节点和表尾节点，或者快速地获取跳跃表节点的数量（也即是跳跃表的长度）等信息</p><h4 id="跳跃表常见api"><a href="#跳跃表常见api" class="headerlink" title="跳跃表常见api"></a>跳跃表常见api</h4><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh01ipeqxfj30r80miakt.jpg"></p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><ul><li><p>跳跃表是有序集合的底层实现之一。</p></li><li><p>Redis的跳跃表实现由zskiplist和zskiplistNode两个结构组成，其中zskiplist用于保存跳跃表信息（比如表头节点、表尾节点、长度），而zskiplistNode则用于表示跳跃表节点。</p></li><li><p>每个跳跃表节点的层高都是1至32之间的随机数。</p></li><li><p>在同一个跳跃表中，多个节点可以包含相同的分值，但每个节点的成员对象必须是唯一的。❑跳跃表中的节点按照分值大小进行排序，当分值相同时，节点按照成员对象的大小进行排序。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis 基础-5大对象</title>
      <link href="2020/07/22/redis-2020-07-27-redis-%E5%9F%BA%E7%A1%80-5%E5%A4%A7%E5%AF%B9%E8%B1%A1/"/>
      <url>2020/07/22/redis-2020-07-27-redis-%E5%9F%BA%E7%A1%80-5%E5%A4%A7%E5%AF%B9%E8%B1%A1/</url>
      
        <content type="html"><![CDATA[<h4 id="对象的类型与编码"><a href="#对象的类型与编码" class="headerlink" title="对象的类型与编码:"></a>对象的类型与编码:</h4><p>对象类型-&gt;对象编码-&gt;对象所使用的数据结构</p><p>Redis使用对象来表示数据库中的键和值，每次当我们在Redis的数据库中新创建一个键值对时，我们至少会创建两个对象，一个对象用作键值对的键（键对象），另一个对象用作键值对的值（值对象）</p><p>Redis中的每个对象都由一个redisObject结构表示，该结构中和保存数据有关的三个属性分别是type属性、encoding属性和ptr属性</p><span id="more"></span><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh1aokij6gj31860eumz2.jpg"></p><ul><li>类型</li></ul><p>对象的type属性记录了对象的类型，这个属性的值可以是列出的常量的其中一个。</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh1aqpij1xj30r20h6tdu.jpg"></p><p>一般键是字符串，值是字符串对象、列表对象、哈希对象、集合对象或者有序集合对象的其中一种。</p><p>不同类型值对象的可以通过TYPE命令输出<br><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh1avi4btfj30s20c8q7c.jpg"></p><ul><li>编码和底层实现</li></ul><p>对象的ptr指针指向对象的底层实现数据结构，而这些数据结构由对象的encoding属性决定。</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh1ay5hjl8j30sq0aatbf.jpg"></p><p>使用OBJECT ENCODING命令可以查看一个数据库键的值对象的编码，从而知道对应使用的数据结构。</p><p>通过encoding属性来设定对象所使用的编码，而不是为特定类型的对象关联一种固定的编码，极大地提升了Redis的灵活性和效率，因为Redis可以根据不同的使用场景来为一个对象设置不同的编码，从而优化对象在某一场景下的效率</p><p>举个例子，在列表对象包含的元素比较少时，Redis使用压缩列表作为列表对象的底层实现：</p><p>❑因为压缩列表比双端链表更节约内存，并且在元素数量较少时，在内存中以连续块方式保存的压缩列表比起双端链表可以更快被载入到缓存中；</p><p>❑随着列表对象包含的元素越来越多，使用压缩列表来保存元素的优势逐渐消失时，对象就会将底层实现从压缩列表转向功能更强、也更适合保存大量元素的双端链表上面；其他类型的对象也会通过使用多种不同的编码来进行类似的优化。</p><h4 id="字符串对象"><a href="#字符串对象" class="headerlink" title="字符串对象"></a>字符串对象</h4><p>字符串对象保存的是一个字符串值，并且这个字符串值的长度大于32字节，那么字符串对象将使用一个简单动态字符串（SDS）来保存这个字符串值，并将对象的编码设置为raw，小与32字节编码设置则为embstr。</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh1be9pfucj31640b240y.jpg"></p><ul><li>embstr编码和raw编码对比：</li></ul><p>embstr编码 创建字符串对象分配一次内存，raw编码分配两次内存，同理释放内存也是，且embstr编码的字符串对象在内存上是连续的，更好的利用缓存的优势。</p><ul><li>编码的转换</li></ul><p>embstr编码的字符串对象在执行APPEND命令之后，对象的编码从embstr变为raw</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh1btzg9ssj31fa0ewdi5.jpg"></p><ul><li>字符串命令的实现</li></ul><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh1bv1g61vj30wr0u0wzq.jpg"></p><h4 id="哈希对象"><a href="#哈希对象" class="headerlink" title="哈希对象"></a>哈希对象</h4><p>哈希对象的编码可以是ziplist或者hashtable</p><p>当哈希对象可以同时满足以下两个条件时，哈希对象使用ziplist编码：</p><ul><li><p>哈希对象保存的所有键值对的键和值的字符串长度都小于64字节；</p></li><li><p>哈希对象保存的键值对数量小于512个；不能满足这两个条件的哈希对象需要使用hashtable编码。</p></li></ul><p>举个例子，如果我们执行以下HSET命令，那么服务器将创建一个列表对象作为profile键的值：</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh1ceyr7ezj31fa0c040f.jpg"></p><p>如果profile键的值对象使用的是ziplist编码：</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh1cgljoefj31200jmn16.jpg"></p><p>profile哈希对象的压缩列表底层实现:</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh1chfkv5oj315w06eq4z.jpg"></p><p>如果profile键的值对象使用的是hashtable编码：</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh1cjz4sd9j310y0k8af6.jpg"></p><p>哈希命令的实现：</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh1cm3idw4j30zo0nggxk.jpg"></p><h4 id="列表对象"><a href="#列表对象" class="headerlink" title="列表对象"></a>列表对象</h4><p>列表对象的编码可以是ziplist或者linkedlist</p><p>ziplist编码的列表对象使用压缩列表作为底层实现，每个压缩列表节点（entry）保存了一个列表元素</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh6tcs5jd3j30z20863zu.jpg"></p><p>linkedlist编码的列表对象使用双端链表作为底层实现，每个双端链表节点（node）都保存了一个字符串对象，而每个字符串对象都保存了一个列表元素。</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh6tdx6bicj313w086wgn.jpg"></p><p>StringObject 是字符串对象的简写,完整如下：</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh6tei8lzsj30u404kdgu.jpg"></p><p>当列表对象可以同时满足以下两个条件时，列表对象使用ziplist编码：</p><ul><li><p>列表对象保存的所有字符串元素的长度都小于64字节；</p></li><li><p>列表对象保存的元素数量小于512个；不能满足这两个条件的列表对象需要使用linkedlist编码。</p></li></ul><p>列表命令的实现</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh6tfra0mkj30sa0o2h1l.jpg"></p><h4 id="集合对象"><a href="#集合对象" class="headerlink" title="集合对象"></a>集合对象</h4><p>集合对象的编码可以是intset或者hashtable。</p><p>intset编码的集合对象使用整数集合作为底层实现，集合对象包含的所有元素都被保存在整数集合里面。</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh6tretdeqj30yg08y0uw.jpg"></p><p>hashtable编码的集合对象使用字典作为底层实现，字典的每个键都是一个字符串对象，每个字符串对象包含了一个集合元素，而字典的值则全部被设置为NULL</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh6trr0e0cj30we0ckaeb.jpg"></p><p>集合命令的实现</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh6tu7cmc0j30vw0is7h2.jpg"></p><h4 id="有序集合对象"><a href="#有序集合对象" class="headerlink" title="有序集合对象"></a>有序集合对象</h4><p>有序集合的编码可以是ziplist或者skiplist。</p><p>ziplist编码的压缩列表对象使用压缩列表作为底层实现，每个集合元素使用两个紧挨在一起的压缩列表节点来保存，第一个节点保存元素的成员（member），而第二个元素则保存元素的分值（score）</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh6twum182j310q0eo77q.jpg"></p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh6tx9fbsyj30x204g75r.jpg"></p><p>skiplist编码的有序集合对象使用zset结构作为底层实现，一个zset结构同时包含一个字典和一个跳跃表：</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh6ty5nhk6j318c074wf2.jpg"></p><ul><li>为什么有序集合需要同时使用跳跃表和字典来实现？</li></ul><p>理论上单独使用任何一种结构都可以实现有序集合，但从复杂度来说，<br>单独使用字典实现，虽然查找分值是O(1),但因为字典是无序的,所以排序O(NlogN）复杂度。<br>单独使用跳跃表实现，虽然可以有序，但是查询分值复杂度从O（1）上升为O（logN).</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh6uc2evb0j30xk0gkgqe.jpg"></p><p>有序集合命令的实现</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gh6udkfts7j30xk0pe7jc.jpg"></p>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis 对象 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring5-Reactor函数式编程</title>
      <link href="2020/07/10/kafka-2020-07-10-Spring5-Reactor%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B/"/>
      <url>2020/07/10/kafka-2020-07-10-Spring5-Reactor%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>反应式编程是一种可以替代命令式编程的编程范式。这种可替代性存在的原因在于反应式编程解决了命令式编程中的一些限制。理解这些限制，有助于你更好地理解反应式编程模型的优点</p><span id="more"></span><h3 id="反应式流规范"><a href="#反应式流规范" class="headerlink" title="反应式流规范"></a>反应式流规范</h3><ul><li>对比 Java 中的流</li></ul><p>  Java的流和反应式流Java的流和反应式流之间有很多相似之处。首先，它们的名字中都有流（Stream）这个词。</p><p>  它们还提供了用于处理数据的函数式API。事实上，正如你稍后将会在介绍Reactor时看到的那样，它们甚至可以共享许多相同的操作。</p><p>  Java的流通常都是同步的，并且只能处理有限的数据集。从本质上来说，它们只是使用函数来对集合进行迭代的一种方式。</p><p>  反应式流支持异步处理任意大小的数据集，同样也包括无限数据集。只要数据就绪，它们就能实时地处理数据，并且能够通过回压来避免压垮数据的消费者。</p><ul><li>反应式流规范</li></ul><p>  反应式流规范可以总结为4个接口：Publisher、Subscriber、Subscription和Processor。</p><p>  Publisher负责生成数据，并将数据发送给Subscription（每个Subscriber对应一个Subscription）。</p><p>  Publisher接口声明了一个方法subscribe()，Subscriber可以通过该方法向Publisher发起订阅。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">public interface Publisher&lt;T&gt; &#123;</span><br><span class="line">    void subscribe(Subscriber&lt;? super T&gt; var1);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">public interface Publisher&lt;T&gt; &#123;</span><br><span class="line">    void subscribe(Subscriber&lt;? super T&gt; var1);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public interface Subscriber&lt;T&gt; &#123;</span><br><span class="line">    void onSubscribe(Subscription var1);</span><br><span class="line"></span><br><span class="line">    void onNext(T var1);</span><br><span class="line"></span><br><span class="line">    void onError(Throwable var1);</span><br><span class="line"></span><br><span class="line">    void onComplete();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public interface Subscription &#123;</span><br><span class="line">    void request(long var1);</span><br><span class="line"></span><br><span class="line">    void cancel();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public interface Processor&lt;T, R&gt; extends Subscriber&lt;T&gt;, Publisher&lt;R&gt; &#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="初识Reactor"><a href="#初识Reactor" class="headerlink" title="初识Reactor"></a>初识Reactor</h3><p>Reactor项目是反应式流规范的一个实现，提供了一组用于组装反应式流的函数式API。</p><p>反应式编程要求我们采取和命令式编程不一样的思维方式。此时我们不会再描述每一步要进行的步骤，反应式编程意味着要构建数据将要流经的管道。当数据流经管道时，可以对它们进行某种形式的修改或者使用。</p><p>命令式编程：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">String a &#x3D; &quot;Apple&quot;;</span><br><span class="line">String s &#x3D; a.toUpperCase();</span><br><span class="line">String s1 &#x3D; &quot;hello&quot; + s + &quot;!&quot;;</span><br><span class="line">System.out.println(s1);</span><br></pre></td></tr></table></figure><p>反应式编程：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">  Mono.just(&quot;Apple&quot;)</span><br><span class="line"> .map(String::toUpperCase)</span><br><span class="line"> .map(x-&gt; &quot;hello&quot; + x + &quot;!&quot;)</span><br><span class="line"> .subscribe(System.out::println);</span><br><span class="line"></span><br><span class="line">&#96;&#96;&#96;  </span><br><span class="line">控制台：</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>helloAPPLE!<br>14:36:38.685 [main] DEBUG reactor.util.Loggers$LoggerFactory - Using Slf4j logging framework<br>helloAPPLE!</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">这个例子中的Mono是Reactor的两种核心类型之一，另一个类型是Flux。两者都实现了反应式流的Publisher接口。Flux代表具有零个、一个或者多个（可能是无限个）数据项的管道.</span><br><span class="line"></span><br><span class="line">![](https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;007S8ZIlgy1gglvncheldj31aw0jcai2.jpg)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 添加Reactor依赖</span><br><span class="line"></span><br><span class="line">要开始使用Reactor，请将下面的依赖项添加到项目的构建文件中：</span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>    &lt;!--reactor core--&gt;&lt;dependency&gt;    &lt;groupId&gt;io.projectreactor&lt;/groupId&gt;    &lt;artifactId&gt;reactor-core&lt;/artifactId&gt;&lt;/dependency&gt;    &lt;!--reactor test--&gt;&lt;dependency&gt;    &lt;groupId&gt;io.projectreactor&lt;/groupId&gt;    &lt;artifactId&gt;reactor-test&lt;/artifactId&gt;    &lt;version&gt;3.2.6.RELEASE&lt;/version&gt;    &lt;scope&gt;compile&lt;/scope&gt;&lt;/dependency&gt;    </code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">### 使用常见的反应式操作</span><br><span class="line"></span><br><span class="line">Flux和Mono是Reactor提供的最基础的构建块，而这两种反应式类型所提供的操作符则是组合使用它们以构建数据流动管线的黏合剂。</span><br><span class="line"></span><br><span class="line">Flux和Mono共有500多个操作，这些操作都可以大致归类为：</span><br><span class="line"></span><br><span class="line">•创建操作；</span><br><span class="line"></span><br><span class="line">•组合操作；</span><br><span class="line"></span><br><span class="line">•转换操作；</span><br><span class="line"></span><br><span class="line">•逻辑操作。</span><br><span class="line"></span><br><span class="line">* 1 创建</span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>   Flux&lt;String&gt; fruitFlux = Flux.just(&quot;Apple&quot;,&quot;Orange&quot;);   fruitFlux.subscribe(System.out::println);</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">这里传递给subscribe()方法的lambda表达式实际上是一个java.util.Consumer，用来创建反应式流的Subscriber。在调用subscribe()之后，数据会开始流动。在这个例子中，没有中间操作，所以数据从Flux直接流向订阅者</span><br><span class="line"></span><br><span class="line">要验证预定义的数据是否流经了fruitFlux，我们可以编写如下所示的测试代码：</span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>   StepVerifier.create(fruitFlux)   .expectNext(&quot;Apple&quot;)   .expectNext(&quot;Orange&quot;)   .verifyComplete();</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">在这个例子中，StepVerifier订阅了fruitFlux，然后断言Flux中的每个数据项是否与预期的水果名称相匹配。最后，它验证Flux在发布完“Strawberry”之后，整个fruitFlux正常完成。</span><br><span class="line"></span><br><span class="line">还可以从数组 集合 Java Stream来作为Flux的源。</span><br></pre></td></tr></table></figure><pre><code>  List&lt;String&gt; list = Lists.newArrayList();    list.add(&quot;Apple&quot;);    list.add(&quot;Orange&quot;);    Flux&lt;String&gt; stringFlux = Flux.fromIterable(list);</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">![](https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;007S8ZIlgy1gglweh3r7uj322k0u0ay8.jpg)</span><br><span class="line"></span><br><span class="line">例如，要创建一个每秒发布一个值的Flux，你可以使用Flux上的静态interval() 方法，如下所示：</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>   Flux<Long> take = Flux.interval(Duration.ofSeconds(1)).take(5);</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">通过interval()方法创建的Flux会从0开始发布值，并且后续的条目依次递增。此外，因为interval()方法没有指定最大值，所以它可能会永远运行。我们也可以使用take()方法将结果限制为前5个条目</span><br><span class="line"></span><br><span class="line">* 2 组合反应式类型</span><br><span class="line"></span><br><span class="line">有时候，我们会需要操作两种反应式类型，并以某种方式将它们合并在一起。或者，在其他情况下，我们可能需要将Flux拆分为多种反应式类型</span><br><span class="line"></span><br><span class="line">合并:</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>  Flux<String> fruitFluxA = Flux.just(“Apple”,”Orange”);</p><p>  Flux<String> fruitFluxB = Flux.just(“Banana”,”watermelon”);</p><p>  fruitFluxA.mergeWith(fruitFluxB).subscribe(System.out::println);</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure><p> com.ckj.superlearn.superlearn.base.ReactorStrategy<br>16:03:07.343 [main] DEBUG reactor.util.Loggers$LoggerFactory - Using Slf4j logging framework<br>Apple<br>Orange<br>Banana<br>watermelon</p><p>Process finished with exit code 0</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">![](https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;007S8ZIlgy1gglzay93rfj30xs0esafw.jpg)</span><br><span class="line"></span><br><span class="line">mergeWith()方法不能完美地保证源Flux之间的先后顺序，所以我们可以考虑使用zip()方法</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>  Flux<String> fruitFluxA = Flux.just(“Apple”,”Orange”).delayElements(Duration.ofMillis(10));</p><p>  Flux<String> fruitFluxB = Flux.just(“Banana”,”watermelon”).delayElements(Duration.ofMillis(50));</p><p>  Flux<String> allFlux = fruitFluxA.mergeWith(fruitFluxB);</p><p>  allFlux.subscribe(x-&gt; System.out.println(“allFlux:”+x));</p><p>  Flux&lt;Tuple2&lt;String, String&gt;&gt; zip = Flux.zip(fruitFluxA, fruitFluxB);</p><p>  zip.subscribe(x-&gt; System.out.println(“zip:”+x));</p><p>  Thread.sleep(1000);</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">![](https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;large&#x2F;007S8ZIlgy1gglzc3zljuj312k0fqq76.jpg)</span><br><span class="line"></span><br><span class="line">控制台：</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>/com.ckj.superlearn.superlearn.base.ReactorStrategy<br>16:49:44.543 [main] DEBUG reactor.util.Loggers$LoggerFactory - Using Slf4j logging framework<br>allFlux:Apple<br>allFlux:Orange<br>allFlux:Banana<br>zip:[Apple,Banana]<br>allFlux:watermelon<br>zip:[Orange,watermelon]</p><p>Process finished with exit code 0</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">* 3 转换和过滤反应式流</span><br><span class="line"></span><br><span class="line">针对具有多个数据项的Flux，skip操作将创建一个新的Flux，它会首先跳过指定数量的数据项，然后从源Flux中发布剩余的数据项。下面的测试方法展示如何使用skip()方法：</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>  Flux<String> fruitFluxA = Flux.just(“Apple”,”Orange”,”Banana”,”watermelon”).skip(2);</p><pre><code>fruitFluxA.subscribe(x-&gt;&#123;    System.out.println(x);    &#125;);</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure><p>/com.ckj.superlearn.superlearn.base.ReactorStrategy<br>17:05:00.141 [main] DEBUG reactor.util.Loggers$LoggerFactory - Using Slf4j logging framework<br>Banana<br>watermelon</p><p>Process finished with exit code 0</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">与之对应相反的是take()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p> Flux<String> fruitFluxA = Flux.just(“Apple”,”Orange”,”Banana”,”watermelon”).take(2);</p><pre><code>    fruitFluxA.subscribe(x-&gt;&#123;        System.out.println(x);    &#125;);</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure><p> com.ckj.superlearn.superlearn.base.ReactorStrategy<br>17:20:59.483 [main] DEBUG reactor.util.Loggers$LoggerFactory - Using Slf4j logging framework<br>Apple<br>Orange</p><p>Process finished with exit code 0</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">filter()的过滤效果</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>  Flux<String> fruitFluxA = Flux.just(“Apple”,”Orange”,”Banana”,”watermelon”).take(2);</p><p>  fruitFluxA.filter(x-&gt;x.equals(“Apple”)).subscribe(x-&gt;{</p><pre><code> System.out.println(x); &#125;);</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure><p>com.ckj.superlearn.superlearn.base.ReactorStrategy<br>17:24:03.242 [main] DEBUG reactor.util.Loggers$LoggerFactory - Using Slf4j logging framework<br>Apple</p><p>Process finished with exit code 0</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">如何使用flatMap()方法和subscribeOn()方法</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>  Flux<String> fruitFluxA = Flux.just(“Apple”, “Orange”, “Banana”, “watermelon”, “Apple”, “Orange”, “Banana”,<br>                “watermelon”, “Apple”, “Orange”, “Banana”, “watermelon”, “Apple”, “Orange”, “Banana”, “watermelon”);</p><p>   fruitFluxA.flatMap(Mono::just).map(String::toUpperCase).subscribeOn(Schedulers.parallel());</p><pre><code>![](https://tva1.sinaimg.cn/large/007S8ZIlgy1ggm1rjb3naj31580kgguh.jpg)使用flatMap()和subscribeOn()的好处是：我们可以在多个并行线程之间拆分工作，从而增加流的吞吐量。因为工作是并行完成的，无法保证哪项工作首先完成，所以结果Flux中数据项的发布顺序是未知的  &gt; 原创不易，如果觉得有点用的话，请毫不留情点个赞，转发一下，这将是我持续输出优质文章的最强动力。</code></pre>]]></content>
      
      
      <categories>
          
          <category> Spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入了解kafka系列-主题</title>
      <link href="2020/07/03/kafka-2020-07-03-%E6%B7%B1%E5%85%A5%E4%BA%86%E8%A7%A3kafka%E7%B3%BB%E5%88%97-%E4%B8%BB%E9%A2%98/"/>
      <url>2020/07/03/kafka-2020-07-03-%E6%B7%B1%E5%85%A5%E4%BA%86%E8%A7%A3kafka%E7%B3%BB%E5%88%97-%E4%B8%BB%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><blockquote><p>主题和分区是Kafka 的两个核心概念，前面系列中讲述的生产者和消费者的设计理念所针对的都是主题和分区层面的操作。主题作为消息的归类，可以再细分为一个或多个分区，分区也可以看作对消息的二次归类。分区的划分不仅为Kafka提供了可伸缩性、水平扩展的功能，还通过多副本机制来为Kafka提供数据冗余以提高数据可靠性。</p></blockquote><p>从Kafka的底层实现来说，主题和分区都是逻辑上的概念，分区可以有一至多个副本，每个副本对应一个日志文件，每个日志文件对应一至多个日志分段（LogSegment），每个日志分段还可以细分为索引文件、日志存储文件和快照文件等。不过对于使用Kafka进行消息收发的普通用户而言，了解到分区这一层面足以应对大部分的使用场景,这里暂时只说到主题和分区,更底层的内容会在后续这个系列持续讲解~</p><span id="more"></span><h3 id="主题的管理"><a href="#主题的管理" class="headerlink" title="主题的管理"></a>主题的管理</h3><p>主题的管理包括创建主题、查看主题信息、修改主题和删除主题等操作。可以通过 Kafka提供的 kafka-topics.sh脚本来执行这些操作，这个脚本位于$KAFKA_HOME/bin/目录下，其核心代码仅有一行，具体如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">exec $(dirname $0)&#x2F;kafka-run-class.sh kafka.admin.TopicCommand &quot;$@&quot;</span><br></pre></td></tr></table></figure><p>当然主题的管理并非只有使用 kafka-topics.sh 脚本这一种方式，我们还可以通过KafkaAdminClient 的方式实现（这种方式实质上是通过发送 CreateTopicsRequest、DeleteTopicsRequest 等请求来实现的,甚至我们还可以通过直接操纵日志文件和ZooKeeper节点来实现,这个后续我会单独抽出来放在这个系列继续讲解~</p><ul><li>1 创建主题</li></ul><p> 如果broker端配置参数auto.create.topics.enable设置为true（默认值就是true），那么当生产者向一个尚未创建的主题发送消息时，会自动创建一个分区数为num.partitions （默认值为1）、副本因子为default.replication.factor（默认值为1）的主题。不建议这样操作,topic 未知难以维护,建议下面这种方式:</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-topics.sh --create --zookeeper localhost:2181&#x2F;kafka100 --topic topic-create --replication-factor 2 --partitions 4</span><br></pre></td></tr></table></figure><p> 上面的示例中创建了一个分区数为 4、副本因子为 2 的主题.</p><p> 三个broker节点一共创建了8个文件夹，这个数字8实质上是分区数4与副本因子2的乘积。每个副本（或者更确切地说应该是日志，副本与日志一一对应）才真正对应了一个命名形式如＜topic＞-＜partition＞的文件夹。主题、分区、副本和 Log（日志）的关系如图所示</p><p> <img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gghbnbj175j30wi082adz.jpg"></p><p>同一个分区中的多个副本必须分布在不同的broker中，这样才能提供有效的数据冗余。对于示例中的分区数为4、副本因子为2、broker数为3的情况下，按照2、3、3的分区副本个数分配给各个broker是最优的选择。再比如在分区数为3、副本因子为3，并且broker数同样为3的情况下，分配3、3、3的分区副本个数给各个broker是最优的选择，也就是每个broker中都拥有所有分区的一个副本。</p><ul><li>2 分区副本的分配</li></ul><p>这里的分区分配是指为集群制定创建主题时的分区副本分配方案，即在哪个broker中创建哪些分区的副本<br>在创建主题时，如果使用了replica-assignment参数，那么就按照指定的方案来进行分区副本的创建；如果没有使用replica-assignment参数，那么就需要按照内部的逻辑来计算分配方案了。使用kafka-topics.sh脚本创建主题时的内部分配逻辑按照机架信息划分成两种策略：未指定机架信息和指定机架信息。如果集群中所有的 broker节点都没有配置broker.rack参数，或者使用disable-rack-aware参数来创建主题，那么采用的就是未指定机架信息的分配策略，否则采用的就是指定机架信息的分配策略</p><ul><li>3 查看主题</li></ul><p>kafka-topics.sh脚本有5种指令类型：create、list、describe、alter和delete。其中list和describe指令可以用来方便地查看主题信息,通过list指令可以查看当前所有可用的主题，示例如下:<br> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-topics.sh --zookeeper localhost:2181 --list</span><br></pre></td></tr></table></figure><br> 查看指定topic信息<br> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-topics.sh --zookeeper localhost:2181 --describe --topic topic-create</span><br></pre></td></tr></table></figure></p><ul><li>4 修改主题</li></ul><p>当一个主题被创建之后，依然允许我们对其做一定的修改，比如修改分区个数、修改配置等，这个修改的功能就是由kafka-topics.sh脚本中的alter指令提供的。我们首先来看如何增加主题的分区数。以前面的主题topic-config为例，当前分区数为1，修改为3，示例如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># bin&#x2F;kafka-topics.sh --zookeeper localhost:2181&#x2F;kafka --alter --topic topic-config --partitions 3</span><br><span class="line">WARNING: If partitions are increased for a topic that has a key, the partition logic or ordering of the messages will be affected</span><br><span class="line">Adding partitions succeeded!</span><br><span class="line"> </span><br><span class="line"># bin&#x2F;kafka-topics.sh --zookeeper localhost:2181&#x2F;kafka --describe --topic topic-create</span><br><span class="line">Topic:topic-config    PartitionCount:3  ReplicationFactor:1   Configs:</span><br><span class="line">Topic: topic-config    Partition: 0 Leader: 2    Replicas: 2  Isr: 2</span><br><span class="line">Topic: topic-config    Partition: 1 Leader: 0    Replicas: 0  Isr: 0</span><br><span class="line">Topic: topic-config    Partition: 2 Leader: 1    Replicas: 1  Isr: 1</span><br></pre></td></tr></table></figure><p>当主题中的消息包含key时（即key不为null），根据key计算分区的行为就会受到影响,对于基于key计算的主题而言，建议在一开始就设置好分区数量，避免以后对其进行调整。目前Kafka只支持增加分区数而不支持减少分区数.</p><ul><li>5 删除主题</li></ul><p>如果确定不再使用一个主题，那么最好的方式是将其删除，这样可以释放一些资源，比如磁盘、文件句柄等。kafka-topics.sh脚本中的delete指令就可以用来删除主题，比如删除一个主题topic-delete.</p><h3 id="初识KafkaAdminClient"><a href="#初识KafkaAdminClient" class="headerlink" title="初识KafkaAdminClient"></a>初识KafkaAdminClient</h3><p>一般情况下，我们都习惯使用kafka-topics.sh脚本来管理主题，但有时候我们希望将主题管理类的功能集成到公司内部的系统中，打造集管理、监控、运维、告警为一体的生态平台.</p><p>KafkaAdminClient继承了org.apache.kafka.clients.admin.AdminClient抽象类，并提供了多种方法。篇幅限制，下面只列出与本章内容相关的一些方法。</p><ul><li> 创建主题：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CreateTopicsResult createTopics（Collection＜NewTopic＞newTopics）</span><br></pre></td></tr></table></figure><ul><li> 删除主题：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DeleteTopicsResult deleteTopics（Collection＜String＞topics）。</span><br></pre></td></tr></table></figure><ul><li> 列出所有可用的主题：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ListTopicsResult listTopics（）。</span><br></pre></td></tr></table></figure><ul><li> 查看主题的信息：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DescribeTopicsResult describeTopics（Collection＜String＞topicNames）</span><br></pre></td></tr></table></figure><ul><li> 查询配置信息：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DescribeConfigsResult describeConfigs（Collection＜ConfigResource＞resources）</span><br></pre></td></tr></table></figure><ul><li>修改配置信息：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AlterConfigsResult alterConfigs（Map＜ConfigResource，Config＞configs）</span><br></pre></td></tr></table></figure><ul><li>增加分区：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CreatePartitionsResult createPartitions（Map＜String，NewPartitions＞newPartitions）</span><br></pre></td></tr></table></figure><blockquote><p>原创不易，如果觉得有点用的话，请毫不留情点个赞，转发一下，这将是我持续输出优质文章的最强动力。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入了解kafka系列-生产者</title>
      <link href="2020/07/01/kafka-2020-06-30-%E6%B7%B1%E5%85%A5%E4%BA%86%E8%A7%A3kafka%E7%B3%BB%E5%88%97-%E7%94%9F%E4%BA%A7%E8%80%85/"/>
      <url>2020/07/01/kafka-2020-06-30-%E6%B7%B1%E5%85%A5%E4%BA%86%E8%A7%A3kafka%E7%B3%BB%E5%88%97-%E7%94%9F%E4%BA%A7%E8%80%85/</url>
      
        <content type="html"><![CDATA[<h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><blockquote><p>整个Kafka体系结构中引入了以下3个术语。</p></blockquote><p> （1）Producer：生产者，也就是发送消息的一方。生产者负责创建消息，然后将其投递到Kafka中。</p><p> （2）Consumer：消费者，也就是接收消息的一方。消费者连接到Kafka上并接收消息，进而进行相应的业务逻辑处理。</p><span id="more"></span><p> （3）Broker：服务代理节点。对于Kafka而言，Broker可以简单地看作一个独立的Kafka服务节点或Kafka服务实例。大多数情况下也可以将Broker看作一台Kafka服务器，前提是这台服务器上只部署了一个Kafka实例。一个或多个Broker组成了一个Kafka集群。一般而言，我们更习惯使用首字母小写的broker来表示服务代理节点。</p><p>  在Kafka中还有两个特别重要的概念—主题（Topic）与分区（Partition）。Kafka中的消息以主题为单位进行归类，生产者负责将消息发送到特定的主题（发送到Kafka集群中的每一条消息都要指定一个主题），而消费者负责订阅主题并进行消费。</p><p>  主题是一个逻辑上的概念，它还可以细分为多个分区，一个分区只属于单个主题，很多时候也会把分区称为主题分区（Topic-Partition）。同一主题下的不同分区包含的消息是不同的，分区在存储层面可以看作一个可追加的日志（Log）文件，消息在被追加到分区日志文件的时候都会分配一个特定的偏移量（offset）。offset是消息在分区中的唯一标识，Kafka通过它来保证消息在分区内的顺序性，不过offset并不跨越分区，也就是说，Kafka保证的是分区有序而不是主题有序。如图所示，主题中有 4 个分区，消息被顺序追加到每个分区日志文件的尾部。Kafka中的分区可以分布在不同的服务器（broker）上，也就是说，一个主题可以横跨多个broker，以此来提供比单个broker更强大的性能。</p><p>  <img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ggao5l941cj30u00km0zz.jpg"></p><h3 id="生产者"><a href="#生产者" class="headerlink" title="生产者"></a>生产者</h3><blockquote><p>消息在真正发往Kafka之前，有可能需要经历拦截器（Interceptor）、序列化器（Serializer）和分区器（Partitioner）等一系列的作用，那么在此之后又会发生什么呢？下面我们来看一下生产者客户端的整体架构.</p></blockquote><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ggall9855yj30wk0qsh18.jpg"></p><h4 id="producer-流程："><a href="#producer-流程：" class="headerlink" title="producer 流程："></a>producer 流程：</h4><p>  整个生产者客户端由两个线程协调运行，这两个线程分别为主线程和Sender线程（发送线程）。</p><p>  在主线程中由KafkaProducer创建消息，然后通过可能的拦截器、序列化器和分区器的作用之后缓存到消息累加器（RecordAccumulator，也称为消息收集器）中。</p><p>  Sender 线程负责从RecordAccumulator中获取消息并将其发送到Kafka中。</p><h4 id="主线程"><a href="#主线程" class="headerlink" title="主线程"></a>主线程</h4><p>   <font color=#C7063  size=3>生产者拦截器</font> 可以用来在消息发送前做一些准备工作，比如按照某个规则过滤不符合要求的消息、修改消息的内容等，也可以用来在发送回调逻辑前做一些定制化的需求，比如统计类工作。生产者拦截器的使用也很方便，主要是自定义实现 org.apache.kafka.clients.producer.ProducerInterceptor接口。ProducerInterceptor接口中包含3个方法<br><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ggaombbbfoj31bk0u0ncu.jpg"></p><p>KafkaProducer() 在将消息序列化和计算分区之前会调用生产者拦截器的onSend（）方法来对消息进行相应的定制化操作。</p><p>KafkaProducer() 在消息被应答（Acknowledgement）之前或消息发送失败时调用生产者拦截器的onAcknowledgement（）方法，优先于用户设定的 Callback 之前执行。</p><p>close() 主要用于在关闭拦截器时执行一些资源的清理工作。在这 3 个方法中抛出的异常都会被捕获并记录到日志中，但并不会再向上传递。</p><p>  <font color=#C7063  size=3>序列化器</font> 生产者需要用序列化器（Serializer) 把对象转换成字节数组才能通过网络发送给Kafka，消费者需要用反序列化器（Deserializer）把从 Kafka 中收到的字节数组转换成相应的对象,Serializer接口中包含3个方法</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ggapcp91uuj31tq0qg113.jpg"></p><p>configure() 方法用来配置当前类</p><p>serialize() 方法用来执行序列化操作</p><p>close() 方法用来关闭当前的序列化器，一般情况下 close（）是一个空方法，如果实现了此方法，则必须确保此方法的幂等性，因为这个方法很可能会被KafkaProducer调用多次。</p><p><font color=#C7063  size=3>分区器</font> 分区器的作用就是为消息分配分区。序列化器是必需的。消息经过序列化之后就需要确定它发往的分区，如果消息ProducerRecord中指定了partition字段，那么就不需要分区器的作用，因为partition代表的就是所要发往的分区号。</p><h4 id="消息累加器-RecordAccumulator"><a href="#消息累加器-RecordAccumulator" class="headerlink" title="消息累加器 RecordAccumulator"></a>消息累加器 RecordAccumulator</h4><p> RecordAccumulator 主要用来缓存消息以便 Sender 线程可以批量发送，进而减少网络传输的资源消耗以提升性能。RecordAccumulator 缓存的大小可以通过生产者客户端参数buffer.memory 配置，默认值为 32MB。<br>  如果生产者发送消息的速度超过发送到服务器的速度，则会导致生产者空间不足，这个时候KafkaProducer的send（）方法调用要么被阻塞，要么抛出异常，这个取决于参数max.block.ms的配置，此参数的默认值为60000，即60秒。</p><p> 主线程中发送过来的消息都会被追加到RecordAccumulator的某个双端队列（Deque）中，在RecordAccumulator 的内部为每个分区都维护了一个双端队列，队列中的内容就是ProducerBatch，即 Deque＜ProducerBatch＞。消息写入缓存时，追加到双端队列的尾部；Sender读取消息时，从双端队列的头部读取。注意ProducerBatch不是ProducerRecord，ProducerBatch中可以包含一至多个 ProducerRecord。</p><p> 通俗地说，ProducerRecord 是生产者中创建的消息，而ProducerBatch是指一个消息批次，ProducerRecord会被包含在ProducerBatch中，这样可以使字节的使用更加紧凑。与此同时，将较小的ProducerRecord拼凑成一个较大的ProducerBatch,也可以减少网络请求的次数以提升整体的吞吐量</p><h4 id="sender-线程"><a href="#sender-线程" class="headerlink" title="sender 线程"></a>sender 线程</h4><p> Sender 从 RecordAccumulator 中获取缓存的消息之后，会进一步将原本＜分区，Deque＜ProducerBatch＞＞的保存形式转变成＜Node，List＜ ProducerBatch＞的形式，其中Node表示Kafka集群的broker节点,Sender 还会进一步封装成＜Node，Request＞的形式，这样就可以将Request请求发往各个Node了，这里的Request是指Kafka的各种协议请求,请求在从Sender线程发往Kafka之前还会保存到InFlightRequests中，InFlightRequests保存对象的具体形式为Map＜NodeId，Deque＜Request＞＞<br> 它的主要作用是缓存了已经发出去但还没有收到响应的请求（NodeId 是一个 String 类型，表示节点的 id 编号)。</p><blockquote><p>原创不易，如果觉得有点用的话，请毫不留情点个赞，转发一下，这将是我持续输出优质文章的最强动力。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>zookeeper 安装教程</title>
      <link href="2020/06/29/kafka-2020-06-29-zookeeper-mac%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/"/>
      <url>2020/06/29/kafka-2020-06-29-zookeeper-mac%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h3 id="brew安装"><a href="#brew安装" class="headerlink" title="brew安装"></a>brew安装</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install zookeeper</span><br></pre></td></tr></table></figure><span id="more"></span><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&#x3D;&#x3D;&gt; Downloading https:&#x2F;&#x2F;homebrew.bintray.com&#x2F;bottles&#x2F;zookeeper-3.4.13.mojave.bottle.tar.gz</span><br><span class="line">&#x3D;&#x3D;&gt; Downloading from https:&#x2F;&#x2F;akamai.bintray.com&#x2F;d1&#x2F;d1e4e7738cd147dceb3d91b32480c20ac5da27d129905f336ba51c0c01b8a476?__gd</span><br><span class="line">######################################################################## 100.0%</span><br><span class="line">&#x3D;&#x3D;&gt; Pouring zookeeper-3.4.13.mojave.bottle.tar.gz</span><br><span class="line">&#x3D;&#x3D;&gt; Caveats</span><br><span class="line">To have launchd start zookeeper now and restart at login:</span><br><span class="line">  brew services start zookeeper</span><br><span class="line">Or, if you don&#39;t want&#x2F;need a background service you can just run:</span><br><span class="line">  zkServer start</span><br><span class="line">&#x3D;&#x3D;&gt; Summary</span><br><span class="line">🍺  &#x2F;usr&#x2F;local&#x2F;Cellar&#x2F;zookeeper&#x2F;3.4.13: 244 files, 33.4MB</span><br></pre></td></tr></table></figure><p>查看zookeeper 信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">brew info zookeeper</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">zookeeper: stable 3.4.13 (bottled), HEAD</span><br><span class="line">Centralized server for distributed coordination of services</span><br><span class="line">https:&#x2F;&#x2F;zookeeper.apache.org&#x2F;</span><br><span class="line">&#x2F;usr&#x2F;local&#x2F;Cellar&#x2F;zookeeper&#x2F;3.4.13 (244 files, 33.4MB) *</span><br><span class="line">  Poured from bottle on 2020-06-30 at 17:51:47</span><br><span class="line">From: https:&#x2F;&#x2F;github.com&#x2F;Homebrew&#x2F;homebrew-core&#x2F;blob&#x2F;master&#x2F;Formula&#x2F;zookeeper.rb</span><br><span class="line">&#x3D;&#x3D;&gt; Options</span><br><span class="line">--HEAD</span><br><span class="line">Install HEAD version</span><br><span class="line">&#x3D;&#x3D;&gt; Caveats</span><br><span class="line">To have launchd start zookeeper now and restart at login:</span><br><span class="line">  brew services start zookeeper</span><br><span class="line">Or, if you don&#39;t want&#x2F;need a background service you can just run:</span><br><span class="line">  zkServer start</span><br><span class="line">&#x3D;&#x3D;&gt; Analytics</span><br><span class="line">install: 7,043 (30 days), 21,263 (90 days), 79,252 (365 days)</span><br><span class="line">install_on_request: 2,192 (30 days), 6,831 (90 days), 25,814 (365 days)</span><br><span class="line">build_error: 0 (30 days)</span><br></pre></td></tr></table></figure><p>brew nstall 完成之后 对应配置如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&#x2F;usr&#x2F;local&#x2F;etc&#x2F;zookeeper</span><br><span class="line">chengkejundeMacBook-Pro:zookeeper c.kj$ ls</span><br><span class="line">defaultslog4j.propertieszoo.cfgzoo_sample.cfg</span><br><span class="line">chengkejundeMacBook-Pro:zookeeper c.kj$</span><br></pre></td></tr></table></figure><p>修改 zoo.cfg 搭建集群修改这些配置 因为只需要搭建一个伪集群所以没有修改其中参数，感兴趣的可以自己搜索一些教程～</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># The number of milliseconds of each tick</span><br><span class="line">tickTime&#x3D;2000</span><br><span class="line"># The number of ticks that the initial</span><br><span class="line"># synchronization phase can take</span><br><span class="line">initLimit&#x3D;10</span><br><span class="line"># The number of ticks that can pass between</span><br><span class="line"># sending a request and getting an acknowledgement</span><br><span class="line">syncLimit&#x3D;5</span><br><span class="line"># the directory where the snapshot is stored.</span><br><span class="line"># do not use &#x2F;tmp for storage, &#x2F;tmp here is just</span><br><span class="line"># example sakes.</span><br><span class="line">dataDir&#x3D;&#x2F;usr&#x2F;local&#x2F;Cellar&#x2F;zookeeper&#x2F;data</span><br><span class="line"># the port at which the clients will connect</span><br><span class="line">clientPort&#x3D;2181</span><br><span class="line"># the maximum number of client connections.</span><br><span class="line"># increase this if you need to handle more clients</span><br><span class="line">#maxClientCnxns&#x3D;60</span><br><span class="line">#</span><br><span class="line"># Be sure to read the maintenance section of the</span><br><span class="line"># administrator guide before turning on autopurge.</span><br><span class="line">#</span><br><span class="line"># http:&#x2F;&#x2F;zookeeper.apache.org&#x2F;doc&#x2F;current&#x2F;zookeeperAdmin.html#sc_maintenance</span><br><span class="line">#</span><br><span class="line"># The number of snapshots to retain in dataDir</span><br><span class="line">#autopurge.snapRetainCount&#x3D;3</span><br><span class="line"># Purge task interval in hours</span><br><span class="line"># Set to &quot;0&quot; to disable auto purge feature</span><br><span class="line">#autopurge.purgeInterval&#x3D;1</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>为了能够在任意目录启动zookeeper集群，我们需要配置环境变量.<br> <br> ps:你也可以不配，这不是搭建集群的必要操作，只不过如果你不配置环境变量，那么每次启动zookeeper需要到安装文件的 bin 目录下去启动。<br> <br> 配置如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">chengkejundeMacBook-Pro:data c.kj$ open -e ~&#x2F;.bash_profile</span><br><span class="line">chengkejundeMacBook-Pro:data c.kj$ cat ~&#x2F;.bash_profile</span><br><span class="line">export M3_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;mvn&#x2F;apache-maven-3.3.9</span><br><span class="line">export GRADLE_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;Cellar&#x2F;gradle&#x2F;5.2.1</span><br><span class="line">export SCALA_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;Cellar&#x2F;scala&#x2F;2.12.8</span><br><span class="line">export ZK_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;Cellar&#x2F;zookeeper&#x2F;3.4.13</span><br><span class="line">export PATH&#x3D;$M3_HOME&#x2F;bin:$PATH:$GRADLE_HOME&#x2F;bin:$SCALA_HOME&#x2F;bin:$ZK_HOME&#x2F;binchengkejundeMacBook-Pro:data c.kj$</span><br><span class="line">chengkejundeMacBook-Pro:data c.kj$</span><br><span class="line">chengkejundeMacBook-Pro:data c.kj$ source ~&#x2F;.bash_profile</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>启动命令：<br><code>zkServer start</code></p><p>停止命令：<br><code>zkServer stop</code></p><p>重启命令：<br><code>zkServer restart</code></p><p>查看集群节点状态：<br><code>zkServer status</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">chengkejundeMacBook-Pro:~ c.kj$ zkServer start</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: &#x2F;usr&#x2F;local&#x2F;etc&#x2F;zookeeper&#x2F;zoo.cfg</span><br><span class="line">Starting zookeeper ... already running as process 49422.</span><br><span class="line">chengkejundeMacBook-Pro:~ c.kj$ zkServer status</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: &#x2F;usr&#x2F;local&#x2F;etc&#x2F;zookeeper&#x2F;zoo.cfg</span><br><span class="line">Mode: standalone</span><br><span class="line">chengkejundeMacBook-Pro:~ c.kj$</span><br></pre></td></tr></table></figure><p>end ~</p>]]></content>
      
      
      <categories>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> zookeeper </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入了解kafka系列-消费者</title>
      <link href="2020/06/29/kafka-2020-06-31-%E6%B7%B1%E5%85%A5%E4%BA%86%E8%A7%A3kafka%E7%B3%BB%E5%88%97-%E6%B6%88%E8%B4%B9%E8%80%85/"/>
      <url>2020/06/29/kafka-2020-06-31-%E6%B7%B1%E5%85%A5%E4%BA%86%E8%A7%A3kafka%E7%B3%BB%E5%88%97-%E6%B6%88%E8%B4%B9%E8%80%85/</url>
      
        <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><blockquote><p>与生产者对应的是消费者，应用程序可以通过KafkaConsumer来订阅主题，并从订阅的主题中拉取消息。不过在使用KafkaConsumer消费消息之前需要先了解消费者和消费组的概念，否则无法理解如何使用KafkaConsumer。</p></blockquote><span id="more"></span><h3 id="Consumer"><a href="#Consumer" class="headerlink" title="Consumer"></a>Consumer</h3><ul><li> 消费者（Consumer）负责订阅Kafka中的主题（Topic），并且从订阅的主题上拉取消息。与其他一些消息中间件不同的是：在Kafka的消费理念中还有一层消费组（Consumer Group）的概念，每个消费者都有一个对应的消费组。</li></ul><p>   当消息发布到主题后，只会被投递给订阅它的每个消费组中的一个消费者。如图所示，某个主题中共有4个分区（Partition）：P0、P1、P2、P3。有两个消费组A和B都订阅了这个主题，消费组A中有4个消费者（C0、C1、C2和C3），消费组B中有2个消费者（C4和C5）。按照Kafka默认的规则，最后的分配结果是消费组A中的每一个消费者分配到1个分区，消费组B中的每一个消费者分配到2个分区，两个消费组之间互不影响。每个消费者只能消费所分配到的分区中的消息。换言之，每一个分区只能被一个消费组中的一个消费者所消费。</p><p>   <img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ggcvc5xbflj30vw0fu45f.jpg"></p><h3 id="分区分配的演变（Rebalance）"><a href="#分区分配的演变（Rebalance）" class="headerlink" title="分区分配的演变（Rebalance）"></a>分区分配的演变（Rebalance）</h3><p>   我们再来看一下消费组内的消费者个数变化时所对应的分区分配的演变。假设目前某消费组内只有一个消费者C0，订阅了一个主题，这个主题包含 7 个分区：P0、P1、P2、P3、P4、P5、P6。也就是说，这个消费者C0订阅了7个分区，具体分配情形如图。</p><p>   <img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ggcw1dy1irj30v00n478h.jpg"></p><p>   消费者与消费组此时消费组内又加入了一个新的消费者C1，按照既定的逻辑，需要将原来消费者C0的部分分区分配给消费者C1消费，如下图所示。消费者C0和C1各自负责消费所分配到的分区，彼此之间并无逻辑上的干扰。</p><p>   <img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ggcw48m6p6j30w40nq0x8.jpg"></p><p>   紧接着消费组内又加入了一个新的消费者C2，消费者C0、C1和C2按照下图方式各自负责消费所分配到的分区。</p><p>   <img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ggcw48m6p6j30w40nq0x8.jpg"></p><p>   消费者与消费组这种模型可以让整体的消费能力具备横向伸缩性，我们可以增加（或减少）消费者的个数来提高（或降低）整体的消费能力。对于分区数固定的情况，一味地增加消费者并不会让消费能力一直得到提升，如果消费者过多，出现了消费者的个数大于分区个数的情况，就会有消费者分配不到任何分区。参考图如下，一共有8个消费者，7个分区，那么最后的消费者C7由于分配不到任何分区而无法消费任何消息。   </p><p>   <img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ggcwbn8b1mj30vg0hudje.jpg"></p><h3 id="投递模式"><a href="#投递模式" class="headerlink" title="投递模式"></a>投递模式</h3><p>   以上分配逻辑都是基于默认的分区分配策略进行分析的，可以通过消费者客户端参数partition.assignment.strategy 来设置消费者与订阅主题之间的分区分配策略，有关分区分配的更多细节可以再接下来的系列继续聊。</p><p>   对于消息中间件而言，一般有两种消息投递模式：</p><p>   点对点（P2P，Point-to-Point）模式:  点对点模式是基于队列的，消息生产者发送消息到队列，消息消费者从队列中接收消息。</p><p>   发布/订阅（Pub/Sub）模式: 发布订阅模式定义了如何向一个内容节点发布和订阅消息，这个内容节点称为主题（Topic），主题可以认为是消息传递的中介，消息发布者将消息发布到某个主题，而消息订阅者从主题中订阅消息。主题使得消息的订阅者和发布者互相保持独立，不需要进行接触即可保证消息的传递，发布/订阅模式在消息的一对多广播时采用。</p><p>   Kafka 同时支持两种消息投递模式，而这正是得益于消费者与消费组模型的契合：</p><ul><li>如果所有的消费者都隶属于同一个消费组，那么所有的消息都会被均衡地投递给每一个消费者，即每条消息只会被一个消费者处理，这就相当于点对点模式的应用。</li><li> 如果所有的消费者都隶属于不同的消费组，那么所有的消息都会被广播给所有的消费者，即每条消息会被所有的消费者处理，这就相当于发布/订阅模式的应用</li></ul><p>   消费组是一个逻辑上的概念，它将旗下的消费者归为一类，每一个消费者只隶属于一个消费组。每一个消费组都会有一个固定的名称，消费者在进行消费前需要指定其所属消费组的名称，这个可以通过消费者客户端参数group.id来配置，默认值为空字符串。消费者并非逻辑上的概念，它是实际的应用实例，它可以是一个线程，也可以是一个进程。同一个消费组内的消费者既可以部署在同一台机器上，也可以部署在不同的机器上。</p><h3 id="创建一个Kafka消费者"><a href="#创建一个Kafka消费者" class="headerlink" title="创建一个Kafka消费者"></a>创建一个Kafka消费者</h3><ul><li>以下代码段显示了如何创建KafkaConsumer：</li></ul>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Properties props &#x3D; new Properties();</span><br><span class="line">  props.put(&quot;bootstrap.servers&quot;, &quot;broker1:9092,broker2:9092&quot;);</span><br><span class="line">  props.put(&quot;group.id&quot;, &quot;CountryCounter&quot;);</span><br><span class="line">  props.put(&quot;key.deserializer&quot;,</span><br><span class="line">      &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);</span><br><span class="line">  props.put(&quot;value.deserializer&quot;,</span><br><span class="line">      &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);</span><br><span class="line">  </span><br><span class="line">  KafkaConsumer&lt;String, String&gt; consumer &#x3D;</span><br><span class="line">      new KafkaConsumer&lt;String, String&gt;(props);</span><br></pre></td></tr></table></figure><ul><li>订阅主题</li></ul>   <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">consumer.subscribe(Collections.singletonList(&quot;customerCountries&quot;));</span><br></pre></td></tr></table></figure><ul><li>要订阅所有test主题，我们可以：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">consumer.subscribe(Pattern.compile(&quot;test.*&quot;));</span><br></pre></td></tr></table></figure><ul><li>轮询循环</li></ul><p>   消费者API的核心是一个简单的循环，用于轮询服务器以获取更多数据。<br>   一旦用户订阅了主题，轮询循环便会处理协调，分区重新平衡，心跳和数据获取的所有详细信息，从而为开发人员提供了一个干净的API，该API仅从分配的分区中返回可用数据。<br>   消费者的主体如下所示</p>   <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">try &#123;</span><br><span class="line">    while (true) &#123; 1</span><br><span class="line">        ConsumerRecords&lt;String, String&gt; records &#x3D; consumer.poll(100); 2</span><br><span class="line">        for (ConsumerRecord&lt;String, String&gt; record : records) 3</span><br><span class="line">        &#123;</span><br><span class="line">            log.debug(&quot;topic &#x3D; %s, partition &#x3D; %d, offset &#x3D; %d,&quot;</span><br><span class="line">                customer &#x3D; %s, country &#x3D; %s\n&quot;,</span><br><span class="line">                record.topic(), record.partition(), record.offset(),</span><br><span class="line">                record.key(), record.value());</span><br><span class="line"></span><br><span class="line">            int updatedCount &#x3D; 1;</span><br><span class="line">            if (custCountryMap.countainsKey(record.value())) &#123;</span><br><span class="line">                updatedCount &#x3D; custCountryMap.get(record.value()) + 1;</span><br><span class="line">            &#125;</span><br><span class="line">            custCountryMap.put(record.value(), updatedCount)</span><br><span class="line"></span><br><span class="line">            JSONObject json &#x3D; new JSONObject(custCountryMap);</span><br><span class="line">            System.out.println(json.toString(4)) 4</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125; finally &#123;</span><br><span class="line">    consumer.close(); 5</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>反序列化</li></ul>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">public class StringDeserializer implements Deserializer&lt;String&gt; &#123;</span><br><span class="line">    private String encoding &#x3D; &quot;UTF8&quot;;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void configure(Map&lt;String, ?&gt; configs, boolean isKey) &#123;</span><br><span class="line">        String propertyName &#x3D; isKey ? &quot;key.deserializer.encoding&quot; : &quot;value.deserializer.encoding&quot;;</span><br><span class="line">        Object encodingValue &#x3D; configs.get(propertyName);</span><br><span class="line">        if (encodingValue &#x3D;&#x3D; null)</span><br><span class="line">            encodingValue &#x3D; configs.get(&quot;deserializer.encoding&quot;);</span><br><span class="line">        if (encodingValue instanceof String)</span><br><span class="line">            encoding &#x3D; (String) encodingValue;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public String deserialize(String topic, byte[] data) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            if (data &#x3D;&#x3D; null)</span><br><span class="line">                return null;</span><br><span class="line">            else</span><br><span class="line">                return new String(data, encoding);</span><br><span class="line">        &#125; catch (UnsupportedEncodingException e) &#123;</span><br><span class="line">            throw new SerializationException(&quot;Error when deserializing byte[] to string due to unsupported encoding &quot; + encoding);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>消息消费</li></ul><p>  Kafka中的消费是基于拉模式的。消息的消费一般有两种模式：推模式和拉模式。推模式是服务端主动将消息推送给消费者，而拉模式是消费者主动向服务端发起请求来拉取消息。从轮询循环代码清单中可以看出，Kafka中的消息消费是一个不断轮询的过程，消费者所要做的就是重复地调用poll（）方法，而poll（）方法返回的是所订阅的主题（分区）上的一组消息。对于poll（）方法而言，如果某些分区中没有可供消费的消息，那么此分区对应的消息拉取的结果就为空；如果订阅的所有分区中都没有可供消费的消息，那么poll（）方法返回为空的消息集合。</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ggcyw50wbjj31nw0eeaib.jpg"></p><p>poll（long）方法中timeout的时间单位固定为毫秒，而poll（Duration）方法可以根据Duration中的ofMillis（）、ofSeconds（）、ofMinutes（）、ofHours（）等多种不同的方法指定不同的时间单位，灵活性更强。并且 poll（long）方法也已经被标注为@Deprecated，虽然目前还可以使用，如果条件允许的话，还是推荐使用poll（Duration）的方式。</p><p>我们在消费消息的时候可以直接对 ConsumerRecord 中感兴趣的字段进行具体的业务逻辑处理。</p><p>poll（）方法的返回值类型是 ConsumerRecords，它用来表示一次拉取操作所获得的消息集，内部包含了若干ConsumerRecord，它提供了一个iterator（）方法来循环遍历消息集内部的消息，iterator（）方法的定义如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">public Iterator&lt;ConsumerRecord&lt;K, V&gt;&gt; iterator() &#123;</span><br><span class="line">    return new ConcatenatedIterable&lt;&gt;(records.values()).iterator();</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>在 ConsumerRecords 类中还提供了几个方法来方便开发人员对消息集进行处理：count（）方法用来计算出消息集中的消息个数，返回类型是int；isEmpty（）方法用来判断消息集是否为空，返回类型是boolean；empty（）方法用来获取一个空的消息集，返回类型是ConsumerRecord＜K，V＞。</p><p>到目前为止，可以简单地认为poll（）方法只是拉取一下消息而已，但就其内部逻辑而言并不简单，它涉及消费位移、消费者协调器、组协调器、消费者的选举、分区分配的分发、再均衡的逻辑、心跳等内容</p><ul><li>位移提交</li></ul><p>  对于Kafka中的分区而言，它的每条消息都有唯一的offset，用来表示消息在分区中对应的位置。对于消费者而言，它也有一个offset的概念，消费者使用offset来表示消费到分区中某个消息所在的位置。单词“offset”可以翻译为“偏移量”，也可以翻译为“位移”，很多同学可能并没有过多地在意这一点：在很多中文资料中都会交叉使用“偏移量”和“位移”这两个词，并没有很严谨地进行区分。</p><p>  我对offset做了一些区分：对于消息在分区中的位置，我们将offset称为“偏移量”；对于消费者消费到的位置，将 offset 称为“位移”，有时候也会更明确地称之为“消费位移”。做这一区分的目的是让读者在遇到 offset 的时候可以很容易甄别出是在讲分区存储层面的内容，还是在讲消费层面的内容</p><p>  在每次调用poll（）方法时，它返回的是还没有被消费过的消息集（当然这个前提是消息已经存储在Kafka 中了，并且暂不考虑异常情况的发生），在旧消费者客户端中，消费位移是存储在ZooKeeper中的。而在新消费者客户端中，消费位移存储在Kafka内部的主题__consumer_offsets中。这里把将消费位移存储起来（持久化）的动作称为“提交”，消费者在消费完消息之后需要执行消费位移的提交。</p><p>  <img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ggd02ca45zj30w40f2q5a.jpg"></p><ul><li> 指定位移消费</li></ul><p>  正是有了消费位移的持久化，才使消费者在关闭、崩溃或者在遇到再均衡的时候，可以让接替的消费者能够根据存储的消费位移继续进行消费 ,可是有一个问题则是 _consumer_offsets 位移信息过期而被删除后，它也没有可以查找的消费位移 ，这个时候就会根据消费者客户端参数auto.offset.reset的配置来决定从何处开始进行消费</p><p>  除了查找不到消费位移，位移越界也会触发 auto.offset.reset 参数的执行 ，然而有些时候，我们需要一种更细粒度的掌控，可以让我们从特定的位移处开始拉取消息，哎 ！这个时候 KafkaConsumer 中的 seek（）方法正好提供了这个功能，让我们得以追前消费或回溯消费。seek（）方法的具体定义如下：</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public void seek(TopicPartition partition, long offset) &#123;&#125;</span><br></pre></td></tr></table></figure><p>seek（）方法为我们提供了从特定位置读取消息的能力，我们可以通过这个方法来向前跳过若干消息，也可以通过这个方法来向后回溯若干消息，这样为消息的消费提供了很大的灵活性</p><blockquote><p>原创不易，如果觉得有点用的话，请毫不留情点个赞，转发一下，这将是我持续输出优质文章的最强动力。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
